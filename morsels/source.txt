:d:A list of game design concepts.
:k:Game Design, Game Mechanics, Game Narratives, Technical Game Design, Game AI, Gameplay Systems, Game Development, Mechanical Narratives, Gameplay Algorithms, Gameplay Semantics, Game Logic
:l:2024-07-26

[Game Design Concepts] June 27, 2024 - July 26, 2024

This is a collection of game design concepts.

@@<hr>
@@<div class="l_spacer"></div>
<001>
@@<h3><b>1. Mechanical Narratives</b></h3>

A game is usually a combination of two factors - mechanics and narratives.

Mechanics represent the systematic aspects of the game, such as physics, AI, crafting rules, progression curves, and others which rely on the knowledge of math/engineering.

Narratives represent the volitional aspects of the game, such as lores, stories, personalities, goals, and others which rely on the knowledge of arts/humanities.

A problem we often experience is that it is too tricky to fit these two together in one place. Many ambiguous cases are prone to arise, such as:

(1) Having a cool story (narrative) for a video game, but not knowing how to turn it into gameplay (mechanic).
(2) Knowing how to implement a clever enemy AI (mechanic), but not knowing how to design an appropriate enemy character for it (narrative).
(3) Having an interesting NPC with a unique personality (narrative), but not knowing which in-game role it ought to play (mechanic).

A solution is to start designing the game with building blocks which can both be considered mechanics and narratives at the same time (aka "mechanical narratives").

If we start by laying out the game's narratives first, it will be difficult to devise mechanics which are compatible with the given narratives. If we start by laying out the game's mechanics first, on the other hand, it will be difficult to devise narratives which are compatible with the given mechanics.

Such a dilemma can be bypassed by simply collecting a number of "mechanical narratives" and assembling them together.

@@<hr>
@@<div class="l_spacer"></div>
<002>
@@<h3><b>2. Sensors, Filters, and Motors</b></h3>

In general, a gameplay agent can be constructed by assembling 3 types of modules - sensors, filters, and motors.

Sensors collect data from the environment, filters process the data (for analysis), and motors trigger the agent to take actions based upon the filtered data.

Here is an example. Imagine that there is an anti-aircraft gun whose role is to shoot down enemy airplanes in range. We can model this gun as a composition of:

(1) A sensor (i.e. radar) which detects anything within the specified range,
(2) A filter (i.e. computing module) which looks up the database to see if the detected object is an enemy airplane, and
(3) A motor (i.e. the gun itself) which fires bullets at any object which is identified as an enemy airplane.

The gun detects an aircraft, checks to see if it is an enemy, shoots at it if so, and then detects another aircraft, checks to see if it is an enemy, shoots at it if so, and then detects another aircraft... and so on.

This is just a simple example. For more complex behaviors, you may as well equip it with multiple sensors (e.g. radar, camera, antenna), multiple filters (e.g. distance filter, look-angle filter), multiple motors (e.g. gun, horizontal rotor, vertical rotor, ammunition reloader), etc.

Such a multitude of modules can then communicate with one another by means of series connections, parallel connections, or both.

@@<hr>
@@<div class="l_spacer"></div>
<003>
@@<h3><b>3. Psychological Force Field</b></h3>

Psychological force field is a useful concept in game design.

We typically imagine each individual game character as an observer, equipped with its own independent mind. It continuously scans the environment and makes decisions off of it.

Each observer carries its own psychological force field which permeates the entirety of the game world. Every entity other than the observer itself essentially "warps" the field nearby, modifying the magnitudes and directions of the force vectors which guide the observer's movement.

A repulsive entity adds outward forces to the field, whereas an attractive entity adds inward forces to the field. This makes the observer move away from repulsive entities and closer to attractive entities.

Whether an entity is repulsive or attractive is determined by the observer's personal preference.

The force that is to be applied to the observer can be computed by the function "PsyForce(id, X, Y)", where "id" is the unique ID of the observer and (X, Y) is the observer's current position. This function returns the psychological force vector which gets added to the observer's net force.

A real life example of psychological force field is Feng Shui, where architectural patterns are believed to shape the field in which the residents of the house reside, thereby influencing the way they behave.

@@<hr>
@@<div class="l_spacer"></div>
<004>
@@<h3><b>4. Parallel-Attention Timeline</b></h3>

A parallel-attention timeline is a pretty useful tool to use in gameplay AI.

It starts from a simple analogy.

When I am stirring a pot of spaghetti while also heating a plate of frozen garlic bread in the oven, you can say that I must be multitasking.

However, it should be noted that I am paying way more attention to the pot of spaghetti than to the oven because the latter basically takes care of itself and only demands occasional supervision.

When designing a game, it is convenient to assume that each game character carries its own schedule in its mind, filled with tasks which start and end at their own designated points in time.

It is sometimes even more desirable, though, to model a schedule not as a one-dimensional queue of tasks, but as a two-dimensional grid in which each column represents a time slot and each row represents what could be referred to as "attention priority".

A character which follows this two-dimensional schedule always runs the task which occupies the highest row (i.e. highest attention priority) among all the tasks which occupy the current time slot.

Whenever an "attention trigger" (i.e. any object which demands attention) tries to register a new task to the schedule, the schedule will either ignore this new task if it happens to collide with an existing one, or proceed to register it if not.

Each task possesses its own intrinsic attention priority (i.e. row) which cannot be modified.

@@<hr>
@@<div class="l_spacer"></div>
<005>
@@<h3><b>5. Partial Movement Constraints</b></h3>

Both too much freedom and too little freedom are undesirable in gameplay.

Suppose that there are enemy characters whom the player must defeat in order to finish the level.

If the enemies are able to move in any direction, it will be a bit too bland because it reduces the functional significance of the level's peculiar spatial configuration (e.g. If you are being chased by an enemy who can only move horizontally, you can take refuge in a vertical space).

If the enemies are completely immobile, on the other hand, it will be pretty bland as well because it makes gameplay less dynamic.

A nice middle ground which leverages the benefits of both is to confine each enemy's locomotive freedom to a set of simple pathways, as though it is a train following a railway.

This mixed approach has 3 main advantages:

(1) It makes it easy to diversify enemy behaviors and introduce a wide variety of in-game strategies.
(2) Its pathfinding algorithm is easier to implement and way less computationally expensive than, say, the A-Star algorithm.
(3) It prevents extreme gameplay scenarios, such as letting the player be completely surrounded by a truckload of enemies because they always keep chasing the player without a pause. By limiting each enemy's maximum range of movement, we can spread out the distribution of enemies throughout the level and prevent them from concentrating too much in one place.

@@<hr>
@@<div class="l_spacer"></div>
<022>
@@<h3><b>6. Emotional State Machine</b></h3>

When it comes to designing gameplay systems, it is often useful to model each game character as a state machine (i.e. an object with a set of possible states). There are more advanced models indeed, but state machines usually suffice for fairly simple purposes.

Such a state machine typically comprises the character's action states, such as "idle", "attacking", "stunned", "wandering", and so on. However, this representation does not reflect the character's inner psychological states such as emotions.

In order to give depth to the game's narratives, we must let game characters have their own emotions. And this can be done by designing each character as an emotional state machine.

An emotional state machine resides in a 3D space called "emotion space", whose 3 spatial axes represent the character's happiness, excitement, and confidence.

The characters's emotional state is a point in the emotion space, and a change in the emotion is the same thing as a displacement of the point from one location to another.

When happiness, excitement, and confidence are all low, the character is depressed and timid. When happiness, excitement, and confidence are all high, the character is fascinated and arrogant. When happiness is high but excitement and confidence are low, the character is quietly happy in its selfless devotion. And when happiness and excitement are low but confidence is high, the character is in the mood of Squidward.

You can change the emotion's current state by applying a "psychological force" to it. The way you do it is to put the emotion's position under a psychological force field.

@@<hr>
@@<div class="l_spacer"></div>
<023>
@@<h3><b>7. Deities of the Game World</b></h3>

Designing a game is essentially the same thing as designing your own virtual world.

A game is a world which is governed by its own set of natural laws. And the manner in which these laws are being enforced largely depends on the manner in which the developer has initially configured the world.

Game worlds come in different types, each of which pertains to a particular theistic worldview.

Inside a monotheistic game world, a single control module regulates the feedback loops of the game characters.

Inside a polytheistic game world, multiple control modules regulate the feedback loops of the game characters.

Inside a pantheistic game world, the game characters' feedback loops are not being regulated by any external module; the characters themselves are their own regulators.

One of the main advantages of using either a monotheistic or polytheistic system is that it allows the gamemaster to occasionally override the game's default laws by means of admin privilege. In computer science, it is called "miracle".

@@<hr>
@@<div class="l_spacer"></div>
<025>
@@<h3><b>8. Modular Behavior Tree</b></h3>

Behavior trees are useful in game AI. You can implement a wide range of complex decision-making agents based upon them.

Sometimes, however, we feel overwhelmed by the urge to make a behavior tree unreasonably enormous when there are way too many types of items with which the agent is supposed to interact.

For example, imagine that a game character has a behavior tree which involves a task called "eat". In order to tell the character exactly what to do when it runs this task, the "eat" node must be able to handle all possible ways of eating, such as how to eat a salmon, how to eat a donut, how to eat a taco, and so on.

Thus, it is oftentimes convenient to make behavior trees modular, so that a tree of tasks that is specific to the object of interaction can simply reside within the object, temporarily stick itself to the character's "eat" task during the interaction, and then depart once the interaction is over.

@@<hr>
@@<div class="l_spacer"></div>
<026>
@@<h3><b>9. Brand-Building</b></h3>

One thing I learned while developing and publishing indie games, was that a game needs to have its own brand in order to be truly successful.

Creating a brand is such a monumental challenge. One cannot just put a bunch of buzzwords together and expect it to leave a lasting impact upon the heart of the audience. In my opinion, a great brand requires 3 major elements: Purpose, Logic, and Mystery.

A brand needs a purpose because otherwise the customer won't be encouraged to partake in its narrative. Without a purpose, there is no need to support the brand's growth by any means.

A brand cannot flourish without any logic either. It must have a logically sound solution to fulfill the said purpose. Our reason must be able to grasp it, for otherwise everybody will be left confounded.

However, a brand also ought to preserve a decent amount of mystery in it. Even a perfectly logical solution, guaranteed to solve the most urgent problem in the most quintessential way, won't attract the audience if they are not given their own roles to participate in a journey to freely explore the unknown and discover hidden treasures.

In general, I believe that the most appealing brand must have its own purpose, logic, and mystery in equal measures. This corresponds to the center point of the circular diagram I have shown here (denoted by the Sun).

@@<hr>
@@<div class="l_spacer"></div>
<043>
@@<h3><b>10. Image as a Game Map</b></h3>

Using an image to generate a game map is sometimes a good idea.

Suppose that your game comprises one vast terrain, modeled as a 2D voxel grid.

All you need to do is create an image and simply assume that its pixels represent to the terrain's voxels.

Each pixel's brightness may indicate the terrain's height. This can be graphically implemented by rendering the terrain as a grid of quads and letting the vertex shader set the y-coordinate of each vertex based on the corresponding pixel's brightness.

Each pixel's saturation may indicate the density of props, where low saturation means low probability of spawning a prop at the pixel's location, and high saturation means high probability of spawning a prop at the pixel's location.

Lastly, each pixel's hue may indicate the terrain's biome type, where "green" means forest/meadow, "orange" means village, "magenta" means palace, and so on.

Additional data-embedding is possible, too, as long as your image is transparent. The opacity of each pixel can be used to specify some other physical properties of the terrain, such as temperature, humidity, etc. Or it may be used for metadata, in which the game's trigger zones, waypoints, and spawn hotspots can be encoded.

With this image-based map generation system, you can even manipulate the terrain while playing the game because it is just a matter of image processing (run by fragment shaders). The overall erosion of the terrain is the same thing as blurring the image, and hitting the terrain with a meteorite is the same thing as painting the impact zone with a semi-transparent black brush.







:d:A mathematical model of our own thoughts, feelings, and the sense of curiosity.
:k:Curiosity, Motivation, Motive Force, Curiosity Force, Conceptual Space, Physical Space, Katarina Gyllenbäck, Feature Space, Idealism, Ontology, Epistemology
:l:2024-07-27

[Model of the Mind] June 28, 2024 - July 27, 2024

This is a collection of mathematical concepts designed to express the nature of human mind in a rational manner.

The ideas shown below are inspired by Katarina Gyllenbäck's articles. For more information, visit {%a href="https://thingspool.net/read-rec/page-2.html"%}Here{%/a%}.

@@<hr>
@@<div class="l_spacer"></div>
<006>
@@<h3><b>1. Physical Space and Conceptual Space</b></h3>

There are two different spaces in our universe - physical space and conceptual space.

Physical space is the space we usually refer to whenever we are employing the word "space". It consists of spatial and temporal axes (e.g. X, Y, Z, and Time), and serves as a frame of reference when it comes to describing physical entities such as rigid bodies.

Conceptual space, on the other hand, is the space of qualitative features. For example, a color is a position in the RGB color space, where the axes (R, G, B) represent the intensity levels of the three primary color components (i.e. Red, Green, Blue). The RGB color space is one of many types of conceptual spaces we can imagine.

Each object has its own position in physical space as well as a position in conceptual space. The former tells us where the object is, and the latter tells us what the object looks like.

@@<hr>
@@<div class="l_spacer"></div>
<007>
@@<h3><b>2. Particulars and Universals</b></h3>

There are two types of objects - particulars and universals.

A particular is an object which exists at a specific point in space and time. All tangible objects, such as a table we can touch, a sandwich we can eat, a cup we can hold, and countless other "real" things, can be classified as particulars.

A universal is different from a particular in the sense that we cannot directly perceive it, since it exists only in conceptual space and not in physical space. It is a pure idea which resides only in the spiritual realm; it does not belong to anywhere in our material world.

In computer science, a class is a universal. It is purely spiritual because it lives in the static memory, which is fixed and therefore "eternal" in the sense that it spans the entirety of the application's runtime.

An instance of a class, which is dynamically allocated in memory, is a particular. It is a mortal being which gets created at some point in time and gets destroyed at some other point in time. It is never eternal because it does not span the entirety of the application's runtime.

@@<hr>
@@<div class="l_spacer"></div>
<008>
@@<h3><b>3. Contiguity and Resemblance</b></h3>

Since an object exists in two different spaces (namely, "physical space" and "conceptual space"), a distance between a pair of objects can possess either one of two meanings depending on the type of space in which it is measured.

Physical proximity implies contiguity. When two things are very close to each other in physical space, we say that they are contiguous because looking at one of them lets us look at the other much more easily.

Conceptual proximity implies resemblance. When two things are very close to each other in conceptual space, we say that they resemble each other because thinking of one of them lets us think of the other much more easily.

Proximity can be measured by taking the reciprocal of the distance. Less distance means more proximity, and more distance means less proximity.

@@<hr>
@@<div class="l_spacer"></div>
<009>
@@<h3><b>4. Surprise</b></h3>

How to measure the amount of surprise between two objects?

Each object has two distinct positions - one in physical space, and the other one in conceptual space. Therefore, we are able to compute two separate distances between a pair of objects - physical distance and conceptual distance.

The amount of surprise between two objects is proportional to their conceptual distance because the more qualitatively different they are, the more surprised they will be when they see each other.

On the other hand, the amount of surprise between two objects is inversely proportional to their physical distance because the closer they are, the more vividly they will observe each other's qualitative differences.

Thus, we can measure the amount of surprise by measuring the conceptual distance and then dividing it by the physical distance.

@@<hr>
@@<div class="l_spacer"></div>
<010>
@@<h3><b>5. Curiosity Force</b></h3>

Curiosity often drives us to move from familiar places to unfamiliar places. It is possible to devise a mathematical formula which tells us exactly how the force of curiosity will initiate such a movement.

Suppose that there is an observer somewhere in physical space. We can first compute the observer's "surprise vectors", each of which represents the amount of surprise that the observer feels in regard to an external object.

If you take the sum of all the surprise vectors which involve the observer and multiply the resulting "net surprise vector" by the amount of the observer's curiosity, you will obtain the "curiosity force vector" which is responsible for pushing the observer to venture into the unknown.

@@<hr>
@@<div class="l_spacer"></div>
<016>
@@<h3><b>6. How to Compute Curiosity</b></h3>

Can we represent curiosity as a numerical quantity?

The amount of curiosity reaches its peak value when the person is feeling a sense of surprise which is neither too intense nor too dim.

If you are surrounded by an environment which is not surprising at all, you will lose curiosity due to boredom.

If you are surrounded by an environment which is too overwhelmingly surprising, you will be anxious. As a result, you will suppress your curiosity in order to protect yourself from potential dangers.

It is only when you are surrounded by a moderately surprising environment (i.e. neither too familiar nor too unfamiliar) that you will be able to feel a vivid sense of curiosity.

A halfway mixture between familiar and unfamiliar elements creates a "Goldilocks zone of motivation" which will encourage you to uncover partially hidden secrets.

If everything is already uncovered, there will be no secret to uncover and so you won't feel the necessity to start an adventure. If everything is veiled in darkness, you will feel clueless and thus not even dare to start an adventure.

@@<hr>
@@<div class="l_spacer"></div>
<046>
@@<h3><b>7. Uniformity</b></h3>

It is possible to measure the amount of uniformity between two objects.

In order for a pair of objects to comprise one uniform body, they must satisfy two conditions.

First, they must be physically close to each other. If they are too far apart, we will clearly be able to see that there is a significant spatial gap between them, showing that they are discontinuous and thus not uniform.

Secondly, they must resemble each other (i.e. similar in characteristics). If they look too drastically different, we will be able to tell that their mutual contrast is too huge to ensure that they are part of one smooth, uniform body.

Therefore, the amount of uniformity can be computed by taking the inverse of the product between their physical and conceptual distances.

@@<hr>
@@<div class="l_spacer"></div>
<047>
@@<h3><b>8. Force of Adaptation</b></h3>

If you measure the amount of uniformity between the observer and a nearby object, you will obtain a number which tells you how familiar the observer is with the object.

And if you represent this number as the magnitude of a vector which starts at the observer's conceptual location and points itself to the object's conceptual location, you will get a vector which can be referred to as a "uniformity vector".

Take the sum of all uniformity vectors which originate from the observer, and you will acquire the net uniformity vector. This vector informs us the strength and direction of the surrounding environment's familiarity with respect to the observer.

Scale this net uniformity vector by the observer's adaptivity (which is a scalar value) and you will obtain the force vector which is currently pushing the observer's viewpoint in conceptual space. This force gradually "adapts" the observer to the surroundings, making them become more and more familiar as time passes by.

@@<hr>
@@<div class="l_spacer"></div>
<048>
@@<h3><b>9. Dynamics of Exploration</b></h3>

The force of curiosity pushes the observer's body in physical space, toward areas which are unfamiliar to him.

Meanwhile, the force of adaptation pushes the observer's viewpoint in conceptual space, toward areas which are as familiar to him as possible. This lets him quickly adapt himself to his surroundings.

These two forces work together in parallel, continuously propelling both the observer's body (location in physical space) and viewpoint (location in conceptual space) in the direction of spontaneous exploration.

The back-and-forth interaction between these two forces creates a feedback system. The force of curiosity puts the observer in unfamiliar places, which in turn compels the observer to adapt his viewpoint to the unfamiliar. Once his surroundings become too familiar to him, his curiosity then drives him to search for other unfamiliar territories to explore.







:d:A mathematical interpretation of David Hume's philosophy.
:k:David Hume, Empiricism, Empirical Philosophy, Metaphysics, Epistemology, Ontology, Discrete Math, Philosophy Of Mind, Computational Psychology
:l:2024-07-31

[Mathematical Interpretation of Hume's Philosophy] July 2, 2024 - July 31, 2024

This is a mathematical interpretation of David Hume's philosophy. It is mostly based upon my personal analysis, so please take it with a grain of salt.

I drew most of my inspirations from his book, "An Enquiry Concerning Human Understanding". For more information, visit {%a href="https://thingspool.net/read-rec/page-6.html"%}Here{%/a%}.

@@<hr>
@@<div class="l_spacer"></div>
<011>
@@<h3><b>1. Introduction</b></h3>

Hume's empiricist worldview begins with a hierarchy of concepts.

There are two major types of components in his domain of knowledge. One is "perceptions", and the other one is "objects of reason". Perceptions are the atoms of the mind, whereas objects of reason are molecules which can be formed by bonding those atoms together.

A perception is any "thought" we can conceive in our minds. It belongs to either one of the two categories - impressions and ideas.

An impression is a direct stimulus received by our sense organs. Things we directly see, hear, smell, taste, and feel are all impressions.

In contrast, an idea is an afterthought on the impressions we received. For example, what we see is an impression, but the recollection of what we just saw is an idea. Impressions are vivid, while ideas are dim.

Objects of reason can be subdivided into two categories - "relations of ideas" and "matters of fact".

A relation of ideas is a result of pure logic, such as a mathematical theorem which manages to prove itself based upon a set of ideas only, without relying on the presence of external stimuli. A matter of fact, on the other hand, requires a considerable amount of empirical data to validate itself (like the law of gravitation).

@@<hr>
@@<div class="l_spacer"></div>
<012>
@@<h3><b>2. Impressions and Ideas</b></h3>

Hume's definition of "impressions" and "ideas" provides us with a rudimentary ground of logic, upon which we can formulate a model of how we sense and recall our own thoughts.

Impressions are what we typically refer to as "sensory stimuli". These are the most immediate and piercing kind of perceptions which we feel with the utmost degree of intensity.

Ideas, on the other hand, are byproducts of impressions. They linger in our minds like ghosts, which occasionally touch our feelings but to a much lesser degree. Unlike impressions which are momentary, ideas stay in the person's memory and get recalled on demand.

In a way, therefore, ideas are Lego bricks which can fit one another nicely in our minds, whereas impressions are just raw plastic ingredients which are yet to be molded into such bricks.

@@<hr>
@@<div class="l_spacer"></div>
<013>
@@<h3><b>3. Generation of Ideas</b></h3>

According to Hume's philosophy, each impression generates its corresponding idea when it enters our domain of cognition.

However, he also mentions that the relation between impressions and their ideas is not necessarily one-to-one. There may as well be cases in which a wide spectrum of ideas manage to emerge from a relatively few impressions.

An impression of "light blue" and an impression of "dark blue", for example, may allow us to imagine an intermediate shade of blue (by mixing the qualities of light blue and dark blue) and remember it as a distinct idea. This lets us picture the full spectrum of blue without having to directly sense every single one of its variants via external stimuli.

@@<hr>
@@<div class="l_spacer"></div>
<014>
@@<h3><b>4. Relations between Ideas</b></h3>

We assign meaning to our ideas by establishing relations between them. In Hume's model of the human mind, there are three fundamental types of such relations - resemblance, contiguity, and causality (aka "cause and effect").

Resemblance tells us that two ideas are qualitatively similar to each other (such as two slightly different shades of blue). This is something we can immediately tell from our perceptions.

Contiguity tells us how close two ideas are to each other in spacetime. This, too, is something we can immediately tell from our perceptions.

Causality, however, is not something we can identify in such a straightforward manner. We must derive it from the other two types of relations (i.e. resemblance and contiguity).

@@<hr>
@@<div class="l_spacer"></div>
<015>
@@<h3><b>5. Causal Relations</b></h3>

An idea alone does not have the word "cause" or "effect" written on its face, and the only way for us to prove that an idea "causes" another idea is that one of them frequently precedes (or succeeds) the other in spacetime.

Also, since it is almost impossible for us to reproduce the same exact idea over and over in our material world (which is plagued with all sorts of random noises such as acoustic waves, electromagnetic disturbances, thermal noise, etc), we must rely on our belief that similar causes are likely to produce similar effects.

This leads us to the conclusion that, if a set of mutually resembling ideas are contiguous with another set of mutually resembling ideas, we can say that these two sets are causally related to each other.

@@<hr>
@@<div class="l_spacer"></div>
<017>
@@<h3><b>6. Facts</b></h3>

What is a "fact", really?

There are many ideas in our domain of reason, yet the boundary between ones that are supposed to be "facts" and ones that are mere personal feelings often looks a bit fuzzy.

Hume's philosophy tells us that an idea can be considered a "fact" if it is caused by a sufficiently large number of causes (e.g. preceded by a sufficiently long chain of causal relations).

Each cause works as a proof of the idea's truthfulness. The more causes there are, the more confidently we are able to say that the idea is true. If it is so true that its truthfulness is hardly questionable, we say that the idea is a "fact".

People who know how a blockchain works (such as Bitcoin or Ethereum) will easily come to the realization that ideas are reminiscent of blockchain transactions, and that a "fact" is basically a transaction which has been mined (verified) and is given credit by a long chain of preceding blocks.

@@<hr>
@@<div class="l_spacer"></div>
<027>
@@<h3><b>7. Simple and Complex Ideas</b></h3>

In "A Treatise of Human Nature", Hume makes a clear distinction between simple and complex ideas.

Based upon his rejection of the infinite divisibility of our sense-data, he says that "simple ideas" are ideas which cannot be further divided into its component parts, meaning that they are the "atoms" of our mind.

Examples of simple ideas include the primary color components (e.g. red, green, and blue), musical notes, and other irreducible units of sensation.

"Complex ideas", on the other hand, are groups of simple ideas. Each complex idea is a product of synthesis among two or more simple ideas. It is also possible to group complex ideas to form even more complex ideas.

A simple impression (i.e. external stimulus) gives birth to a simple idea. A multitude of simple ideas, then, give birth to complex ideas based on the way in which they are related to each other.

@@<hr>
@@<div class="l_spacer"></div>
<028>
@@<h3><b>8. Abstraction and Combination</b></h3>

A group of simple ideas are able to produce a complex idea. A group of complex ideas, too, are able to produce yet another complex idea which is even more complex than the preceding ones.

In general, therefore, we can say that a group of ideas with appropriate relations, whether they are simple or complex, are capable of generating a complex idea whose level of complexity is slightly higher than them.

There are two ways in which a complex idea may emerge - abstraction and combination.

When you see a group of slightly different shades of blue, you will recognize that they closely resemble each other. From this, you can conclude that they all belong to a class of objects called "blue". This is an example of abstraction.

When you see a lump of various colors, on the other hand, you will recognize that the individual colored spots do not necessarily resemble each other but are nevertheless very closely packed together in physical space. From this, you can conclude that they all belong to the same object. This is an example of combination.

@@<hr>
@@<div class="l_spacer"></div>
<029>
@@<h3><b>9. Relations between Complex Ideas</b></h3>

There are two primary types of relations between ideas - resemblance and contiguity. Resemblance indicates conceptual proximity, and contiguity indicates physical proximity.

Just like resemblance and contiguity can connect simple ideas, they are able to connect complex ideas as well.

An object is a complex idea which is based off of a set of contiguous ideas. When two objects have sufficiently many pairs of resembling ideas between them, they resemble each other.

A class is a complex idea which is based off of a set of resembling ideas. When two classes have sufficiently many pairs of contiguous ideas between them, they are contiguous to each other.

A contiguity between two classes may also be referred to as "causality" (i.e. One of them is either the "cause" or "effect" of the other).

@@<hr>
@@<div class="l_spacer"></div>
<030>
@@<h3><b>10. Data Structure of an Idea</b></h3>

According to Hume's argument in "A Treatise of Human Nature", every idea (or impression) must possess its own quality and quantity.

An idea's quality denotes the category of sensation to which it belongs, such as "brightness", "musical pitch", or "temperature".

An idea's quantity denotes its quality's intensity level. For instance, if there is an idea whose quality is "temperature" and whose quantity is "30", we may consider this idea as a sensation of warmth which is 30 degrees in temperature.

Hume says that an impression is basically the same thing as an idea (i.e. It has its own quality and quantity), except that it is much higher in "force and vivacity".

Therefore, I personally find that it is much more convenient to consider an impression as an idea whose level of vivacity is sufficiently high.

When expressed in the language of computer science, both impressions and ideas are mere instances of the same data structure called "Idea", which contains 3 integers - Quality, Quantity, and Vivacity.

@@<hr>
@@<div class="l_spacer"></div>
<031>
@@<h3><b>11. Metaphor</b></h3>

Metaphors are everywhere. They appear in poetry, novels, songs, and many other forms of media. However, they are often accused of being irrational.

Hume's philosophy suggests otherwise. It is possible to define a metaphor on a rational basis.

An idea has a location in conceptual space, which is composed of two dimensions called "quality" and "quantity". Quality indicates the category of sensation (e.g. brightness, loudness, temperature, etc), and quantity indicates its level of intensity.

We say that there is a resemblance between two ideas when they are close to each other in conceptual space. There are two types of resemblances: (1) Resemblance in quality, and (2) Resemblance in quantity.

Coldness and hotness do not resemble each other quantitatively, since their intensity levels (i.e. temperature) differ significantly. However, they resemble each other qualitatively because they both belong to the same category called "temperature".

On the contrary, red and hotness do not resemble each other qualitatively because they belong to two drastically different categories of sensation. However, they resemble each other quantitatively because the high emotional intensity of red is similar in magnitude to the high temperature of hotness. This is what we call "a metaphor".

@@<hr>
@@<div class="l_spacer"></div>
<032>
@@<h3><b>12. Unity between Two Positions</b></h3>

An idea must have its own quality and quantity. However, we ought to be aware that it must also have its own physical location in order for the mind to conceive it.

For example, when you are imagining a colored point, you cannot do it without locating it somewhere inside your imaginary field of vision.

Hume suggests that, in order for an idea to "exist", we must be able to perceive it either through external senses or our own imagination. Therefore, an idea is required to have a pair of positions - one in conceptual space, and the other one in physical space.

It may theoretically be insisted that it is also feasible to formulate "pure ideas" which belong to either physical space or conceptual space but not both. Such constructs, however, are not directly sensible and thus do not belong to the domain of cognition.

@@<hr>
@@<div class="l_spacer"></div>
<033>
@@<h3><b>13. Position of a Complex Idea</b></h3>

How to compute the position of an idea?

The position of a simple (atomic) idea does not have to be computed. It is simply given to our faculty of senses the very moment it is perceived.

The position of a complex idea, on the other hand, must be computed based upon those of its component ideas.

An object in physical space appears to be a single point when viewed from a sufficiently long distance. The physical position of such a point is the center of mass of the object's components in physical space.

Meanwhile, the object's individual color spots "average out" when they are condensed into a single point. This means that its conceptual position is the center of mass of the object's components in conceptual space.

The "mass" of an idea is its vivacity.

@@<hr>
@@<div class="l_spacer"></div>
<034>
@@<h3><b>14. Word and Symbol</b></h3>

Whenever we communicate, we use words and symbols to reference our ideas.

The difference between a word and a symbol can be found in the two fundamental relations between ideas - contiguity (i.e. proximity in physical space) and resemblance (i.e. proximity in conceptual space).

When you open up a children's book intended to teach basic English words, you will see that there are lots of images with words next to them. For example, if there is an image of fire, the book will also put the word "fire" right next to it in order to teach the child that the word "fire" is associated with the appearance of fire.

Here, the word "fire" and the appearance of fire do not visually resemble each other, but the child nevertheless learns that the former indicates the latter because these two things have been displayed contiguously in physical space (i.e. page of the book).

What about a symbol? Here is an example. An airplane's safety manual typically uses an icon of fire (aka pictogram) to reference real fire.

In this case, the icon is a symbol of fire, not because we have necessarily seen this icon appearing right next to real fire in physical space, but because we know that these two things visually resemble each other.

Therefore, a word is an idea which references another idea by means of proximity in physical space, whereas a symbol is an idea which references another idea by means of proximity in conceptual space.

@@<hr>
@@<div class="l_spacer"></div>
<035>
@@<h3><b>15. Rate of Change</b></h3>

When there is a moving car, how do we measure its speed?

Suppose that we have two snapshots available, one of them showing the car's position at one point in time, and the other one showing the car's position at another point in time.

Let us refer to the first snapshot's position and time as (p1, t1), and the second snapshot's position and time as (p2, t2). Since p1 and t1 appear together in the same snapshot, we know that they are contiguous. And since p2 and t2 appear together in the same snapshot, we know that they, too, are contiguous. Furthermore, since the two snapshots are juxtaposed right next to each other, they are contiguous as well.

And since they (p1, t1, p2, t2) all make up a single body of contiguities, we can tell that they all belong to the same context.

t1 and t2, although they are not physically nearby, belong to the same "quality" in conceptual space (because they are both time values). From this coincidence, we are able to tell that their quantities are comparable. The result of their comparison is the change in time (Δt = t2 - t1).

Similarly, p1 and p2 belong to the same "quality" in conceptual space (because they are both position values), so we are able to tell that their quantities are comparable as well. The result of their comparison is the change in position (Δp = p2 - p1).

The car's speed according to the two snapshots, then, is the ratio between Δt and Δp (i.e. ratio between the lengths of the vertical line segments in conceptual space which are associated with the two snapshots).

@@<hr>
@@<div class="l_spacer"></div>
<036>
@@<h3><b>16. Cause and Effect</b></h3>

Ideas often represent events, and we know that the human mind is prone to associate events with one another in terms of cause and effect (i.e. causality).

Hume says that, by making a sufficient number of observations, we are able to notice a "constant conjuction" between two classes of objects. Hence, he explains that this "constant conjuction" is the data from which we draw the notion of causality.

In order to decide which event is the cause (or effect) of the other, however, we should make an additional analysis. It is the concept of "precedence" to which we ought to pay attention, since it is what gives a direction to the causal relation.

If there is a relation of causality between X and Y, we say that X must be the cause of Y if X precedes Y in time, and vice versa.

This endows the chain of events with a fixed direction of progress, flowing from the past to the future.

@@<hr>
@@<div class="l_spacer"></div>
<037>
@@<h3><b>17. Belief</b></h3>

It is possible to compute the amount of belief in an idea.

Our minds are populated by various ideas. Some of them are considered fictitious, while others are considered real. We make such a distinction based upon the amount of belief in each idea.

Imagine that an idea is preceded by a chain of causes (i.e. causal relations). The longer and more vivid the chain is, the more we are convinced that the idea is "real". And the shorter and less vivid the chain is, the more we are convinced that the idea is "fake".

Thus, the total amount of belief in an idea is the sum of vivacities of its preceding ideas, plus its own vivacity.

An impression (i.e. external stimulus) is "real" because, although it is not preceded by a chain of causes, its own vivacity is so sufficiently high that it easily conjures up a strong sense of belief.

@@<hr>
@@<div class="l_spacer"></div>
<038>
@@<h3><b>18. Conditional Probability</b></h3>

When a cause is given, how do we measure the probability of occurrence of each of its effects?

Our minds are filled with ideas, and ideas usually represent events. Our belief in the occurrence of an event possesses its own numerical quantity, which can be computed by the "Belief(X)" function where X is the event of interest.

Given a cause, we say that the probability of occurrence of one of its potential effects is the proportion of the belief in the given effect with respect to the sum of the beliefs in all the potential effects.

The more frequently we observe an event, its vivacity increases. And the less frequently we observe an event, its vivacity decreases.

Since the amount of belief in an event is the sum of the vivacities of its history, we can say that more observation yields higher probability and less observation yields lower probability.

@@<hr>
@@<div class="l_spacer"></div>
<039>
@@<h3><b>19. Attention</b></h3>

A person's attention is a pointer which points to an idea.

Ideas, which fill up the mind's mental space, stay inactive as long as they are being neglected. It is because their vivacity levels are zero by default.

When an external stimulus enters the person's sensory organ, an impression gets created. It sticks itself to the corresponding idea and breathes vivacity into its mouth, thereby making it alive.

At the same time, the impression attracts the mind's attenion and induces it to point to the idea. The impression soon dies out (due to the cooling down of the stimulus), but the attention remains for a while, cogitating the idea to which it was summoned.

@@<hr>
@@<div class="l_spacer"></div>
<040>
@@<h3><b>20. Attention's Job</b></h3>

A person's mind contains at least one active agent of cognition called "attention". An attention points itself to one idea at a time.

There may as well be multiple attentions navigating the person's mental space concurrently. If it is the case, we will refer to them as "primary attention", "secondary attention", and so on.

An attention performs two major jobs while it is pointing to an idea.

(1) It connects the idea with nearby ideas. In physical space, such a connection is called "contiguity". In conceptual space, such a connection is called "resemblance".

(2) It boosts up the vivacity level of the idea.

The more we pay attention to certain ideas, the more vivid they get. This, in turn, strengthens our belief in these ideas.

Ceremonies and rituals are important in human society because citizens need to share a set of common beliefs. Such activities basically "recharge" the vivacity levels of a set of ideas, ensuring that their connections are firmly fixed in our minds.

@@<hr>
@@<div class="l_spacer"></div>
<041>
@@<h3><b>21. Attention Shift</b></h3>

The dots you see here are ideas. Ideas can be connected to each other (denoted by line segments) if they are either contiguous in physical space or if they resemble each other in conceptual space.

The mind contains a self-moving agent called "attention" which constantly crawls the vast network of ideas and their connections, boosting their vivacity levels.

Each idea possesses its own "belief" number. This number tells us how strongly the mind believes in the existence of the idea.

When the attention encounters multiple alternative pathways through which it can move, it tends to move toward nearby ideas with higher beliefs than those with lower beliefs.

Over time, this tendency forces only a few strongly believed ideas to survive and all the other ideas to die out. It is reminiscent of gas clouds in space gradually being condensed into a few dense balls of mass (i.e. planets).

@@<hr>
@@<div class="l_spacer"></div>
<042>
@@<h3><b>22. Thinning of the Cloud</b></h3>

A person's mind is like a galaxy; it is a dense celestial body of innumerable ideas, all shining desperately to be embraced by the attention of the consciousness.

The mind must pay attention to an idea at least occasionally in order to keep it alive. Otherwise, its vivacity will decrease over time and, once it reaches zero, it will kill the idea.

Unfortunately, the mind can pay attention to only a small number of ideas at a time. So, even if the mind happens to have a vast cloud of ideas (due to a sudden appearance of a huge number of external stimuli, for instance), time will eventually do its job of "thinning out" such a cloud into a rigid skeleton of only a selected few ideas which are deemed way more important than others.

@@<hr>
@@<div class="l_spacer"></div>
<044>
@@<h3><b>23. Plenum and Vacuum</b></h3>

Hume's rejection of the infinite divisibility of matter in our minds eventually leads us to the conclusion that ideas must be discrete and finite in nature.

The reason is simple. A brain does not possess infinite processing power, so it cannot possibly perceive an infinite number of ideas.

Therefore, our mental space must be discrete (i.e. not continuous), and must be enclosed by finite boundaries beyond which no further ideas are conceivable (We cannot see things whiter than white itself, for instance).

What this means is that there must be a "minimum distance between ideas". No two distinct ideas can ever be closer than this.

If a pair of ideas separated by the minimum distance are connected to each other (either via the relation of contiguity or resemblance), we can define this interval as the most basic unit of "plenum" (i.e. filled space).

If a pair of ideas separated by the minimum distance are disjoint from each other, we can define this interval as the most basic unit of "vacuum" (i.e. empty space).

@@<hr>
@@<div class="l_spacer"></div>
<045>
@@<h3><b>24. Idea Field</b></h3>

Since ideas are discrete, we can imagine the mind as a vast field of ideas which are placed at regular intervals. The size of each interval is the minimum distance allowed between a pair of ideas.

Most of these ideas, however, are in sleep because their vivacity levels are zero. The mind cannot perceive them because they "do not exist".

External stimuli, which enter the mind via sense organs, give birth to impressions. These impressions, in turn, pump up the vivacity levels of their respective ideas.

The vivified ideas attract the mind's attention. The attention, then, connects these ideas by "smearing" their fluids of vivacity toward each other. If they are too far apart, however, there won't be enough vivacity to spread and the connection will fall short.









:d:Possible usage of Peter Gärdenfors' two-vector event model in the design of gameplay systems.
:k:Peter Gärdenfors, Cognitive Science, Causality, Causation, Causal Loops, Systems Thinking, System Dynamics, Game Design, Game Mechanics, Game Systems, Philosophy, Epistemology, Russell, Hume, Gameplay Systems Design, Technical Design, Lund University
:l:2024-07-28

[Game Design using Gärdenfors' Event Model] July 28, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Introduction</b></h3>

When developing a game, one of the biggest challenges that the developer often encounters is the problem of implementing complex gameplay systems.

A large-scale game project often involves various in-game events, such as instantaneous actions (e.g. malee attack), firing of projectiles, casting of spells (i.e. status conditions), area effects, upgrades, and many others. It is not so easy to make sure that all these events will coexist in harmony, due to undesired side effects which might be caused by factors such as: (1) Race condition, (2) Combination of multiple events, (3) Criteria for deciding whether an event should be applied or not, and so on.

Professor Gärdenfors, who is both a cognitive scientist and a philosopher at the University of Lund (Sweden), has introduced a structurally elegant model of events and their internal causal relations. It is called the "Two-Vector Model", and it leverages vector quantities as means of specifying the cause and effect of an event. In other words, his model defines an event as an instance of vector transformation.

What I have personally noticed is that his event model works beautifully in the context of game development. Many of the complexities which are prone to arise in gameplay systems can easily be mitigated (or even avoided) by applying the two-vector model, due to the fact that it lets us nicely encapsulate each gameplay event's causal relation as a simple algebraic operation.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>The Two-Vector Event Model</b></h3>

<049>

According to Professor Gärdenfors' definition of cause and effect, an event can be thought of as a vector function which takes a vector as the input and returns another vector as the output.

In the two-vector event model, the input is a "force vector" and the output is a "result vector". Imagine that there are two separate entities in the world - agent and patient. The agent is the one who causes the event, and the patient is the one who is being affected by the event. Once the event kicks in, the patient receives the force vector (aka "cause") that was emitted by the agent, and yields its own result vector (aka "effect").

The result vector should be able to represent any type of change, but the easiest way to understand it (from the point of view of classical mechanics) is to simply assume that it represents an offset in the patient's position. So if you (i.e. agent) hit a ball (i.e. patient) with the force of 1N and let it move by 1m, you may say that the force vector is (1N, 0N, 0N) and the result vector is (1m, 0m, 0m) in 3D space.

Gärdenfors, however, does not necessarily confine the force and result vectors solely to the physical domain. In his model of events, a "position" may as well refer to the quality of the patient (e.g. color, temperature, emotional state, etc), and a "force" may as well be considered a force which modifies the quality. For instance, an act of painting can be considered an application of a "color-changing force" to the patient, which subsequently pushes the patient's position in color space (e.g. RGB) to the desired color location.

<050>

Gärdenfors' event model differs from more traditional models of causation due to its nature of self-encapsulation. It has widely been presumed that the so-called "causation" is simply a relation between events, and that each event is more or less just a "snapshot" of how things look like at each moment. In Gärdenfors' model, on the other hand, each event contains its own cause-and-effect relation, defined in terms of agent, patient, force, and result. The agent and the force it emits can altogether be considered the "cause" of the event, while the patient and its result of receiving the emitted force can altogether be considered the "effect" of the event.

I think the most prominent advantage of modeling an event this way is that it allows us to apply the notion of causation inside the event itself rather than in terms of its relation with other events. In computer science, such a form of conceptualization nicely fits the OOP (Object-Oriented Programming) paradigm, where each object defines its own behaviors within its own body. So for example, in a typical object-oriented programming language such as Java or C#, it is oftentimes convenient to define "Event" as a class, and assume that its force-to-result vector transformation procedure (i.e. causal relation) will be implemented as the class's member function.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>An Alternative Interpretation</b></h3>

<051>

As a side note, I would like to briefly introduce yet another mathematical interpretation of an event. In his paper on event structure and force dynamics (See Fig 11 of {%a href="https://www.sciencedirect.com/science/article/pii/S038800012300075X"%}"Event structure, force dynamics and verb semantics"{%/a%}), Gärdenfors explains Croft's alternative definition of causality. According to Croft, a cause-and-effect relation between forces can be explicated as the propagation of a "causal signal" across the dimension of causality. What's really interesting in this worldview is that it imagines "causality" as yet another dimension in spacetime, via which various worldly phenomena (i.e. events) establish causal links with one another.

This philosophically fascinating design, however, requires both the force vector and the result vector to reside in the same set of dimensions, thereby disallowing the result vector from identifying itself as part of its own hypothetical space which is of a different type from that of the force vector. This apparent lack of expressive freedom, I think, is one of the reasons why this unified spatial representation of causality is not so widely used.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>A Linguistic Interpretation</b></h3>

<052>

In {%a href="https://www.researchgate.net/publication/352868530_Causal_Reasoning_and_Event_Cognition_as_Evolutionary_Determinants_of_Language_Structure"%}"Causal Reasoning and Event Cognition as Evolutionary Determinants of Language Structure"{%/a%}, as well as the latter half of {%a href="https://www.sciencedirect.com/science/article/pii/S038800012300075X"%}"Event structure, force dynamics and verb semantics"{%/a%}, Gärdenfors suggests a possible usage of his two-vector event model as a device for explaining sentence structures in our language. An "event", according to him, can be expressed as an English sentence because it has its own subject (agent), verb (force), and object (patient).

Both the agent and patient can be described by nouns, yet adjectives and prepositions can also be leveraged as "filters" for specifying them more precisely. For example, in conceptual space (aka "feature space" in machine learning and artifical intelligence), a noun can be imagined as a voluminous region (which encloses a cluster of data points that are associated with that noun) and an adjective can be imagined as a thin plane which partially intersects such a region. A combination between a noun and an adjective (e.g. "black cat", "white rose", or "wooden jar"), therefore, indicates the intersection (i.e. a plane segment) between the noun's region and the adjective's plane.

Similarly, a preposition may as well function as a filter because it specifies a region in physical space with respect to the physical location (and direction) of the observer's point of reference. It "sorts out" any object which does not fall within the specified region.

The force and result vectors are expressible in terms of verbs. Here, a verb (or a "verb phrase" in general) can be defined as a vector transformation which maps a region in space to another region in space. These regions are specified by the sentence's subject and object, respectively.

Based upon these observations, Professor Gärdenfors suggests that we formulate our language in terms of events and their force-to-result (i.e. cause-and-effect) relations. In other words, our language is based on the way we cogitate causal relations.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Application in Game Development</b></h3>

A potential application of Peter Gärdenfors' event model can be found in the development of video games. When designing a gameplay system, a developer often finds it hard to construct the cause-and-effect relations of various in-game events (e.g. Attack, Heal, Stun, Knockback, Poison, Teleport, etc) without introducing too many layers of complexity. Gärdenfors' nicely encapsulated model of events solves this problem, and I am here to demonstrate why.

First of all, we need to take a look at the generalized form of the two-vector model in order to be able to leverage it for game design purposes. It is illustrated below.

<053>

Previously, I have shown that an event can be summarized as a combination of a cause (i.e. agent and the force it emits) and an effect (i.e. patient and the result it generates from the received force). In general, however, an event does not necessarily have to involve exactly one agent, one patient, and one force vector.

Whenever I walk on my own, I am both the one who exerts the force of movement (agent) and the one who is being moved by that force (patient). And whenever I happen to be pushed by two people simultaneously, I should consider both of them as the agents of the "push" event. Their force vectors will have to be added up to yield the net force vector, which will then be used by the event to compute the result vector.

Let me show you a simple gameplay scenario to explain why the concept shown so far is useful for gameplay systems design. Suppose that there is a role-playing game in which the player is a fantasy warrior traveling in a dungeon. There are currently 3 characters nearby, one of them attacking the player (i.e. Attacker) and the other two healing the player (i.e. Healer A and Healer B). The player has a health bar which shows his current health. Each attacker decreases the health, and each healer increases the health.

<054>

In the two-vector model, it is necessary to represent this simultaneous presence of attacking/healing effects as a combination of force vectors. Imagine that there is a hypothetical space called "force space" in which all the contributing forces of the event reside (The idea of representing the force/result vectors in their own conceptual spaces is illustrated in {%a href="https://www.sciencedirect.com/science/article/pii/S038800012300075X"%}"Event structure, force dynamics and verb semantics"{%/a%}). When an event kicks in, these contributing forces all add up to yield a single net force vector. This net force vector, then, gets mapped into its corresponding result vector. The result vector exists in another hypothetical space called "result space".

<055>

In the case of the player's health-changing event, we should consider the force space as the spectrum of all health-changing force values. So if the force is 0, you are doing nothing to the player's health. If the force is 1, you are increasing the player's health with the strength of 1 (This is what "healing" does). If the force is -1, you are decreasing the player's health with the strength of 1 (This is what "attacking" does). And so on.

The attacker applies the health-changing force of -1 to the player, while each of the two healers applies the health-changing force of 1 to the player. The net force is (-1) + 1 + 1 = 1, so we will conclude that the overall health-changing force that the player receives must be 1.

<056>

The health-changing event system, then, should be expected to take this net force vector (= 1) and transform it into its corresponding result vector which characterizes the change in the player's health (aka "ΔHealth"). Mathematically, such a process of transformation can be carried out by plugging the net force vector (as the input parameter) into the function called "transfer function", which basically shows us the one-to-one correspondence between force vectors and their result vectors.

Once the transformation part is complete, the only task remaining is to add the result vector (ΔHealth) to the player's current health. This is essentially what the player's health-changing event does whenever it executes itself.

But of course, one might be confused and say, "Dude, why do you overthink it? Just keep it simple. Simple is best. All you need to do is increase the player's health by 1 whenever a healer heals, and decrease it by 1 whenever an attacker attacks. You don't need such a fancy framework to do that!"

I am pretty sure that this is the exact kind of response which will be asserted a thousand times by a group of parrots unless I come up with a slightly more advanced example to show you the complexity of the issue. So here is an additional example.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Status Conditions</b></h3>

<057>

Suppose that there is also a wizard who is casting a spell on the player. This spell is called "heal-blocker spell", and while it is affecting the player, it prevents him from being healed. How shall we implement this this?

A naive approach is to put a conditional statement inside the the gameplay logic, such as: "IF (the player is being affected by a heal-blocker spell), THEN (do not heal the player)". This might be a decent solution for small games. If the game happens to involve a hundred (or even more) types of spells, however, a decent developer will agree that hard-coding their effects using a bunch of conditional statements is not an okay way to do it.

A much more scalable way of implementing a spell (aka "status condition") is to define it as a modifier of an event's transfer function.

<058>

The default transfer function of the player's health-changing event is the identity function ("f(x) = x"). It gracefully handles both the force of heal and the force of attack because, whenever the force is a positive number (heal), the health will change in the positive direction with the rate that is proportional to the magnitude of the force, and whenever the force is a negative number (damage), the health will change in the negative direction with the rate that is proportional to the magnitude of the force. This is exactly what we would expect the health-changing event to do every time it receives a force.

When the player is under the influence of the health-blocker spell, however, such a transfer function is no longer valid because the player shouldn't be healed when he receives a healing force. Therefore, we must zero out the right half of the transfer function to enforce such a condition. And how do we do that? There are multiple ways, but the easiest one is to "add" another function to the transfer function which, after the addition, will cancel out the healing behavior of the original transfer function.

This additive approach is quite elegant because it is incredibly easy to undo the process of addition. Whenever we add the spell, we simply add the spell's modifier function to the player's current transfer function. Whenever we remove the spell, we simply remove (subtract) the spell's modifier function from the player's current transfer function. Since subtraction is the exact inverse of addition, no information will be lost and all the external factors (i.e. anything that is not part of the spell) will be preserved no matter how many times we add/remove the spell to/from the player.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Thresholding</b></h3>

<059>

Another application of the two-vector event model can be found in success-or-fail (aka "binary") scenarios, such as trying to let the character jump up a steep hill in order to proceed to the next stage. Imagine that there is a hill right in front of the player, and that the player is trying to reach the top of the hill by jumping. The player's current altitude is 0, and it will be shifted up to 1 once he successfully reaches the top.

<060>

Just like we did in the previous example, we can use the two-vector event model for the problem of jumping. Unlike in the case of attacking and healing, though, we will now begin to assume that the force space refers to the range of "jump forces" (where high magnitudes denote powerful jumps and low magnitudes denote weak jumps), and that the result space refers to the change in the player's altitude after the jump.

The jump event has its own transfer function which is not an expression of proportionality between two variables, but a "threshold condition" which tells us how strong the player's jump must be in order to let him reach the top of the hill. In this example, at least the force of magnitude 2 is required to accomplish such a goal.

The main benefit of threshold-oriented gameplay scenarios (where you either CAN or CANNOT do something, not somewhere in between) is that it allows you to impose upon the player a specific set of keys which must be utilized in order to unlock his/her way out of the obstacle. If the hill were a smooth surface, for example, the player would've been able to climb it up by paying just a bit more effort and time. Under a strict yes-or-no condition, on the other hand (e.g. locked door, unreachable height, uncrossable river), it becomes possible to force the player to follow an absolute requirement such as: "You MUST have this item in your inventory in order to finish this task". This prevents the player from completing the whole game based solely upon brute-force and enough patience.

<061>

In his article on force dynamics (See {%a href="https://www.sciencedirect.com/science/article/pii/S038800012300075X"%}"Event structure, force dynamics and verb semantics"{%/a%}), Gärdenfors shows us that an event's force vector can be classified into one of the following categories under the presence of a goal - "Enable", "Help", "Prevent", and "Despite". The "Enable" force, when added to the patient's current force vector, allows him/her to achieve the desired result which was unachievable before. The "Help" force is similar to the "Enable" force, except that its presence is not absolutely necessary because the patient is already able to achieve the desired result (with just a bit of additional time and effort). The "Prevent" force is the opposite of the "Enable" force because it disables the patient from achieving the goal which would have been achievable otherwise, and the "Despite" force is the opposite of the "Help" force.

Such categorization of forces is definitely feasible in a threshold-based scenario, such as the problem of jumping to reach the top of the steep hill. For example, if the player's initial jump force is only 1 and there is a "booster" item in the inventory which he/she can consume in order to add an extra boost of 1 to the jump force (which will achieve enough level of force to reach the top of the hill), we will be able to tell that this item is the "enabler" of the player's hill-mounting event. This way, we are able to sort various items, abilities, spells, and other numerous in-game factors into the four major categories (i.e. Enable, Help, Prevent, and Despite) and implement them appropriately based on how their presence will affect the progression of the game in binary (i.e. threshold-driven) gameplay scenarios.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Data-Driven Design</b></h3>

Many of you who have implemented large-scale gameplay systems may have heard of the term, "data-driven". It is one of the most popular design philosophies in game development, in which the game's rules are specified in the form of declarative statements (e.g. data tables, English sentences, block diagrams, etc) instead of being hard-coded as part of the game's script itself.

Gärdenfors' event model nicely fits the spirit of data-driven gameplay design, due to the fact that it allows us to fully describe an event and its causal relation in the form of a plain English sentence (i.e. a declarative statement), instead of a bunch of conditional and iterative statements which are intertwined with one another (See {%a href="https://www.researchgate.net/publication/352868530_Causal_Reasoning_and_Event_Cognition_as_Evolutionary_Determinants_of_Language_Structure"%}"Causal Reasoning and Event Cognition as Evolutionary Determinants of Language Structure"{%/a%}). Engineers who have studied a logic programming language (e.g. Prolog) will instantly grasp the beauty of this, as well as how neatly it is going to mitigate many of the design complexities which tend to arise in gameplay engineering.

As long as we manage to express gameplay events as English sentences, we will be able to summarize all gameplay rules simply as a list of sentences and hardly anything else.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Event as a List Processor</b></h3>

The examples I have shown so far are only one-dimensional - that is, each force space or result space is only a single number line, made up of a single variable (e.g. "change in health", "change in altitude", etc). However, this is just for the ease of visualization (because it is easier to draw 1D and 2D graphs than ones which are 3D, 4D, etc). In general, each force space or result space should be allowed to possess any number of dimensions, which may be spatial (x, y, z), temporal (t), or qualitative (e.g. color, temperature, health, mana, dexterity, experience, anger, happiness, attack strength, defense strength, and so forth).

Designing a transfer function which maps a multidimensional force vector to a multidimensional result vector is indeed a difficult thing to do. If you consider each vector as just an array of numbers (e.g. "int[]"), however, you will be able to tell that the two-vector event model is nothing more than a "list-mapping process" - a generic system which takes a list of numbers as the input, and generates another list of numbers as the output. One of the easiest ways of designing such a system is to treat each element of the output list as a linear combination of the elements of the input list. This lets the system's transfer function be constructed as a simple matrix multiplication, which is something your graphics card (GPU) can do extremely well.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Special Thanks</b></h3>

<062>

I would really like to thank Katarina Gyllenbäck for introducing the works of Professor Gärdenfors. I would have not had a chance to delve into his profound insights in the field of cognitive science, if she did not introduce his papers in her articles.

Katarina Gyllenbäck, who is both a narrative designer and a researcher of interactive media, has shown me a narrative-driven interpretation of Gärdenfors' two-vector event model. It is most thoroughly illustrated in her description of conceptual space in the article, {%a href="https://katarinagyllenback.com/2023/03/16/part-11-the-meaning-makers-space/"%}"Part 11, The Meaning-Maker's Space"{%/a%}.

To learn more about her areas of insight, please visit {%a href="https://thingspool.net/read-rec/page-2.html"%}Here{%/a%} to see my review of her writings on narrative design. Or, you may want to visit her website and read her vast collection of articles {%a href="https://katarinagyllenback.com"%}Here{%/a%}.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Bibliography</b></h3>

1. {%a href="https://www.sciencedirect.com/science/article/pii/S038800012300075X"%}Event structure, force dynamics and verb semantics{%/a%} by Peter Gärdenfors (This article most accurately summarizes the mathematical pattern behind the causal relations of the two-vector event model.)

2. {%a href="https://www.researchgate.net/publication/352868530_Causal_Reasoning_and_Event_Cognition_as_Evolutionary_Determinants_of_Language_Structure"%}Causal Reasoning and Event Cognition as Evolutionary Determinants of Language Structure{%/a%} by Peter Gärdenfors (This one most thoroughly describes the linguistic interpretation of the two-vector event model, explaining why an event can be considered a sentence and each element of the event can be considered a phrase such as a "noun phrase", "verb phrase", etc)

3. {%a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2020.584017/full"%}Primary Cognitive Categories Are Determined by Their Invariances{%/a%} by Peter Gärdenfors (This is a great introductory text to the idea of "Conceptual Space" - a hypothetical space which expresses the qualitative attributes of an object as a point in geometry. It also explains how a set of invariances in our domain of cognition (i.e. a dense cluster of sense-data) eventually manifest themselves in the form of a discrete entity called "object". This is one of the most foundational ideas in the study of artificial intelligence and machine learning (often referred to as "pattern recognition").)

4. {%a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2020.00630/full"%}Events and Causal Mappings Modeled in Conceptual Spaces{%/a%} by Peter Gärdenfors (This is a general overview of how the force and result vectors are related to one another in an event. In this paper, Professor Gärdenfors tells us various subleties that are involved in the dynamics of causality, such as the capacity of the human mind to perform interpolation between two force vectors (which means that the total domain of forces which can be formed by a set of basis force vectors is their convex hull), etc.)

5. {%a href="https://www.researchgate.net/publication/322314237_From_Sensations_to_Concepts_a_Proposal_for_Two_Learning_Processes"%}From Sensations to Concepts: a Proposal for Two Learning Processes{%/a%} by Peter Gärdenfors (This article introduces some of the experimental results which show us that, during early childhood development, young children do manage to learn how much an object (i.e. a cluster of data points) differs from another object (i.e. another cluster of data points), but not necessarily the direction (i.e. dimension) in which they differ. It is only later stages in life during which they acquire the ability to break down each object as a product of multiple dimensions and make comparisons based upon individual dimensions, not only in terms of the overall distance between two clusters of data).






:d:A computational interpretation of Good and Evil.
:k:Good and Evil, Dichotomy, Dualism, Binarism, Philosophy, Computational Philosophy, Computational Ethics, Ethics, Monotheism, Theology, Theism, Theosophy
:l:2024-07-30

[Good and Evil] July 30, 2024

This is a computational interpretation of Good and Evil, as well as how to model their dynamics using vector math. This is useful for technical systems design in the development of computer games.

@@<hr>
@@<div class="l_spacer"></div>
<018>
@@<h3><b>Heaven and Hell</b></h3>

Good and evil are measurable quantities.

There are three points in space - the center of Heaven, the center of Hell, and the center of the world.

The center of Heaven is the best possible state of the world; it is the pivot of pure good.

The center of Hell is the worst possible state of the world; it is the pivot of pure evil.

The center of the world belongs to neither of these two pivots. It represents the current state of the world, which is a mixture between both good and evil. Therefore, it is located somewhere between Heaven and Hell.

Both Heaven and Hell are perfect spheres. The radius of Heaven is the radius of its spherical event horizon (i.e. threshold beyond which the world can no longer escape from the volume of Heaven), and the radius of Hell is the radius of its spherical event horizon (i.e. threshold beyond which the world can no longer escape from the volume of Hell).

The amount of good in the world is its distance from Hell, minus its distance from Heaven. The farther away the world is from Hell, the more "good" it is. The closer the world is to Heaven, the more "good" it is.

The opposite scenario applies to the amount of evil in the world; it is the world's distance from Heaven, minus its distance from Hell.

@@<hr>
@@<div class="l_spacer"></div>
<019>
@@<h3><b>Goodness of Movement</b></h3>

There are three regions in space - Heaven, Hell, and the world in which we live. All three of them have their own center positions.

The world can either be moving toward Heaven, toward Hell, or somewhere in between. A movement directed toward Heaven is a "good movement", and a movement directed toward Hell is an "evil movement".

The world's movement is characterized by its velocity vector. This vector tells us how fast and in which direction the world is currently moving.

Suppose that there is a unit vector which starts from the center of the world and points directly to the center of Heaven. This indicates the best direction in which the world can ever move with respect to Heaven.

Furthermore, suppose that there is yet another unit vector which starts from the center of the world and points directly away from the center of Hell. This indicates the best direction in which the world can ever move with respect to Hell.

Combine these two unit vectors together and you will get the best direction of movement with respect to both Heaven and Hell.

If you compute the dot product between this vector and the world's velocity vector, you will obtain the degree of how good the world's velocity is.

@@<hr>
@@<div class="l_spacer"></div>
<020>
@@<h3><b>Thermostat's World</b></h3>

How to calculate the position of Heaven and Hell? It really depends on the definition of our world.

A world made up of a single thermostat dwells in a one-dimensional space which represents the full range of temperatures. The center of the world refers to the current temperature.

This one-dimensional space's lower edge indicates the lowest temperature that the thermostat can ever reach. It is one of the two centers of Hell (i.e. It is the center of the headquarter of Hell's ice department).

In contrast, the upper edge indicates the highest temperature that the thermostat can ever reach. This, too, is one of the two centers of Hell (i.e. It is the center of the headquarter of Hell's fire department).

The center of Heaven is the thermostat's most ideal temperature (i.e. Temperature that the thermostat is ordered to reach).

@@<hr>
@@<div class="l_spacer"></div>
<021>
@@<h3><b>Force of Morality</b></h3>

Measurement of the force of morality starts from the realization of our best desire.

The center of the world is constantly moving. The rate at which it simultaneously approaches Heaven and escapes Hell indicates the overall goodness of its movement.

The best velocity of the world is its most optimal direction of movement (That is, the direction which decreases the distance between the world and Heaven and increases the distance between the world and Hell as quickly as possible), scaled by the maximum possible speed of the world.

Our best desire is the direction which guides the world's current velocity to its best velocity as quickly as possible. If you multiply it by the world's overall amount of morality, you will get the force of morality which is currently pushing the world.

@@<hr>
@@<div class="l_spacer"></div>
<024>
@@<h3><b>Multiple Eras</b></h3>

The world's timeline consists of multiple eras. As time passes by, the world advances from one era to the next in a sequential manner.

Each era has its own Heaven and Hell, meaning that the amount of good (or evil) in the world is determined by the particular era in which we live.

Once the world enters Heaven 1 during Era 1, the era changes from Era 1 to Era 2. Then, once the world enters Heaven 2 during Era 2, the era changes from Era 2 to Era 3.

If Era 3 is the last of all eras, the world will finally merge with Heaven 3 (i.e. the final Heaven) after entering it.

On the other hand, entering the current era's Hell brings the world back to its previous era instead of the next.

As a side note, it is also feasible to connect the last era to the first era, thus forming an infinite loop of eras. In this case, time will be eternal and the world will keep on moving in its orbit forever.








:d:This a new way of designing biology-inspired emergent systems, based upon Glenn Puchtel's biocybernetic theory. It encompasses the construction of artificial life, artificial mind, virtual ecosystems, wetware, and other nature-inspired phenomena, based on ideas such as Systems Thinking and Unconventional Computing.
:k:Glenn Puchtel, Emergent Systems, Control Systems, Feedback Loop, Control Theory, Cybernetics, Biocybernetics, Swarm Intelligence, Software Design, Software Architecture, System Dynamics, Systems Thinking, Systems Engineering, Signal Processing, DSP, Communication Systems, Communication Network, Wetware, Unconventional Computing, Unconventional Cognition, Cognitive Science
:l:2024-08-02

[Emergent Systems based on Glenn Puchtel's Biocybernetic Theory] August 2, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Introduction</b></h3>

If you are a software engineer, you will probably agree that designing a well-organized system is a necessary step in the development of an application. Not that many engineers, however, agree that the system must be "emergent" in order for us to maximize its robustness as well as resilience.

It is probably true that emergence is not a necessary ingredient when it comes to creating a rather static, single-purpose program. When it comes to highly dynamic applications such as simulations and video games, though, we cannot help ourselves realizing that the sheer complexity of the system we are dealing with is not something which can be thoroughly grasped by the developer's intellect alone.

A large-scale application with its own adaptive behaviors is oftentimes too complex in nature, that the developer is inevitably led to the conclusion that the system must be broken down into smaller subsystems. Such a divide-and-conqure approach comes in handy especially when a fairly large team of developers are simultaneously working on the same codebase (Modularization helps us reduce interdependencies, for example).

There is a much more profound advantage in the aforementioned design philosophy, however, and it is often referred to as "emergence". As you might have already guessed, expressing a system as a group of multiple subsystems (rather than a single, monolithic blackbox) is a good idea not only because it makes it easy for developers to tackle each individual part separately, but also because the collective behavior of such subsystems makes room for what we would like to describe as "swarm intelligence" - an army of relatively dumb agents which, when coordinated under a common goal, display surprisingly robust and resilient phenomena (e.g. self-recovery of a multicellular organism).

Such a multi-agent system is called "emergent", due to the fact that its complexity is something which emerges out of simpler elements, rather than something which was carved like a rigid sculpture by the developer.

<a0_1>

Glenn Puchtel, who is an interdisciplinary software architect with expertise in system dynamics and cognitive science, has introduced a set of novel concepts in the design of emergent systems. Explained in the context of cybernetics, these concepts tell us that they can be used as building blocks of what may be termed "artificial biological organs" - modules that a cyborg would attach to its body in order to adapt itself to the surrounding environment.

In the following sections, I will be illustrating a collection of Glenn Puchtel's ideas which are indispensable for the construction of emergent systems. They are inspired by some of his major articles, which are listed below:

1. {%a href="#bibliography_1"%}"Cybernetic-Oriented Design (CyOD)"{%/a%}
2. {%a href="#bibliography_2"%}"Coordination without (direct) Communication"{%/a%}
3. {%a href="#bibliography_3"%}"Cybernetic Waves"{%/a%}
4. {%a href="#bibliography_4"%}"Reaction Networks"{%/a%}
5. {%a href="#bibliography_5"%}"Biological Models of Reactionary Networks"{%/a%}
6. {%a href="#bibliography_6"%}"Temporality"{%/a%}
7. {%a href="#bibliography_7"%}"Bio-Cybernetic Patterns"{%/a%}

These articles, however, are not the only ones he has written. If you want to read more of his works, please visit his LinkedIn newsletter: {%a href="https://www.linkedin.com/newsletters/cyborg-bio-cybernetics-6879770834110689280/"%}"Cyborg - (bio)cybernetics"{%/a%}.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>1. Separation of State and Behavior</b></h3>

Glenn Puchtel begins his introduction to cybernetic-oriented design with the notion of "separation of state and behavior" {%a href="#bibliography_1"%}[1]{%/a%}. Programmers who have learned OOP (Object Oriented Programming) will remember that a system (i.e. "object") is practically a blockbox which encapsulates both a behavior and a state. This is quite syntactically apparent in a class declaration, where the member functions characterize its behavior and the member variables characterize its state.

People who dislike OOP may insist that the very idea of wrapping both a behavior and a state inside the same container called "object" is a bad decision, since the mixture of these two drastically different elements is prone to spill nasty side effects such as race conditions and deadlocks.

This, however, is not really an intrinsic aspect of OOP, but rather a result of misunderstanding the way this paradigm should be handled. Most of its undesirable side effects can be attributed to the lack of enough separation between systems (objects), not the lack of a thick, gigantic wall which segregates everything into two global zones - one containing all the functions (behavior), and the other one containing all the state variables.

It is okay to let each system have its own behavior AND its own local state. After all, a system without any state is memoryless, and the range of actions that a memoryless system can take is extremely limited (since it is only able to react to the current input and none of the previous inputs).

One of the main sources of OOP's complexity problem is one's attempt to pack too many functionalities in a single object. Such a mistake can be prevented by making each object as simple as possible. However, we should also take care not to use this design approach as a means of justifying tight coupling (i.e. direct communication) among objects which are functionally closely related.

<a1_1>

Tight coupling might be okay to have if we are dealing with just a few objects. If there are too many of them, the overall architecture will start to degenerate into a jungle of entangled, disorderly web of communication.

<a1_2>

So, what's the solution? The key lies on Glenn Puchtel's concept of "coordination without direct communication" {%a href="#bibliography_2"%}[2]{%/a%}. I will explain it in detail throughout the upcoming sections.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>2. Indirect Communication</b></h3>

If you have looked at Glenn Puchtel's bio-inspired systems (i.e. biocybernetic systems) {%a href="#bibliography_5"%}[5]{%/a%}, you will be able to tell that they do not allow their biological subsystems (e.g. cells) to share information simply by directly invoking each other's member functions. Instead, these subsystems communicate via a "medium" - a chemical mixture which exists somewhere in space and decays over time. Such a medium continuously emits waves {%a href="#bibliography_3"%}[3]{%/a%}, which are signals waiting to be picked up by nearby systems (e.g. neighboring cells) and be processed according to their own behavioral logic (i.e. goal + rules).

<a2_1>

What I just mentioned is the essence of indirect communication. Instead of directly feeding signals to each other (which creates dependency), systems can instead talk to each other by means of a medium. A medium could be interpreted as some form of "shared state" among multiple systems, yet we should also be aware that it carries its own behavior as well (e.g. continual emission of waves, interaction with environmental factors, etc). Such a dual aspect, combined with the architect's demand for structural consistency, eventually leads us to conclude that the place which holds a medium is itself yet another system, composed of its own state and behavior.

(For a specific example, please refer to the component called "Pipe" in Glenn Puchtel's article, "Biological Models of Reactionary Networks" {%a href="#bibliography_5"%}[5]{%/a%}.)

<a2_2>

This is analogous to typical communication networks which we use daily. Our cellphones exchange data by means of cellphone towers, and out personal computers exchange data by means of servers and routers (which altogether constitute the internet). Two most widely known benefits of such a networking scheme are: (1) Reduction of the number of connections between nodes, and (2) Simplification of the overall topology of the connections.

In Glenn Puchtel's biocybernetic design philosophy, however, he reveals yet another major advantage of indirect communication - scoping of information.

In the "Space (scope)" and "Time" sections of his article, "Coordination without (direct) Communication" {%a href="#bibliography_2"%}[2]{%/a%}, Glenn Puchtel mentions that "giving individuals access to too much information may lead to sensory overload", suggesting that limiting the scope of information is crucial.

He says that it can be achieved by using a medium as the gateway of communication. As long as a medium occupies only a limited region in space and time, systems which communicate via such a medium will be guaranteed to receive information which is only relevant to the local region to which they belong.

The importance of scoping eventually leads us to the conclusion that the application as a whole should comprise multiple layers of scope, which necessitates the notion of a "hierarchy".

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>3. Hierarchy of Systems</b></h3>

When developing a large-scale application, a hierarchical worldview oftentime helps. The reason behind this is not difficult to grasp; whenever the system we are required to implement is too complex, we feel the necessity to break it down to a collection of simpler subsystems, devise each of them separately, and then join them together to let them collaborate as a whole.

For instance, a biological organism is a complex system which can be broken down to a number of major subsystems such as the digestive system, circulatory system, respiratory system, nervous system, immune system, and so on. Since these subsystems are still pretty complex, we still have to break them down to even simpler subsystems, etc, in a recursive (tree-like) manner. This means that a complex system should be hierarchical in structure.

<a3_1>

(According to Glenn Puchtel, "Complex systems organize themselves in hierarchical layers of abstraction-a structure achieved by encapsulating smaller, more specific systems within more extensive, more general systems" {%a href="#bibliography_1"%}[1]{%/a%}.)

In fact, we have already seen an example of hierarchical modeling in the previous section (i.e. "2. Indirect Communication"). When two systems are communicating through a medium, we may as well say that they are both physically bound to the same place to which the medium belongs. In other words, these two communicators should be deemed as two neighboring objects which are occupying the same region in space.

This is the simplest example of a hierarchy, in which the two communicating agents are the children of their common parent. In a way, therefore, one could claim that each branching point of a tree of systems is basically a place (i.e. a medium-provider) through which its subsystems are allowed to communicate, as though it is a LAN (Local Area Network).

<a3_2>

In general, a hierarchical breakdown of systems allows us to handle our problems via multiple layers of abstraction (where the root of the tree represents the most general (abstract) system, and each leaf of the tree represents the most specific (single-purpose) system). At the same time, it also lets systems communicate with one another by means of their parent systems, which means that they are able to transmit messages across multiple layers of the hierarchy.

("The result is the control or dynamic regulation of behavior between layers" - Glenn Puchtel {%a href="#bibliography_1"%}[1]{%/a%})

For example, suppose that we are modeling an animal's anatomy as a hierarchy of systems. And let us also suppose that cells are subsystems of a tissue and tissues are subsystems of a bloodstream (Note: I know that this is not an accurate reflection of how the body really works, but let's just ignore it for the sake of demonstration). If a cell wants to send a signal to another cell, it won't require a direct connection to that cell to do so. It will only release a chemical which will eventually be delivered to the other cell through the following steps:

(1) First, the cell's chemical will be absorbed by the surrounding tissue.
(2) The tissue will release the chemical to the adjacent bloodstream.
(3) The chemical in the bloodstream will be picked up by the other tissue.
(4) And finally, the other cell's receptor will receive the chemical's signal.

<a3_3>

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>4. Polymorphism</b></h3>

Glenn Puchtel's "separation of statics and dynamics" {%a href="#bibliography_1"%}[1]{%/a%} is an extremely useful concept not just for the sake of organization, but also for the sake of enabling polymorphism.

The foundation of polymorphism lies on the idea of decoupling. Glenn Puchtel mentions in his article that individual systems which are decoupled by knowledge "need not know about the other; only that stimulus introduction affects the state" {%a href="#bibliography_2"%}[2]{%/a%}. What he means by this is that the stimulus (information) can simply reveal its presence in a shared medium, exposing itself to nearby systems and hardly doing anything else. The individual systems, then, can pick up the stimulus from the shared medium and respond to it based on their own decision-making processes.

<a4_1>

The main advantage of polymorphism is that it enhances the modularity of systems. The sender of a stimulus does not have to care who the recipient is, or in which fashion the stimulus ought to be presented in order to fit the recipient's expectations. Those who want to receive it will receive it, and those who want to respond to it will respond to it. And the type of response is entirely up to the recipient's own behavior. The sender only needs to care about sending, and the recipient only needs to care about receiving.

Since a single type of stimulus is able to trigger different responses when detected by different types of recipients, the effects of its presence can be considered "polymorphic" - "poly" because it exhibits a one-to-many relationship (i.e. single input, multiple outputs), and "morphic" because the effects appear in distinct forms.

<a4_2>

A great example of polymorphism can be found in the case of ants and their pheromone-based communication. Glenn Puchtel says in his article that: "Just as the same pheromone elicits different behavior, whereby a worker ant might respond differently from a soldier ant, messages trigger receptors' behavior depending on their role" {%a href="#bibliography_2"%}[2]{%/a%}. Here, a pheromone is a stimulus (input signal) which triggers two separate responses when received by two different recipients (i.e. worker ant and solider ant).

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>5. Feedback Loops</b></h3>

Another benefit of indirect (medium-based) communication is that it allows us to create indirect feedback loops - i.e. long, circular chains of causality which control the flow of the overall system based on not only short-term effects, but also long-term effects (aka "Circular Causality", as mentioned by Glenn Puchtel in his introduction to cybernetic-oriented design {%a href="#bibliography_1"%}[1]{%/a%}). Such a phenomenon is indispensable for the design of dynamics systems which involve multiple causal loops that are intertwined with one another, such as an ecosystem, a marketplace, an electrical grid, and many others which appear in the study of System Dynamics (aka "Systems Thinking").

<a5_1>

A direct (i.e. internal) feedback loop is something which can easily be constructed within the anatomy of the system itself; those of you who have studied systems engineering will probably know how to design such a thing. All you need to do is branch off the output signal, feed it into a stream of time-delay elements (just 1 delay element for a first-order system, or 2 delay elements for a second-order system, etc), and then use that stream as part of the subsequent input of the system. This is an example of how a system can leverage part of its own history of outputs as means of calculating its current input.

<a5_2>

An indirect (i.e. external) feedback loop, on the other hand, requires a collaboration of multiple systems. The output of a system in such a loop first leaves the system, enters another system, leaves that system too, enters yet another system, and so on, until its effect eventually comes back to the input port of the original system. This is how you can simulate long-term effects in complex systems, such as too much population growth eventually leading to more deaths due to food shortage, and so on.

<a5_3>

The most obvious way of implementing indirect feedback loops is to first draw a CLD ({%a href="https://en.wikipedia.org/wiki/Causal_loop_diagram"%}Causal Loop Diagram{%/a%}) and then devise systematic components (e.g. stocks and flows) based on its graph structure. This approach, however, forces the overall architecture to be static (i.e. hard to modify) due to the way it tightly couples its individual subsystems with each other.

Indirect communication offers a nice solution to this lack of structural flexibility. As long as the individual systems communicate only via their "shared pool of information" (i.e. medium), we will be free to either add an additional system to the pool or remove an existing system from the pool without invoking undesirable side effects. This allows systems to dynamically reproduce or destroy themselves as though they are part of a living organism, allowing the overall architecture to continuously modify its shape (which is indispensable for adaptive, self-regulatory behaviors).

Besides, medium-based communication is far superior to predefined communication routes when it comes to the creation of indirect feedback loops, due to one simple reason; a shared medium allows its members to indirectly influence each other in any order/combination, as illustrated in the diagram below.

<a5_4>

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>6. Divisibility means Resilience</b></h3>

Expressing the overall system as an assembly of numerous subsystems has yet another advantage to offer; it is the sense of resilience.

In the "Weight [measure]" section of his article, "Coordination without (direct) Communication", Glenn Puchtel mentions that "emergent systems favor small, lightweight, almost negligible parts; losing any part does not adversely affect the whole" {%a href="#bibliography_2"%}[2]{%/a%}.

What he means by this is that a system which is divisible in nature (i.e. able to cut some of its parts off and still manage to function) is capable of sacrificing small portions of itself for larger gains - a sign of flexibility. If the system were a single, inseparable unit, any risk which involves its loss would cost the total annihilation of the system and would have to be avoided entirely.

<a6_1>

In general, a divisible system is robust because it is composed of rearrangeable parts. Such a system can grow, shrink, and change its shape as needed, and is able to accept relatively minor risks (e.g. A lion hunts down a giraffe despite the risk of being injured, since it can regrow its damaged tissues).

(Look at "Apoptosis" in Glenn Puchtel's "Coordination without (direct) Communication" {%a href="#bibliography_2"%}[2]{%/a%}.)

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>7. Goal</b></h3>

There is one major factor in systems design which I haven't mentioned yet. It is "goal" - a sense of purpose. A system needs a goal to serve its designated role; otherwise there is no point in designing a system, unless all we want is an engineering equivalent of "art for art's sake".

<a7_1>

A goal is what drives the system's control mechanism. A goal-oriented system constantly strives to keep its current state as close to the desired state as possible; for instance, a thermostat's "goal" is to minimize the difference between its current temperature and the desired temperature.

("A goal-oriented system must actively intervene to achieve or maintain its goal" - Glenn Puchtel {%a href="#bibliography_1"%}[1]{%/a%})

For a simple system such as a thermostat, the goal is easy to define. It only requires us to state simple numerical relations, such as: "The difference between X and X0 should be kept minimal", and so on. In the case of a complex system whose goal is way too complicated to be fully explicated in such a manner, however, we need a somewhat more advanced way of defining goals. From my point of view, one of the best ways of illustrating a complex goal is to decompose it into a list of more specific goals (aka "subgoals"), decompose each of them into even more specific goals, and so on, thereby creating a hierarchy of goals. This is similar to the so-called "behavior tree" in video games.

What's interesting in this model of reasoning is that it is structurally analogous to a hierarchical arrangement of systems. In fact, this happy correlation is due to the intrinsic one-to-one correspondence between each system and the goal it is expected to serve (e.g. The root system serves the root goal, the left subtree's system serves the left subtree's goal, etc).

<a7_2>

Here is an example. An organism's goal is to survive. In this case, "organism" is the root system and "survive" is the root goal. The problem is that the words "organism" and "survive" are so broad in scope, that they fail to delineate all the necessary details.

Therefore, we must repeatedly break them down into more specific components, up until the moment at which we finally feel assured that everything is broken down to a set of "atoms" which do not demand further conceptual decomposition. In computer engineering, the atoms are primitive data types (e.g. char, int, float) and machine level instructions (e.g. MOV, ADD, MUL). In electrical engineering, the atoms are basic circuit components (e.g. transistors, capacitors, inductors).

In this example, the "survive" goal can be defined as a compound of 2 subgoals - "eat" and "breathe". Serving the "survive" goal is the same thing as serving both the "eat" and "breathe" goals. 

The hierarchy of systems can be expected to mirror the hierarchy of goals. Since the "survive" goal is the parent of its 2 child goals ("eat" and "breathe"), the organism (whose goal is to "survive") should be considered the parent of its 2 child systems which serve the "eat" and "breathe" goals, respectively. The first one is the digestive system, and the second one is the respiratory system.

<a7_3>

The presence of a hierarchy of goals helps us design the hierarchy of systems because these two have a direct one-to-one relationship (i.e. they are structurally identical). All we have to do is look at each of the goals and construct a system which fulfills that goal.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Bibliography</b></h3>

1. {%a id="bibliography_1" href="https://www.linkedin.com/pulse/cybernetic-oriented-design-cyod-glenn-puchtel/"%}Cybernetic-Oriented Design (CyOD){%/a%} by Glenn Puchtel (This introductory article outlines pretty much all the main concepts in the design of emergent systems, including: (1) Separation of state and behavior (which enables polymorphism), (2) Hierarchical arrangement of individual subsystems (which is a neat way of breaking down a complex system into a collaborative network of simpler systems), (3) Back-and-forth interaction between state and behavior, which gives rise to feedback loops, and so on.)

2. {%a id="bibliography_2" href="https://www.linkedin.com/pulse/coordination-without-direct-communication-glenn-puchtel/"%}Coordination without (direct) Communication{%/a%} by Glenn Puchtel (Reading this article is crucial for understanding the nature of emergence and how its full potential might be leveraged. Here, the author suggests "indirect communication" (i.e. communication by means of a medium, rather than by means of a direct and instantaneous feeding of signals) as a method of letting individual subsystems collaborate with each other in an implicit manner, which eventually reveals highly emergent patterns such as those we can find in cellular automata.)

3. {%a id="bibliography_3" href="https://www.linkedin.com/pulse/cybernetic-waves-glenn-puchtel/"%}Cybernetic Waves{%/a%} by Glenn Puchtel (This article suggests a chemistry-inspired method of designing a signal-transmitting medium in a cybernetic communication network. The author tell us that a "medium", a mixture of multiple chemical substances of varying saturations, along with several physical parameters such as temperature and pressure, can be placed in the environment, which in turn will emit waves (signals) to the surroundings for some limited duration.)

4. {%a id="bibliography_4" href="https://www.linkedin.com/pulse/reaction-networks-glenn-puchtel/"%}Reaction Networks{%/a%} by Glenn Puchtel (Here, the author directly shows us how to define a chemical mixture in a software simulation and use it as a medium of communication between virtual biological modules. He also suggests specific ways of interpreting the content of such a mixture for the purpose of evaluating/modifying the surrounding environment (aka "conditions" and "cures"). Additionally, the very last diagram of the article deserves special attention, since it summarizes the grand cycle of information flow in a cybernetic-oriented system. In this diagram, "signals" is where an organism receives information, "rules" and "states" are where the organism evaluates and stores the received information, and "actions" is where the organism emits actions based on the result of evaluation. The "world" is the outside environment, which is governed by its own environmental factors such as chemical mixtures (media). These factors continuously emit waves, which the organism's receptors then receive as "signals".)

5. {%a id="bibliography_5" href="https://www.linkedin.com/pulse/biological-models-reactionary-networks-glenn-puchtel/"%}Biological Models of Reactionary Networks{%/a%} by Glenn Puchtel (This one explains in detail the specific building blocks of the author's (bio)cybernetic systems architecture, including nodes, edges, pipes, rules, applicators, kits, and others. Nodes are basically the entry/exit points of signals, edges are transmitters of signals, and pipes/applicators are the ones which make decisions based on the received signals.)

6. {%a id="bibliography_6" href="https://www.linkedin.com/pulse/temporality-glenn-puchtel/"%}Temporality{%/a%} by Glenn Puchtel (This article illustrates the inner workings of time-related cybernetic components (e.g. temporals) using specific code examples. By doing this, the author proves us that these components are highly useful for simulating the ways in which signals vary their intensity levels as time passes by - an extremely crucial concept for implementing time delays in the system's feedback mechanism, as well as for implementing gradual memory decay.)

7. {%a id="bibliography_7" href="https://www.linkedin.com/pulse/cybernetic-patterns-glenn-puchtel/"%}Bio-Cybernetic Patterns{%/a%} by Glenn Puchtel (This is the graphical summary of the major building blocks in cybernetic-oriented design. They resemble digital circuit components in some sense, yet are much more functionally abstract. Within this collection, "pipe" is probably the most notable component because it represents the very concept of "controlled transmission of signals" - an ever-recurring theme in the activity of neurons, protein receptors, and other biological signal-processors.)









:d:A new way of designing gameplay systems, based on a force-exchange network and functional force-vector transformation logic. This was inspired by the two-vector event model of Peter Gärdenfors (Professor at Lund University), as well as the emergent system architecture concepts invented by Glenn Puchtel (Principal software architect at GRUBBRR).
:k:Game Design, Gameplay System, Game System, Technical Game Design, Gameplay Engineering, Peter Gärdenfors, Glenn Puchtel, Emergent Systems, Network Theory, Exchange Network, Game Mechanics, Lund University, GRUBBRR, Software Architecture, Emergent Gameplay, Pathfinding Network
:l:2024-08-13

[Force-Exchange Network for Gameplay Systems] August 13, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Introduction</b></h3>

Designing a gameplay system is a fairly complicated job, due to the way in which game mechanics typically work. A game usually involves a variety of factors, which are intertwined with one another in all sorts of dynamic ways. Worse still, a game designer who is not well-versed in software engineering is prone to further compound this kind of complexity by making requests which compel the engineers to break the general rule of the game by introducing special cases, thus convoluting the codebase.

If engineers ever happen to decide that a large portion of the codebase must be refactored in order to meet the designer's unexpected request, they are likely to be accused of "not willing to deliver the product on time". Eventually, those who are deemed "productive" are ones who duct-tape their way around the designer's irrational expectations and shove the accuring tech debt under the rug.

Therefore, engineers who are intelligent enough to comprehend the seriousness of this problem will be quick to realize that there are two ways of solving it; it is either (1) Work with a decent designer who at least has a STEM mindset, or (2) Start developing a system which is so robust, that even the craziest design request cannot ruin it.

The first solution works only if the engineers are able to choose which designer to work with. Unfortunately, this does not usually happen unless they are part of a small indie game studio (in which case the boundary between a designer and an engineer would be pretty blurry anyways).

The second solution, on the other hand, works at least to some extent as long as those in charge of shaping the overall architecture of the system are engineers, not "coders". A person who knows how to write code in more than a myriad of programming languages and has memorized a bunch of IT terminologies may look impressive on the outside, yet it does not indicate his/her competence as an engineer who is capable of thinking in terms of systems.

Coming up with a gameplay system which meets every single design request might be an impossible task. However, we can still minimize the necessity of refactoring the whole system if we make sure that it is as versatile as possible in the first place. The goal of engineering is to mitigate the issue of complexity, not necessarily to get rid of it entirely (because such a goal is too idealistic to be achievable).

<b0_1>

Therefore, it my belief that beginning a game development project with a highly robust gameplay system is a crucial step to take in order to prevent the occurrence of tech debt as much as possible. And for such a purpose, I have come up with a new model of gameplay systems which I decided to refer to as "Force-Exchange Network".

In a force-exchange network, actors (i.e. gameplay agents) dispatch force vectors to one another, which travel across the network of places (i.e. spatial zones) and eventually reach their recipients. Those recipients, then, apply these force vectors to their state vectors and respond by dispatching their own force vectors.

Some of the key benefits of this design can be outlined as the following:

(1) The componentization of events in the form of vector quantities (e.g. force vectors, result vectors) helps us specify game rules as vector transformation functions (aka "transfer functions") instead of a complicated set of conditional statements.

(2) Since events communicate their effects via a medium (i.e. force-exchange network), it is easy for the system to intervene with the game's cause-and-effect relations and modify them as needed. In a "peace zone", for example, the developer can simply turn off all damage-causing forces by letting the communication network simply dismiss them during the routing process.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Background Information</b></h3>

I drew inspirations for this model of gameplay from two people.

@@<b>(1) Peter Gärdenfors</b>

Professor Gärdenfors is a cognitive scientist and a philosopher at Lund University (Lund, Sweden), whose two-vector model of causality and the idea of "forces in conceptual space" helped me model gameplay events as instances of vector transformation. Please read {%a href="https://thingspool.net/morsels/page-4.html"%}Game Design using Gärdenfors' Event Model{%/a%} to learn more about the way his ideas contributed to the computational modeling of events and their causal relations.

@@<b>(2) Glenn Puchtel</b>

Glenn Puchtel is a principal software architect/engineer at GRUBBRR (Boca Raton, Florida), whose ideas in bio-inspired emergent systems (i.e. biocybernetics, wetware, etc) as well as their architectural implications inspired me to construct a network-based topology of the gameplay system. Please read {%a href="https://thingspool.net/morsels/page-6.html"%}Emergent Systems based on Glenn Puchtel's Biocybernetic Theory{%/a%} to learn more about the way his ideas contributed to the formation of the force-exchange network model.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>1. Events</b></h3>

The force-exchange network model of gameplay starts with a core concept called "events". Everything which happens in our game is an event, and events form chains of causality based upon their cause-and-effect relations.

Suppose that there are actors (i.e. gameplay agents) in the game world. Actors experience events, yet these events are causally bound to one another in terms of forces and their results. A force triggers an event, the event applies the force to the actor (thereby generating a result), and the result, in turn, emits a force which triggers yet another event, and so on.

<b1_1>

When an actor receives a force from another actor, it applies that force to itself and generates the appropriate result. This force-to-result conversion process, as a whole, is basically what an "event" is. Such a representation of an event can be described as an example of the "two-vector model of causality" in Professor Gärdenfors' theory in cognitive science.

<b1_2>

What is really important, though, is the inner workings of the event itself. In {%a href="https://thingspool.net/morsels/page-4.html"%}Game Design using Gärdenfors' Event Model{%/a%}, I have mentioned that an event can be interpreted as a process of transforming the incoming force vector to its corresponding result vector, as well as that such transformation can be achieved by means of a transfer function (i.e. a list of one-to-one mappings between scalar values).

In addition, what is happening inside an actor as it undergoes an event should also be noted. An actor first receives an incoming force vector, transforms it into the result vector (via the transfer function), and accumulates that result vector in its own persistent vector called "state vector". This special vector represents the current state of the actor, and can be considered the cumulative sum of all the result vectors produced so far.

<b1_3>

The following code demonstrates how force vectors, result vectors, and state vectors can be implemented. They are all subtypes of IAbstractVector, which is a generic data type containing a list of numerical values. The "ForceVectorComponentIndex" enum indicates the meaning of each coordinate in a force vector, the "ResultVectorComponentIndex" enum indicates the meaning of each coordinate in a result vector, and so on. In this example, the 4th coordinate of the incoming force vector characterizes the healing/damaging force, which is responsible for influencing the 4th coordinate of the result vector which characterizes the change in the actor's health.

#$
public enum ForceVectorComponentIndex
{
    PositionForceX,
    PositionForceY,
    RadiusForce,
    HealthForce,
}

public enum ResultVectorComponentIndex
{
    PositionChangeX,
    PositionChangeY,
    RadiusChange,
    HealthChange,
}

public enum StateVectorComponentIndex
{
    PositionX,
    PositionY,
    Radius,
    Health,
}

public interface IAbstractVector
{
    int[] Components { get; }
}

public class ForceVector : IAbstractVector { ... }
public class ResultVector : IAbstractVector { ... }
public class StateVector : IAbstractVector { ... }
#$

And the code below shows how a transfer function can be implemented. Here, "MinForceValue" is the staring value of the x-axis of the transfer function, and "TransferValues" are the list of f(x) values corresponding to the values in the x-axis (if we suppose that f(x) is the mathematical notation denoting a transfer function). "ForceVectorComponentIndex" indicates the type of force the function's x-axis represents, and "ResultVectorComponentIndex" indicates the type of result the function's y-axis represents.

Processing of an event is essentially the same thing as executing the "ApplyForceToState" function of its TransferFunction object.

#$
public class TransferFunction
{
    public int[] TransferValues;
    public int MinForceValue;
    public ForceVectorComponentIndex ForceVectorComponentIndex;
    public ResultVectorComponentIndex ResultVectorComponentIndex;

    public TransferFunction(...)
    {
        ...
    }

    public AddModifier(TransferFunction modifier)
    {
        if (modifier.ForceVectorComponentIndex != ForceVectorComponentIndex)
            throw new Exception("Force vector component indices do not match.");
        if (modifier.ResultVectorComponentIndex != ResultVectorComponentIndex)
            throw new Exception("Result vector component indices do not match.");

        int N = TransferValues.Length;
        for (int i = 0; i < N; ++i)
            TransferValues[i] += modifier.TransferValues[i];
    }

    public RemoveModifier(TransferFunction modifier)
    {
        if (modifier.ForceVectorComponentIndex != ForceVectorComponentIndex)
            throw new Exception("Force vector component indices do not match.");
        if (modifier.ResultVectorComponentIndex != ResultVectorComponentIndex)
            throw new Exception("Result vector component indices do not match.");

        int N = TransferValues.Length;
        for (int i = 0; i < N; ++i)
            TransferValues[i] -= modifier.TransferValues[i];
    }

    public void ApplyForceToState(ForceVector forceVector, StateVector stateVector)
    {
        int forceValue = forceVector.Components[ForceVectorComponentIndex];
        stateVector.Components[ResultVectorComponentIndex] += TransferValues[forceValue - MinForceValue];
    }
}
#$

After processing the events and adding their results to the state vector, the actor then runs its own behavioral logic and emits outgoing forces, which will then be received/processed by other actors. The other actors, then, may decide to send their own outgoing forces to the aforementioned actor, and so on. This back-and-forth transmission of forces allows the system to give birth to complex chains of causality, without requiring the architect to configure them manually. Such chains simply "emerge" out of where the actors are located and what the characteristics of their transfer functions are.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>2. Force Routers</b></h3>

There is a reason why my proposed model of gameplay systems is called "Force-Exchange Network". It is because network-oriented communication is the heart of what makes this model work.

When an actor emits a force vector, how shall we make sure that it will be received by the intended recipients? Unless every actor is sending force to everyone else all the time, we must attach some metadata to the force vector for the purpose of guiding it to its proper destination, such as the target location, places it has already visited so far (so as not to visit the same place over and over again), etc.

The following code shows a wrapper class which will works as a "parcel" for delivering force vectors. This class is simply called "Force", and is where the force vector and its metadata are packaged together. This is what an actor actually sends to other actors whenever it "emits a force".

#$
public class Force
{
    public HashSet<Place> VisitedPlaces;
    public int TargetPositionX;
    public int TargetPositionY;
    public int TargetRadius;
    public ForceVector ForceVector;
}
#$

So, we have this thing called "Force" which is analogous to a letter in a mail delivery service. But how to deliver it to its designated location? In order to answer this question, we must first picture the game world as a collection of spatial entities and then proceed to interpret them as nodes in a communication network.

First of all, let us imagine that the game world consists of a number of places, where a "place" is a fixed region in space. Each place contains a number of actors in it, who are responsible for exchanging forces with one another.

Spatially speaking, a place is an area which encloses its actors. From a communication point of view, though, a place is something more than that. Since an actor communicates with another actor "through space", we ought to imagine a place not as a static region, but as a "force router" which works as a medium of signal transmission (This concept is thoroughly explained in the "Indirect Communication" section of {%a href="https://thingspool.net/morsels/page-6.html"%}Emergent Systems based on Glenn Puchtel's Biocybernetic Theory{%/a%}).

<b2_1>

A place acts as a "cellphone tower" in this respect. It "routes" forces to their rightful recipients, just like a cellphone tower routes voice signals to their receivers' mobile devices. One of the main benefits of this indirect means of communication is that it prevents tight coupling among the actors themselves.

<b2_2>

What if the sender and recipient are in two different places? In this case, the sender's place should first route the sender's force to the recipient's place. The recipient's place, then, will route the received to the recipient, thereby completing the line of delivery.

<b2_3>

The following snippet shows the code implementation of the "Place" data structure. From a topological point of view, each place is a node in a graph with its own edges to its adjacent places (i.e. "neighboringPlaces") as well as a set of actors it contains. The four numbers, "boundaryX1", "boundaryY1", "boundaryX2", and "boundaryY2", refer to the place's spatial boundaries.

Whenever a place receives a force, its "RouteForce" function gets called. This function compares the force's target region with the spatial regions of the place's constituent actors as well as neighboring places, and routes the force to every one of them whose region intersects that of the target region (because anyone who lies outside of the target region is not supposed to receive the force).

#$
public abstract class Place
{
    private HashSet<Actor> actors;
    private HashSet<Place> neighboringPlaces;

    private int boundaryX1;
    private int boundaryY1;
    private int boundaryX2;
    private int boundaryY2;

    public Place(...)
    {
        ...
    }

    public void RouteForce(Force force)
    {
        force.VisitedPlaces.Add(this);
        ApplyFilter(force);

        foreach (Actor actor in actors)
        {
            actor.ReceiveIncomingForce(force);
        }

        foreach (Place neighboringPlace in neighboringPlaces)
        {
            if (!force.VisitedPlaces.Contains(neighboringPlace))
            {
                int forceX1 = force.TargetPositionX - force.TargetRadius;
                int forceY1 = force.TargetPositionY - force.TargetRadius;
                int forceX2 = force.TargetPositionX + force.TargetRadius;
                int forceY2 = force.TargetPositionY + force.TargetRadius;
                if ((forceX1 <= boundaryX2 && forceX2 >= boundaryX1) &&
                    (forceY1 <= boundaryY2 && forceY2 >= boundaryY1))
                {
                    neighboringPlace.RouteForce(force);
                }
            }
        }
    }

    public void Update()
    {
        // Re-evaluate and rearrange actors (based on their current positions).
        ...
    }

    private abstract void ApplyFilter(Force force);
}
#$

The game world, as a whole, may as well be considered a graph which is made out of "Place" nodes. Such a world is fairly convenient to devise, both manually and procedurally, since each place can be thought of either a room or a hallway of a dungeon, etc. Besides, the center of each place may also serve as a pathfinding node, from which a set of more granular pathfinding nodes can branch out.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>3. Force Filters</b></h3>

One may ask, "Why do we even need a network-based communication scheme for exchanging forces? Can't an actor just look up other actors and send forces directly to them?"

And indeed, it is a feasible option. However, there are reasons why I insist that transmitting forces via a network of routers (i.e. places) is a much better idea from an architectural standpoint than direct actor-to-actor force transmission.

The first reason is that the game may not necessarily be single-threaded, single-player, and completely synchronous. It might be an online game which is supposed to be played across multiple servers, in which case the network-based topology accurately reflects the way in which things ought to be arranged. Each server machine, for instance, may serve as a separate "place" in this game, being an actual router of signals inside a real computer network. And even if the game is single-player, modern computing devices often expect us to leverage their power of multithreading (by means of worker threads, etc). In this case, allocating the jobs of different places (i.e. force routers) to different threads becomes a feasible option as long as these places possess their own asynchronous message queues, etc.

The second reason is that using a place as a medium of force transmission allows us to create places with their own ways of intervening with the forces (aka "force filters"). When designing a video game, we often feel that the system ought to be able to change the manners in which the actors interact with each other based on where they are located (e.g. "The game must disable damage effects if the players are in a peace zone", etc). Force filters easily fulfill this kind of expectation by filtering forces via custom methods before they reach their recipients.

<b3_1>

The following code shows how different types of places are able to have their own filters. The "ApplyFilter" method is what applies the place's force filter to any force it happens to be routing. Each subclass of "Place", which represents a custom place type, includes its own definition of "ApplyFilter", allowing it to filter forces in its own way.

#$
public class RegularPlace : Place
{
    private void ApplyFilter(Force force)
    {
    }
}

public class DamageDisabledPlace : Place
{
    private void ApplyFilter(Force force)
    {
        if (force.ForceVector.Components[(int)ForceVectorComponentIndex.HealthForce] < 0)
            force.ForceVector.Components[(int)ForceVectorComponentIndex.HealthForce] = 0
    }
}

public class MechanicalForceDisabledPlace : Place
{
    private void ApplyFilter(Force force)
    {
        force.ForceVector.Components[(int)ForceVectorComponentIndex.PositionForceX] = 0;
        force.ForceVector.Components[(int)ForceVectorComponentIndex.PositionForceY] = 0;
    }
}
#$

"RegularPlace" is a place which does not intercept forces at all; it simply lets forces pass through the vacuum. "DamageDisabledPlace" is some kind of "peace zone" where none of the actors are able to hurt each other (because all negative (damaging) health forces are clamped to 0). "MechanicalForceDisabledPlace" is a chunk of space in which all mechanical interactions are disabled (e.g. collision, knockback, etc), which means that all actors can simply pass through one another like ghosts.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>4. Status Conditions</b></h3>

In {%a href="https://thingspool.net/morsels/page-4.html"%}Game Design using Gärdenfors' Event Model{%/a%}, I have mentioned that an actor's status condition (e.g. spell, upgrade, etc) can be implemented as a modification to the event's transfer function. The simplest approach is to model each status condition as a function which temporarily gets added to the event's original transfer function, thereby "warping" the way in which the event transforms the incoming force vector.

<058>

The question of when to add or remove a status condition, though, presents us with a major technical challenge. A brute-force implementation is to just let actors identify each other and directly invoke each other's "AddStatusCondition(...)" or "RemoveStatusCondition(...)" methods, and so forth, but such a direct solution violates the architectural elegance of the network-based communication protocol.

A significantly better solution is to let the addition and removal of a status condition be part of a force vector. This allows each actor to apply a status condition to another actor by sending a force vector, instead of relying on other means. The image below shows an example layout of a force vector which supports status conditions. The "Add-force" component refers to the number of times the corresponding status condition should be added to the recipient actor, and the "Remove-force" component refers to the number of times the corresponding status condition should be removed from the recipient actor.

<b4_1>

And here is the augmented version of the "ForceVectorComponentIndex" enum. As you can see from the code below, each separate type of status condition has its own pair of force vector components - AddForce and RemoveForce.

#$
public enum ForceVectorComponentIndex
{
    PositionForceX,
    PositionForceY,
    RadiusForce,
    HealthForce,
    StatusConditionAddForce_HealBlocker,
    StatusConditionRemoveForce_HealBlocker,
    StatusConditionAddForce_Stun,
    StatusConditionRemoveForce_Stun,
    StatusConditionAddForce_Poison,
    StatusConditionRemoveForce_Poison,
    StatusConditionAddForce_Freeze,
    StatusConditionRemoveForce_Freeze,
}
#$

A little bit of change in the event-processing logic will be required to make this design work. Previously, we were merely assuming that the event takes the incoming force vector, plugs it into the transfer function, and computes the corresponding result vector. When status conditions are involved, however, the incoming force vector's components which are related to status conditions must be identified/processed via a different procedure. Instead of going through the transfer function, these components will turn themselves into "modifier functions" which will then be added to (or subtracted from) the transfer function.

<b4_2>

The code below is how a status condition should be implemented. Each status condition consists of two parts - is modifier function and expiration time. The modifier function is structurally the same as a transfer function (hence the reason why its type is "TransferFunction"), except that its role is to modify an existing transfer function instead of serving as one. The expiration time is for cases in which the status condition is supposed to be automatically removed from the actor after a certain duration of time, without requiring it to be removed explicitly. The "StatusConditionFactory" class is basically a lookup table for each status condition type's modifier function and lifespan.

#$
public class StatusCondition
{
    public TransferFunction Modifier;
    public float ExpirationTime;
}

public static class StatusConditionFactory
{
    public static Dictionary<ForceVectorComponentIndex, () => StatusCondition> GenerationMethods = {
        {ForceVectorComponentIndex.StatusConditionAddForce_HealBlocker,
            () => new StatusCondition(...)},
        {ForceVectorComponentIndex.StatusConditionRemoveForce_HealBlocker,
            () => new StatusCondition(...)},
        {ForceVectorComponentIndex.StatusConditionAddForce_Stun,
            () => new StatusCondition(...)},
        {ForceVectorComponentIndex.StatusConditionRemoveForce_Stun,
            () => new StatusCondition(...)},
        {ForceVectorComponentIndex.StatusConditionAddForce_Poison,
            () => new StatusCondition(...)},
        {ForceVectorComponentIndex.StatusConditionRemoveForce_Poison,
            () => new StatusCondition(...)},
        {ForceVectorComponentIndex.StatusConditionAddForce_Freeze,
            () => new StatusCondition(...)},
        {ForceVectorComponentIndex.StatusConditionRemoveForce_Freeze,
            () => new StatusCondition(...)},
    };
}
#$

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>5. Anatomy of an Actor</b></h3>

The diagram below illustrates the overall structure of an actor (i.e. gameplay agent). First, it receives all the incoming forces and adds them together, yielding the net incoming force vector. This single vector contains the composite effect of all the incoming forces which the actor happened to receive at that particular moment in time.

This net vector, then, undergoes two different processes. First, some of its components which are related to the addition/removal of status conditions will trigger the system to add/subtract the appropriate "modifier functions" to/from the transfer functions whose dimension types match, as well as setting timers to handle their expiration. Secondly, the rest of the vector components will be applied to the (possibly modified) transfer functions, yield their corresponding result vectors.

The individual result vectors, then, will eventually be added to the actor's state vector (because, after all, result vectors represent changes in the state vector; they are the differentials). The state vector is the current state of the actor, which means that its components reflect the actor's current x position, current y position, current size in radius, current health, etc. The only "state" outside of this vector is the set of ongoing status conditions that the actor has in itself.

Based on the latest state vector, the actor's "force emitters" then execute themselves and generate the outgoing forces. They can be pretty much any sorts of behavioral commands, such as: "Attack every enemy in range", "Heal the closest friend in front of you", "Apply the slow-down status condition to every enemy in front of you", "Turn yourself toward the closest enemy", and so on.

Note that it is definitely possible to generate an outgoing force whose recipient is the sender itself. This kind of force comes in handy when the actor wants to move or rotate itself (or apply a status condition to itself).

<b5_1>

The following code is how an actor can be implemented as a class. Whenever it updates, it processes the incoming force vectors, applies them to the state vector, emits outgoing force vectors, and gets rid of expired status conditions.

#$
public class Actor
{
    private Place place;
    
    private ForceVector netIncomingForceVectorPending;
    private StateVector stateVector;

    private HashSet<TransferFunction> transferFunctions;
    private HashSet<ForceEmitter> forceEmitters;

    private HashSet<StatusCondition> statusConditions;
    private List<StatusCondition> removePendingStatusConditions;

    public int PositionX => stateVector.Components[(int)StateVectorComponentIndex.PositionX];
    public int PositionY => stateVector.Components[(int)StateVectorComponentIndex.PositionY];
    public int Radius => stateVector.Components[(int)StateVectorComponentIndex.Radius];

    public Actor(...)
    {
        ...
    }

    public void ReceiveIncomingForce(Force incomingForce)
    {
        int dx = incomingForce.TargetPositionX - PositionX;
        int dy = incomingForce.TargetPositionY - PositionY;
        int thresDist = incomingForce.TargetRadius + Radius;

        // Receive the incoming force only if the actor intersects the target region.
        if (dx*dx + dy*dy <= thresDist*thresDist)
        {
            netIncomingForceVectorPending += incomingForce.ForceVector;
        }
    }

    public void SendOutgoingForce(Force outgoingForce)
    {
        place.RouteForce(outgoingForce);
    }

    public void Update()
    {
        foreach (TransferFunction transferFunction in transferFunctions)
        {
            int N = netIncomingForceVectorPending.Components.Length;
            for (int i = 0; i < N; ++i)
            {
                if (StatusConditionFactory.GenerationMethods.TryGetValue((ForceVectorComponentIndex)i, out var method))
                {
                    int numStatusConditionsToAdd = netIncomingForceVectorPending.Components[i];
                    for (int j = 0; j < numStatusConditionsToAdd; ++j)
                    {
                        AddStatusCondition(method());
                    }
                }
            }
            transferFunction.ApplyForceToState(netIncomingForceVectorPending, stateVector);
        }

        foreach (ForceEmitter forceEmitter in forceEmitters)
        {
            Force outgoingForce = forceEmitter.GenerateOutgoingForce(actor, stateVector);
            SendOutgoingForce(outgoingForce);
        }

        for (int i = 0; i < netIncomingForceVectorPending.Components.Length; ++i)
        {
            netIncomingForceVectorPending.Components[i] = 0;
        }

        foreach (StatusCondition statusCondition in statusConditions)
        {
            if (statusCondition.ExpirationTime > Time.time)
                removePendingStatusConditions.Add(statusCondition);
        }

        foreach (StatusCondition removePendingStatusCondition in removePendingStatusConditions)
        {
            RemoveStatusCondition(removePendingStatusCondition);
        }
        removePendingStatusConditions.Clear();
    }

    private void AddStatusCondition(StatusCondition statusCondition)
    {
        statusConditions.Add(statusCondition);

        foreach (TransferFunction transferFunction in transferFunctions)
        {
            if ((transferFunction.ForceVectorComponentIndex == statusCondition.TransferFunction.ForceVectorComponentIndex) &&
                (transferFunction.ResultVectorComponentIndex == statusCondition.TransferFunction.ResultVectorComponentIndex))
            {
                transferFunction.AddModifier(statusCondition.Modifier);
            }
        }
    }

    private void RemoveStatusCondition(StatusCondition statusCondition)
    {
        statusConditions.Remove(statusCondition);

        foreach (TransferFunction transferFunction in transferFunctions)
        {
            if ((transferFunction.ForceVectorComponentIndex == statusCondition.TransferFunction.ForceVectorComponentIndex) &&
                (transferFunction.ResultVectorComponentIndex == statusCondition.TransferFunction.ResultVectorComponentIndex))
            {
                transferFunction.RemoveModifier(statusCondition.Modifier);
            }
        }
    }
}

public class ForceEmitter
{
    public Force GenerateOutgoingForce(Actor actor, StateVector stateVector)
    {
        ...
    }
}
#$

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>6. Future Implementation</b></h3>

The schematics and code shown so far, of course, do not cover the full picture of the force-exchange network system. There are many more things which ought to be added to make it usable for gameplay purposes. Here are some of the future implementations which I think may be necessary:

@@<b>(1) Force with delay (e.g. projectile)</b>

In many cases, forces are not instantaneous; they need time to propagate. Therefore, it may be desirable to attach an additional "delay" attribute to the Force object, telling the Place objects that they must wait for a certain duration of time before routing it to either the recipient or another place.

@@<b>(2) Function-based force emission logic</b>

I have not demonstrated any logic for generating outgoing forces. Technically speaking, it is not impossible for an actor to simply look up other actors (via references to its current place, neighboring places, etc), go through a custom logic (with a bunch of hard-coded conditional/iterative statements), and decide what forces to emit. Although such an approach is straightforward, it is far more prone to error and complexity than the way in which incoming forces are being processed. Thus, we will probably need an outgoing-force equivalent of the "transfer function".

@@<b>(3) Place with its own force-emitting behaviors</b>

Just like actors are capable of emitting forces, places may need to be able to emit forces as well. A sauna, for example, is a place which constantly emits "heat force" to all the actors in it. Also, this kind of logic lets us devise places with their own "force fields" (e.g. gravity), as opposed to places which act like complete vaccum in outer space.

@@<b>(4) Observation by means of "notification forces"</b>

While it is definitely possible to let actors directly perceive each other's presence based on references (i.e. reference to the current place + reference to neighboring places + reference to each place's constituent actors, etc), such direct dependency is not so desirable from an architectural point of view. Also, it makes it hard to implement visibility-warping gameplay features such as stealth-mode, and so on. Thus, it may be better to let each actor emit not only state-changing forces such as "knockback", "heal", "damage", etc, but also "notification forces" which notify the actor's presence. This lets the process of observing other actors be passive (i.e. You just wait to receive notification forces instead of actively searching for other actors on your own).











:d:How to use state machine networks (multi-state machines) to design dynamics systems, including gameplay systems, industrial simulations, scientific applications, cellular automata, and many others.
:k:Game Design, Technical Game Design, Game Mechanics, State Machine, FSM, Finite State Machine, Multi State Machine, Systems Engineering, Electrical Engineering, Electronics, Digital Circuits, Digital Logic, Digital Design, Verilog, HDL, Boolean Algebra, Systems Design, Cellular Automata, Circuit Simulator
:l:2024-08-18

[Technical Design using Multi-State Machines] August 18, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Introduction</b></h3>

There are many ways of conceptualizing a system. In computer science, it is typical to picture it as a state machine. One of the main downsides of this approach, however, is the ensuing complexity.

A fairly small system with only a few number of possible states is pretty easy to model as a state machine; all we need to do is come up with a set of states (i.e. nodes in a graph), and a set of transitions between states (i.e. edges between the nodes). This lets us devise the entire system simply by drawing a state diagram.

A system with an enormous number of states, on the other hand, is not something which we are able to design in terms of a single state machine without pulling our hair off out of sheer confusion. While it is technically possible to formultae even an extremely complex system (such as a whole computer) as an FSM (Finite State Machine) in which the current state of the system is represented as one of the nodes in a graph, such a way of modeling the system is prohibitively convoluted.

Therefore, it usually makes more sense to imagine a complex (non-trivial) system not as a single state machine, but as a collection of multiple state machines (i.e. modules), each of which keeps track of its own state. This design philosophy also aligns itself with the OOP (Object Oriented Programming) paradigm, where each object is a state machine with its own set of states (i.e. all possible permutations of the member variables) and state transitions (i.e. all possible ways in which the member variables can change their values).

Such a multitude of state machines, though, can operate as parts of one underlying system only if they are able to influence each other - that is, they must be able to communicate. If not, they will be a mere juxtaposition of completely isolated systems.

<c00>

The question is, "What kind of communication"? There are innumerable ways of sharing information with one another, yet some of them are far more efficient than others. Thus, a wise designer of a system should be able to choose an optimal (or at least a nearly optimal) means of letting state machines affect each other's state.

In this article, I will showcase a new method of communication between state machines which I consider as fairly optimized for a wide variety of applications in system design, such as video games, cellular automata, circuit simulators, and many others.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Multi-State Machine</b></h3>

Since I am personally more familiar with game development than any other area of engineering, it is probably appropriate for me to start with an example which takes place in a video game.

Suppose that there is a top-down game in which the player is going on an adventure in a maze-like world. There are walls preventing him from moving freely, so he is forced to use doors. Unfortunately, some of the doors are locked, which means that the player must figure out how to unlock them in order to get to the other side of the wall.

The image below is an example of a locked door. This door stays open only when the nearby button is being pressed, and immediately closes itself as soon as the button is released. So the only way for our player to cross the door is to first place a box right in front of the button to press it. Unless somebody moves it away, the box will continue pressing the button, and the player will be free to cross the door.

<c01>

How shall we implement such a game mechanic? One of the most intuitive ways, obviously, is to model each individual object as a state machine. For instance, the door is a state machine with two states called "Closed" and "Open", and the button is a state machine with two states called "Released" and "Pressed".

The diagram below shows how the button "talks" to the door, so as to make the aforementioned rule work. Whenever the door is closed and the button is pressed, the button tells the door to open up. And whenever the door is open and the button is released, the button tells the door to close.

<c02>

What we are witnessing here is a pair of state machines - the door and the button. Both of them have their own states and state transitions, and they run concurrently (i.e. both the door's state and button's state are active at the same time). Yet they are not disjoint from each other; the button's state influences the door's state, thereby forming a cause-and-effect relation.

We may refer to such a network of state machines as a "multi-state machine", since the whole thing behaves as though it is a state machine with multiple concurrent states.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Logic without Logic Gates</b></h3>

Let us take a look at a slightly more involved scenario. Suppose that there are two buttons called "button A" and "button B", and that there is a door which stays open only when both of these buttons are simultaneously being pressed (not just one of them, but both). This is an AND relation in boolean logic, and the image below shows an electric circuit analogy of such a logical operation. Here, the two buttons are analogous to two electrical switches which are connected in series. Only when both of them are pressed, the whole circuit becomes conductive and enables itself to activate (open) the door.

<c03>

An engineer might be tempted to implement this using a logic gate (i.e. AND gate), which is a sound approach in a general computing environment in which binary logic operators (such as &&, ||) are some of the most primitive building blocks of expressions. The temptation gets even larger when the engineer is developing a game which is meant to be executed not on a personal computing device (e.g. PC or mobile), but on a piece of programmable hardware, such as FPGA (Field-Programmable Gate Array), wherein logic is being configured by establishing connections upon a vast 2D array of pre-embedded logic gates.

Outside of the realm of digital design, however, logic gates may not be the most appropriate elements to use. A video game, for example, is often filled with a myriad of wild mechanics which are not so easily explicable in terms of binary logic operators, such as dialogues, spatial reasoning (e.g. rush hour puzzles), various causal chains, and many others.

In order to encompass most (if not all) of all these non-boolean mechanics in our design protocol, therefore, we must come up with a framework which is more versatile than a mere assembly of binary logic elements. In my opinion, such a framework can easily be discovered when we stop thinking in terms of logic gates (e.g. AND, OR, NOT, etc) and begin to design the whole system using state machines and their transition rules only.

The diagram shown below is an example of how the aforementioend "AND" logic can be implementated by introducing an intermediatry state machine called "ButtonSeq" (i.e. "Button Sequence"), whose current state indicates the most recently ongoing sequence of button-presses. For instance,

(1) "None" means that neither button A nor button B is being pressed.
(2) "A" means that only button A is being pressed.
(3) "AB" means that button A was pressed first, button B was pressed second, and that they both have been being pressed since then.

<c04>

What you can see here is that both the "AB" and "BA" states trigger the door's transition from "Closed" to "Open". This means that, whenever button A and button B are both being pressed (regardless of the order in which they were initially pressed), the door is forced to be open.

In this example alone, we are already seeing an advantage of designing mechanics in terms of state machines instead of logic gates. Logical operators such as "AND", since they are commutative (i.e. they don't care about the order of the input parameters), are insufficient for handling cases in which the order of pressing these two buttons matters, and so forth. Imagine that, inside a game studio, the game designer comes over to the engineering team, gets mad, and says,

"Hey, the way you implemented my design was wrong. When I said that pressing button A and button B should open up the door, what I meant was that pressing button A AND THEN pressing button B should open up the door. I never said that pressing them the other way around should give the same result. What you guys made is clearly a bug. The entire level won't make any sense at all if you do not fix this immediately!"

Try making the requested adjustment by rearranging logic gates; it is fairly complicated to do so. If you configure things in terms of state machines, on the other hand, you will have an easier life because state machines are much more malleable than logic gates.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Rule Dictionary</b></h3>

But of course, I can totally feel the sentiment that the above example somehow appears to "overcomplicate" a fairly simple piece of logic by not leveraging built-in logical operators. However, there is an enormous benefit in trying to formulate everything solely in terms of state machines; it is what I would call "structural uniformity".

In the model we have been seeing so far, there has really been only a single type of semantic building blocks - state transition rules. Every one of these rules, without an exception, can be interpreted as a mapping of two states (i.e. "current state" and "trigger state") into another state (i.e. "next state"). In case of the state "AB" triggering the door to open, for instance, we can say that it is due to a rule in which "current state" is "Closed", "trigger state" is "AB" (because "AB" is the thing that triggers the door to open), and "next state" is "Open".

<c05>

And if we gather all such rules in one place called "rule dictionary", we may claim that this dictionary alone fully describes the behavior of the whole system. This kind of simplicity is extremely helpful especially if we are aiming to implement it as a custom electronic module (in the form of an ASIC (Application-Specific Integrated Circuit), etc); less variety in the data structure means less complexity in the hardware.

<c06>

The most challenging part is the implementation of the rules. It really depends on the hardware, but let us begin with the assumption that we are developing an application for a general-purpose computer (e.g. PC or mobile). The most brute-force approach is to execute the rules as a bunch of conditional statements, like the ones displayed below.

#$
if (ButtonSeq.CurrState == "None" && ButtonA.CurrState == "Pressed")
    ButtonSeq.NextState = "A";
if (ButtonSeq.CurrState == "A" && ButtonA.CurrState == "Released")
    ButtonSeq.NextState = "None";
if (ButtonSeq.CurrState == "A" && ButtonB.CurrState == "Pressed")
    ButtonSeq.NextState = "AB";
if (ButtonSeq.CurrState == "AB" && ButtonA.CurrState == "Released")
    ButtonSeq.NextState = "B";
if (ButtonSeq.CurrState == "AB" && ButtonB.CurrState == "Released")
    ButtonSeq.NextState = "A";
...
if (ButtonSeq.CurrState == "AB" && Door.CurrState == "Closed")
    Door.NextState = "Open";
if (ButtonSeq.CurrState == "BA" && Door.CurrState == "Closed")
    Door.NextState = "Open";
if (ButtonSeq.CurrState == "None" && Door.CurrState == "Open")
    Door.NextState = "Closed";
if (ButtonSeq.CurrState == "A" && Door.CurrState == "Open")
    Door.NextState = "Closed";
if (ButtonSeq.CurrState == "B" && Door.CurrState == "Open")
    Door.NextState = "Closed";
#$

It is not difficult to interpret the meaning of what is going on here. If ButtonSeq's state is "None" and ButtonA's state is "Pressed", ButtonSeq's state must change into "A", and so on. Each IF statement here is an individual state transition rule.

Of course, this is not the best way of implementing the rules. It is both hard-coded (which means it is not data-driven) and inefficient (because it introduces a long sequence of statements that the program needs to visit), so obviously we need a better approach.

A better (although not the best) way is to define the rules as entries in a nested dictionary which, in C# programming language, could be written as:

#$
Dictionary<CurrStateOwner,
    Dictionary<CurrStateName,
        Dictionary<TriggerStateOwner,
            Dictionary<TriggerStateName,
                NextState>>>> RuleDictionary;
#$

"CurrStateOwner" is the state machine whose "current state" is to be examined, and "TriggerStateOwner" is the state machine whose "trigger state" is to be examined. The rule dictionary is the data structure which maps these two states (i.e. "current state" and "trigger state") to the desired future state of "CurrStateOwner".

If we represent the rule dictionary of the previous two-button scenario in JSON format, it will be written as:

#$
"RuleDictionary": {
    "ButtonSeq": {
        "None": {
            "ButtonA": {
                "Pressed": "A"
            },
            "ButtonB": {
                "Pressed": "B"
            }
        },
        "A": {
            "ButtonA": {
                "Released": "None"
            },
            "ButtonB": {
                "Pressed": "AB"
            }
        },
        "AB": {
            "ButtonA": {
                "Released": "B"
            },
            "ButtonB": {
                "Released": "A"
            }
        },
        ...
    },
    "Door": {
        "Closed": {
            "ButtonSeq": {
                "AB": "Open"
            },
            "ButtonSeq": {
                "BA": "Open"
            }
        },
        "Open": {
            "ButtonSeq": {
                "None": "Closed"
            },
            "ButtonSeq": {
                "A": "Closed"
            },
            "ButtonSeq": {
                "B": "Closed"
            }
        }
    }
}
#$

While a nested dictionary is a pretty complicated and computationally inefficient data structure, one of its upsides is that it is extremely easy to use. Whenever the program happens to run the update loop of the "ButtonSeq" object, for instance, all it has to do is access the "ButtonSeq" entry of "RuleDictionary" to look up all the rules which belong to the "ButtonSeq" object. And within that "ButtonSeq" entry, all it has to do is access the inner entry which corresponds to the current state of the "ButtonSeq" object to look up all "trigger states" which may potentially determine the object's future state.

This makes a nested dictionary a great choice for quick data access. A more optimal means of implementing this dictionary is to come up with a number of relational data tables (like in SQL) and chain them together by means of primary/secondary keys, etc.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Templates for Rules</b></h3>

Syntactic redundancy, though, is going to ensue if we construct all the rules on a case-by-case manner. Imagine that there are 100 doors inside the game, each of which opens up only when a unique pair of buttons are simultaneously being pressed. There are numerous buttons (at least 50 or so), from which 100 such unique combinations are to be made for those doors. Indeed, we do not want to manually type all the rules for a hundred "ButtonSeq" objects. Fortunately, we know that we can abstract out the logic of "ButtonSeq" (i.e. AND operator) and turn it into a template which can be replicated as many times as we want.

In order for this to happen, we must first turn all the relevant states and their transitions into generic, parameterizable entities, like the ones shown below.

<c07>

The idea is that, once they are all parameterized, we will be able to write a function which automatically creates a set of rules based on the given parameters. Such a function works as a template for generating rules, and is demonstrated in the Javascript code below:

#$
const buttonA = {
    name: "buttonA",
    states: {
        "0": "Released",
        "1": "Pressed",
    },
};
const buttonB = {
    name: "buttonB",
    states: {
        "0": "Released",
        "1": "Pressed",
    },
};
const door = {
    name: "door",
    states: {
        "0": "Closed",
        "1": "Open",
    },
};

function AND(output, input0, input1)
{
    return `{
        "AND(${output.name}, ${input0.name}, ${input1.name})": {
            "null": {
                "${input0.name}": {
                    "${input0.states["1"]}": "0"
                },
                "${input1.name}": {
                    "${input1.states["1"]}": "1"
                },
            },
            "0": {
                "${input0.name}": {
                    "${input0.states["0"]}": "null"
                },
                "${input1.name}": {
                    "${input1.states["1"]}": "01"
                },
            },
            "01": {
                "${input0.name}": {
                    "${input0.states["0"]}": "1"
                },
                "${input1.name}": {
                    "${input1.states["0"]}": "0"
                },
            },
            ...
        },
        "${output.name}": {
            "${output.states["0"]}": {
                "AND(${output.name}, ${input0.name}, ${input1.name})": {
                    "01": "${output.states["1"]}"
                },
                "AND(${output.name}, ${input0.name}, ${input1.name})": {
                    "10": "${output.states["1"]}"
                },
            },
            "${output.states["1"]}": {
                "AND(${output.name}, ${input0.name}, ${input1.name})": {
                    "null": "${output.states["0"]}"
                },
                "AND(${output.name}, ${input0.name}, ${input1.name})": {
                    "0": "${output.states["0"]}"
                },
                "AND(${output.name}, ${input0.name}, ${input1.name})": {
                    "1": "${output.states["0"]}"
                },
            }
        }
    }`;
}

const rule_door = AND(door, buttonA, buttonB);
#$

Here, the code just genereated the two-button rule (i.e. "Both button A and B must be pressed in order to open the door") by calling the "AND" function, which took the door as the operator's output parameter and the two buttons (A and B) as the operator's two input parameters.

Leveraging this function-based rule instantiator, the developer is able to quickly come up with a wide spectrum of complex rules simply by calling functions. For example, take a look at the scenario below, expressed in the form of an electric circuit. It tells us that there are two doors (A and B) and three buttons (A, B, and C); door A opens up only when button A and B are both being pressed, whereas door B opens up only when button B and C are both being pressed.

<c08>

By calling the "AND" function twice, each time with a unique combination of arguments, one can easily create two sets of rules which are different yet share the same type of logic (i.e. AND operator). These two sets of rules, when combined as a whole, will fully depict the above scenario. The following code shows us how to do it.

#$
const rules_doorA = AND(doorA, buttonA, buttonB);
const rules_doorB = AND(doorB, buttonB, buttonC);

const ruleDictionary = `{
    ${rules_doorA},
    ${rules_doorB}
}`;
#$

Here is a slightly trickier example. What if there is a door which opens up only when all 3 of the buttons are being pressed, not just 2? This may baffle the designer a bit because the AND function only takes two inputs. This problem, though, is not hard to solve. All we need is an intermediary object (i.e. "wire") whose state is the result of applying the AND function to the first two buttons (A and B). This intermediary object, then, can be fed as an input parameter to another AND function along with the third button (C). The result of this AND function will be equivalent to the result of applying the AND operator to all three buttons (A, B, and C).

<c09>

And the snippet below is the code implementation of what I just mentioned.

#$
const wire = {
    name: "wire",
    states: {
        "0": "LowVoltage",
        "1": "HighVoltage",
    },
};

const rules_wire = AND(wire, buttonA, buttonB);
const rules_door = AND(doorB, wire, buttonC);

const ruleDictionary = `{
    ${rules_wire},
    ${rules_door}
}`;
#$

Such a dynamic rule-generation script, as those of you with expertise in embedded systems may have noticed, closely resembles a hardware description language such as Verilog, since it is composed of a set of declarative statements which tell us the input-output relations between modules.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Race Conditions</b></h3>

One may question the feasibility of this multi-state design scheme by saying, "What if the system accidentally triggers an undesirable race condition? For instance, in your second example, I noticed that it is possible to cause a race condition when ButtonSeq's current state is 'None' and both button A and B are pressed at the same exact time. What should ButtonSeq's next state be - A, or B? This kind of ambiguity makes me question the legitimacy of what you are expounding here."

In a parallel or concurrent (e.g. multi-threaded) environment, such edge cases will be detrimental to the system if they are not being handled properly. They may even cause two or more mutually exclusive states to be simultaneously active! I will deal with this problem near the end of this article (i.e. in the "Race Conditions in Parallel Processing" section).

If the system is simply running on a single-threaded environment, though, we have nothing to worry about. When the system's update loop runs the update procedure of one of the state machines, it will simply scan the rule dictionary from top to bottom and apply the first rule which happens to trigger the state to change. If the rule which makes ButtonSeq respond to button A is listed BEFORE the rule which makes ButtonSeq respond to button B, simultaneously pressing both button A and B will make ButtonSeq respond to button A only. No fatal error will arise, and no one but an over-enthusiastic QA will say anything about it.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Compression of Rule Data</b></h3>

The JSON representation of the rule dictionary, which I have demonstrated above, is a bit too inefficient both in terms of memory and speed. Thus, it is desirable to format the dictionary in a more compact manner.

There are a number of things we ought to do to make it happen. First, we should reference each individual state with a binary code instead of a string of characters (as shown in the table below). This greatly reduces the amount of data needed for referencing the states. Furthermore, it helps us significantly speed up the dictionary's lookup process because a numerical value can directly be used as an index in the hash table (whereas a string requires the application to compute its hash code first).

<c10>

Secondly, we can even get rid of the nested dictionary data structure altogether if we express all the rules using two binary sequences (illustrated in the picture above), which may be referred to as "Rule Ranges" and "Rules", respectively.

The "Rule Ranges" sequence lists all the states of the system and their corresponding ranges in the "Rules" sequence (specified in terms of memory addresses). The "Rules" sequence lists all the rules which correspond to the given CurrState, each of which is denoted by the (TriggerState, NextState) pair.

When the system updates a state machine whose current state is 0101, for instance, it first looks up the range which corresponds to the entry 0101 in the "Rule Ranges" sequence (which corresponds to the range [start1, end1]). It then jumps into the "Rules" sequence, scans the entries in the range [start1, end1], and checks to see if the state 0010 or 0100 is currently active (Note: A state is "active" if it is the current state of one of the state machines). If 0010 is active, the program will change the current state of the machine from 0101 to 0110. If 0100 is active instead, the program will change the current state of the machine from 0101 to 0111.

Such raw-data representation of rules helps us minimize the size of its storage space, minimize the frequency of cache-miss (because more compactness of data means more data can be packed into the cache), and prevent potential incompatibility between ways in which different computing envirionments (e.g. operating systems) tend to handle data (because raw binary data does not make assumptions on how the environment will interpret it; the "rules engine" will simply interpret the data based upon its own custom way, regardless of on which platform it is running).

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Parallel Processing</b></h3>

Versatility and compactness are not the only advantages of the multi-state model I have shown so far. Another major advantage of it is its ability to run on a parallel computing environment, given a custom hardware module.

In order to explain what sort of hardware it is, I must first introduce a hypothetical electronic component called "state activation indicator". It is a 1-bit memory storage (similar to a D Flip-Flop) which tells us whether each state is active or not. So, for example, if there is a state activation indicator which indicates the activation status of the door's "Closed" state, we say that the door's current state is "Closed" if and only if the indicator's output bit is currently 1.

<c11>

This means that the "current state" of the whole system, which is really the ensemble of all the current states of its constituent state machines, is a binary string of length N containing M number of 1s (where 'N' is the total number of all possible states of all the state machines, and 'M' is the number of the state machines themselves). The figure below demonstrates how this data representation works.

<c12>

The system's current state can be characterized by an array of state activation indicators. Similarly, the system's next state (i.e. pending future state which is to be assigned back to the current state by the end of the application's clock cycle), too, can be characterized by an array of state activation indicators.

The image below is the hardware implementation that is necessary for the parallel multi-state machine to work. Between the two bit arrays which respectively represent the system's current state and next state, there is a two-dimensional grid of wire intersections, formed by both horizontally and vertically oriented electrical wires (i.e. conductors) which are placed at regular intervals. Each black dot denotes connection between the two intersecting wires (which means that if the value of one of the wires is 1, the value of the other wire will be 1 as well), and each green dot refers to the presence of an AND logic gate between the two intersecting wires. The result of this logic gate gets communicated through the green line.

<c13>

Here, each green dot (AND logic gate) corresponds to a state transition rule; it takes a "current state" and a "trigger state" as a pair of inputs, and yields the next state as the output. Imagine the green parts of the image above as the ones which are dynamically configured on a programmable hardware module (by means of tri-state buffers, transisters, etc), while the black parts are static and cannot be modified. Installing a rule dictionary, thus, is the same thing as establishing a bunch of green wirings between the grid's intersection points and their corresponding next-state memory input ports.

Once the wiring process is done, all we need to do is set the initial state of the system by pre-configuring the bits of CurrState and then starting the clock to initiate the cyclic flow of signals between CurrState and NextState. This will let the system update all of its states in parallel, without requiring the CPU to visit every individual state machine and update it sequentially.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Race Conditions in Parallel Processing</b></h3>

The aforementioned parallel implementation, though, is prone to introduce race conditions which may inadvertently make a state machine carry two or more concurrent states (which is inappropriate for a state machine). Therefore, we must add some kind of "postprocessing" stage to the end of the state transition cycle to resolve race conditions. For such a purpose, let me introduce yet another hypothetical module called "tie-breaker". It is an electronic component which takes a bit sequence as an input, leaves only a single "1" in it (if there are multiple of them), and returns the resulting sequence as the output.

<c14>

Then, when the system's clock cycle (update loop) ends and its NextState is to be transferred back to CurrState, the system will need to feed each group of states in NextState (corresponding to each individual state machine) to a tie-breaker and assign its result to the respective group in CurrState, instead of simply copying the bits from NextState to CurrState directly. It is demonstrated in the image below.

<c15>

This is how the system can prevent any potential race conditions; each tie-breaker ensures that each state machine contains only ONE current state.








:d:How to express a relation in an undirected graph, without using hypergraphs or any other advanced concepts? This article explains a purely node-based method of representing any n-ary relations. This will be useful for implementing custom hardware for relational computing systems, such as an optimized Prolog interpreter.
:k:Relation, Arity, Discrete Mathematics, Directed Graph, Undirected Graph, Hypergraph, Hyperedge, Hypernode, Hypervertex, Supergraph, Graph Theory, Circuit Theory, Relational Database, Topology, Prolog, Logic Programming, Knowledge Graph, GraphQL
:l:2024-08-22

[On Nodal Representation of Relations] August 22, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Introduction</b></h3>

Relations are everywhere - from discrete mathematics to computer science, from topology to data science, and innumerable other subjects. In popular areas of research such as ML (Machine Learning) and AI (Artificial Intelligence), too, relations serve as some of the most essential components of logic.

One of the problems in the study of relations, though, is the matter of representing them in a visually intelligible way. While it is possible to express any n-ary relations (for any positive integer 'n') in the form of algebraic notations (such as "xRy", "R(x,y)") or relational data table entries (such as those in an SQL database), expressing them in terms of graphical elements has been a major challenge.

When it comes to graphically depicting unary and binary relations, graph theory comes in handy. As long as we suppose that a relation is an edge and a member of a relation is a vertex, it can simply be assumed that a binary relation is an edge which connects its two members. If the relation is symmetric, it will be a undirected edge (because direction won't matter). if the relation is asymmetric, it will be a directed edge.

Similarly, an unary relation could be rendered as though it is a special case of a binary relation - that is, an edge which connects its sole member to an entity which symbolizes the absence of the other member (i.e. null).

<d01>

Now, how about ternary relations, quaternary relations, and other n-ary relations, whose arities are higher than two? It is technically possible to use the language of hypergraph (instead of just plain old graph) in which we may be free to express a relation as a hyperedge (i.e. edge with more than two vertices), and so on. We may even be able to describe the asymmetry of such a relation using the idea of a directed hyperedge.

However, a graphical representation of a hypergraph is visually too intimidating, as it no longer allows us to draw a relation simply as a line segment and instead forces us to draw colored regions, bundles of curved arrows, and a myriad of other complex visual elements. This will bloat the viewer's mind with too much abstract information.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Relation as a Composition of Atoms</b></h3>

In order to be able to draw n-ary relations in a simple, highly recognizable visual language, we must abstain from utilizing conceptual models which are way too abstruse for laymen to understand.

A hypergraph is not something which a person whose area of expertise does not considerably intersect with the domain of pure mathematics is expected to grasp easily. A graph, on the other hand, is something pretty much anyone is able to comprehend at least on a superficial level.

Therefore, it will be helpful for expressive purposes if we somehow figure out a way to represent any arbitrary n-ary relations using the rudimentary graph elements only (i.e. edges and vertices), without leveraging additional layers of abstraction. Also, it will be even more desirable to avoid directed edges and only employ undirected edges (i.e. line segments with no arrow signs whatsoever) so as to ensure utmost structural simplicity.

<d02>

For the purpose of accomplishing the above goals, let me first introduce two basic building blocks - negative nodes and positive nodes (shown above). These two types of nodes, when combined, will be able to constitute the body of any n-ary relation. I will explain the underlying reason shortly.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Unary and Binary Relations in an Undirected Graph</b></h3>

The picture below is our first example of how negative and positive nodes can be used as building blocks of a relation. What you are seeing here is a binary asymmetric relation with two member variables: X and Y. If we were using a directed graph, we would only need a directed edge (i.e. arrow) to depict such a relation. Since we are trying to describe it using an undirected graph, however, we need at least two distinct types of connected nodes between X and Y to express the sense of directionality from X to Y (I am assuming here that the relation's "direction" goes from negative to positive).

<d03>

What if there is no Y, and we are only left with X? There may be two opposing scenarios (demonstrated in the image below).

If X were connected to the negative side, the pair of nodes would be a quasi-unary relation which "points away from" X (i.e. points from X to nowhere). If X were connected to the positive side, the pair of nodes would be a quasi-unary relation which "points toward" X (i.e. points from nowhere to X). In both cases, the pair of nodes characterizes an unary relation whose sole member is X. Its "direction" in regard to X is a highly nuanced feature whose usage depends on the application.

<d04>

What if we do have both X and Y as members of the relation, yet both of them are attached to only one of the relation's pair of nodes? The image below illustrates two possible scenarios.

If X and Y were connected to the negative side, the pair of nodes would be a quasi-binary relation which "points away from" both X and Y (i.e. points from X,Y to nowhere). If X and Y were connected to the positive side, the pair of nodes would be a quasi-binary relation which "points toward" both X and Y (i.e. points from nowhere to X,Y). In both cases, the pair of nodes characterizes a binary symmetric relation whose members are X and Y (It is symmetric because there is nothing which enforces an order between X and Y). Just like in the previous case, its "direction" in regard to X and Y is a highly nuanced feature whose usage depends on the application.

<d05>

In the language of bidirected graphs, these two cases may be interpreted as an "introverted edge" and an "extraverted edge", respectively (See {%a href="https://en.wikipedia.org/wiki/Bidirected_graph"%}Bidirected Graph{%/a%}).

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Symmetric Relations</b></h3>

So far, I have only demonstrated relations which possess their own directions (i.e. asymmetry). It is, however, also feasible to construct a symmetric relation if we model it as though it is a pair of asymmetric relations pointing in two opposite directions. Its unary and binary examples are showcased below.

<d06>

Just like before, we are presuming here that each relation is a connected pair of dual particles (i.e. negative node and positive node). Recall the previous examples, and see how the new ones differ from them.

Suppose that X is the only member of the relation. If X is connected to both the negative and positive sides, we will be able to say that the relation points both toward and away from X. This means that it is an unary relation which associates itself with X without specifying any particular direction in regard to it.

Suppose, on the other hand, that X and Y are both members of the relation. If X and Y are simultaneously connected to both the negative and positive sides, we will be able to say that the relation points both toward and away from X and Y. This means that it is a binary relation which associates itself with X and Y without specifying any particular direction between them.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>N-Ary Relations in an Undirected Graph</b></h3>

The main benefit of using dual (negative and positive) nodes as means of formulating relations can be found in the case of n-ary relations, where 'n' is an arbitrary integer which is greater than 2.

Traditionally, it has been presumed that only binary relations can adequately be rendered in the standard graph notation (i.e. edges and vertices). What I would like to suggest in this article is that, by means of negative and positive nodes, it is possible to represent even an n-ary relation (where n > 2) in a plain undirected graph (That is, by drawing only dots and lines on a sheet of paper, along with a bit of symbolic characters such as '-', '+', and alphanumerics).

The image below shows three examples of the idea I just mentioned, the first two being ternary relations and the last one being a quaternary relation.

The first case depicts an instance of "merge" - i.e. a scenario in which two separate things (X1,X2) merge into one thing (Y). The order of the things which are being merged does not matter, so this relation is symmetric with respect to X1 and X2.

The second case depicts an instance of "split" - i.e. a scenario in which one thing (X) splits into two things (Y1,Y2). The order of the things which are being produced by the split does not matter, so this relation is symmetric with respect to Y1 and Y2.

The third case depicts an instance of "exchange" - i.e. a scenario in which two things (X1,X2) interact with each other, exchange resources, and end up turning themselves into a pair of things (Y1,Y2) which are somewhat different from the previous two. Since this particular act of exchange does not imply a sense of directionality from one thing to the other, this relation is symmetric with respect to both the former pair (X1,X2) and the latter pair (Y1,Y2).

<d07>

What about n-ary relations which require a fixed order between its members? The image below illustrates ways in which such a strict sense of asymmetry can be achieved.

The first case indicates an instance of "split", yet the outcome of the split is a vector of two components (Y1,Y2) instead of a set. Here, the order between Y1 and Y2 is being enforced by the order in which the two positive nodes are connected with respect to the negative node.

The second case indicates an instance of "merge", yet the ingredients of the merging process is a vector of two components (X1,X2) instead of a set. Here, the order between X1 and X2 is being enforced by the order in which the two negative nodes are connected with respect to the positive node.

<d08>

In general, it is definitely feasible to construct any arbitrary n-ary relation and selectively make parts of its list of members either symmetric or asymmetric, by means of dual (negative and positive) nodes connected in series. The number of connected negative (or positive) nodes will imply the number of members in a group whose order is strictly enforced (as though they are elements of a vector), and the number of parallel connections to each negative (or positive) node will imply the number of members in a group whose order does not matter (as though they are elements of a set).

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Practical Applications</b></h3>

Visualization is not the only advantage which can be gained by the aforementioned methodology. One of the upsides of modeling a concept in the form of a plain undirected graph (instead of something fancy such as hypergraph) is that it can easily be translated into a physical equivalent such as an electric circuit (which is useful for applications in science/engineering).

A vertex or a connected set of vertices, for example, can be modeled as a circuit component (e.g. logic gate, amplifier, buffer, arithmetic module, memory module, etc), and an undirected edge can be modeled as a wire which establishes an electrical connection between a pair of circuit components.

If engineers happen to desire to create a specialized computational system (such as a custom circuit) which uses relations as its basic unit of computation, therefore, they will find the nodal representation of n-ary relations to be a helpful means of devising a piece of hardware in which each relation is implemented not as a piece of abstract data inside a random-access array, but as a real physical device which occupies an area on the circuit board.

This kind of implementation will be optimal for interpreting a logic programming language such as Prolog, which is based upon relations and their mappings (i.e. horn clauses).

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Further Readings</b></h3>

1. {%a href="https://thingspool.net/reality/page-4.html"%}The Origin of Reality - Volume 4{%/a%}
2. {%a href="https://thingspool.net/reality/page-7.html"%}The Origin of Reality - Volume 7{%/a%}
3. {%a href="https://thingspool.net/metaphysics/page-59.html"%}연결의 종류 (Korean){%/a%}
4. {%a href="https://thingspool.net/metaphysics/page-61.html"%}이진법적 공간의 배열 (Korean){%/a%}
5. {%a href="https://thingspool.net/metaphysics/page-62.html"%}공간의 근본적 형태들 (Korean){%/a%}








:d:This article explains how a game can be made in Prolog by leveraging the hidden power of logic programming. Inspired by the elegance of data-driven design and declarative programming paradigms, I will be explaining a new way of designing game rules which can at the same time be used as the source code of the gameplay system itself.
:k:Prolog, Logic Programming, Declarative Programming, Data Driven Design, GM Tool, Technical Game Design, Gameplay Systems, Emergent Systems, Game Design, Game Development, Game Systems Design, Game Mechanics, Systems Engineering, Design Patterns, Simulations, Computer Science, Computer Engineering, Software Engineering
:l:2024-08-25

[Game Programming in Prolog - Part 1] August 25, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Introduction</b></h3>

As a fan of unconventional programming paradigms, I enjoy learning new programming languages which are drastically different from the typical object-oriented ones such as C#, Java, and the like. The most iconic of them are LISP (which is a powerful language for both functional programming as well as metalinguistic patterns in software development) and Prolog (which is one of the most popular languages in logic programming). Learning these languages is quite hard, compared to being acquainted with usual C-style imperative languages such as Ruby and Python, yet it has turned out to be one of the most effective ways of exercising one's brain.

By the time I started learning LISP via MIT's 1986 lecture series called "SICP (Structure and Interpretation of Computer Programs)" back in 2018, I was already quite familiar with some of its core concepts (such as lambda expressions, higher-order functions, etc) because they were already integrated as some of the main features of C#, which was the language I was using all the time as a Unity game developer. Also, my academic background in electrical engineering (signal processing in particular) helped me easily grasp the idea of "stream processing" which appeared in the latter half of the lecture series. Thus, learning LISP and its functional design patterns was not as difficult as I imagined it to be.

A major intellectual challenge, however, struck me when I began to study Prolog - the famous logic programming language which is notorious for its esoteric syntax. The grammar itself did not appear to be complicated at all; it was just as minimal as that of LISP. The way in which programming had to be done in Prolog, though, was stressful enough to fry the engine of my brain. The way it approached data structures (such as lists) and algorithms based upon mathematical relations was something so revolutionarily novel to me, that it seriously opened up a new horizon in my faculty of computational reasoning.

While Prolog's approach in software development was quite alien to me, I managed to notice a number of familiar associations between Prolog and many useful topics in engineering. I discovered, for example, that the so-called "relational databases" (e.g. MySQL) are named so not because they comprise data tables which are related to each other via references, but because each row of a data table can be considered an n-ary predicate (where 'n' is the number of columns in the table) in Prolog's syntax. Besides, I found out that the input/output behavior of each digital circuit component (e.g. logic gate) could be implemented as an n-ary relation (where 'n' is the total number of the input/output ports combined), implying that an "object", whether it be a piece of hardware or a piece of pure data in memory, may as well be defined as a relation in logic programming (just like an object may as well be defined as a function in functional programming). Furthermore, the declarative nature of Prolog strongly convinced me that it must be optimal for data-driven design.

These realizations soon led me to contemplate upon the notion that, maybe, logic programming has a great deal of potential in the design and implementation of highly complex systems, such as a video game's core gameplay mechanics. I began to ask myself, "Will it be possible to develop an entire game using the grammar of logic programming?"

Indeed, there are reasons why most game developers just stick to general-purpose programming languages (such as C#) for making games, aside from purely experimental purposes. Implementing an entire game based on Prolog, for instance, is perhaps too much of a challenge for those who are not hardcore mathematicians. Also, Prolog may not be the best language to use for parts of the project which are not necessarily made of a complex web of relations, such as simple I/O modules, graphics modules, audio modules, physics modules, and the like.

However, I believe that at least the core mechanics of a game can definitely be implemented using the language of Prolog, and that we will be able to solve a plethora of complex design problems by doing so. It is because a gameplay system which is structured in terms of a set of declarative statements will be far more robust, modular, and free of confusing edge cases (e.g. race conditions) than an imperative system.

For this alternative methodology to be successful, one must start by designing the system in terms of logical relations/predicates only, and nothing else (That is, no functions, no structs, no classes, no interfaces, no state variables, etc). This will allow us to construct a gameplay system which is purely driven by the soul of Prolog.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>World and Actors</b></h3>

The core idea in Prolog-based game programming is to utilize relations as the most primitive building blocks of the system, just like basic circuit components (e.g. resistors, transistors, capacitors, inductors, etc) are the most primitive building blocks of an electric circuit. It is sensible, therefore, to start this journey by considering the most rudimentary relations (e.g. unary and binary) first, and see if these elements can serve as the most essential nuts and bolts of the game.

<e01>

Suppose that we are designing a game, and that the game consists of two major parts - world and actors (see the image above). The world is a scene in which everything is supposed to happen, and actors are objects which belong to the world. Examples of actors include "players", "enemies", "obstacles", "items", and pretty much any discrete entities which have their own names and attributes. Actors are able to interact with each other (as well as with themselves), from which various events occur. What we refer to as "gameplay" is a chain of such events.

We will begin formulating a gameplay system based off of this conceptual backbone. All you need to remember is that there is a world, and that the world contains a number of actors, each of which possesses its own state and behavior.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Tags</b></h3>

First of all, let us identify each individual actor with a unique name. If there are two actors in the world, for instance, we will simply assume that the name "actor1" and "actor2" will be used to indicate the first and second actors, respectively.

<e02>

The first piece of logic I will illustrate is the idea of tags. A tag is a keyword which, when attached to an actor, describes what the actor stands for. When an actor has the tag "bread" attached to it, for example, we should be able to tell that the actor is a piece of bread.

The Prolog code below assigns the tag "bread" to both actor1 and actor2, in the form of unary predicates (The tag "bread" itself is an unary relation, and "bread(actor1)" & "bread(actor2)" are two separate instances of it). This implies that both actor1 and actor2 are pieces of bread.

#$
bread(actor1).
bread(actor2).
#$

<e03>

An actor can have multiple tags as well. However, one may feel that it is a bit too tedious to manually assign a bunch of tags to each individual actor. For example, let us say that every piece of bread must also be labeled as flammable and decomposable. This means that, whenever an actor is associated with the tag "bread", we are obliged to always ensure that it is also associated with the tag "flammable" and "decomposable". Manually attaching these two additional tags to every "bread" actor is way too cumbersome and error-prone. Fortunately, the following pair of horn clauses neatly solve this problem. They enforce the following two rules:

(1) Whenever tag "bread" is assigned to actor X, tag "flammable" will automatically be assigned to actor X.
(2) Whenever tag "bread" is assigned to actor X, tag "decomposable" will automatically be assigned to actor X.

#$
flammable(X) :- bread(X).
decomposable(X) :- bread(X).
#$

<e04>

These horn clauses, therefore, serve as part of the game's "config data" - a list of data entries in the game's technical design document (like the ones you would see on a spreadsheet) telling us the characteristics of each individual character type, skill type, mission type, and so forth. The tags called "flammable" and "decomposable" in our case, for instance, are characteristics which belong to the type-specifier called "bread", meaning that any actor which can be identified as "bread" is a composition of two properties called "flammable" and "decomposable".

A decent analogy can be found in Unity game engine, where we may create a prefab called "Bread" with two components in it - "Flammable" and "Decomposable". Or, in a general object-oriented programming environment, "Bread" may stand for the name of a class which implements two interfaces called "IFlammable" and "IDecomposable".

In a way, therefore, horn clauses in Prolog play the role of data type definitions.

<e05>

Aside from these pre-configured tags (which all rely on the presence of the tag "bread"), one may as well attach a custom tag to an actor as needed. For example, imagine that a wizard happened to enchant actor2 (i.e. the second piece of bread). This means that, unlike actor1 which is an ordinary piece of bread, actor2 must be an "enchanted" piece of bread which is required to have the tag "enchanted" attached to it for the purpose of showing us that it has been enchanted. The code below ensures that this is the case.

#$
enchanted(actor2).
#$

<e06>

The tags "flammable" and "decomposable" are characteristics of all pieces of bread, whereas the tag "enchanted" is a characteristic of only special pieces of bread which have been enchanted by a wizard.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Relationships</b></h3>

So far, we have been using tags for specifying the characteristics of each individual actor. In a gameplay system, however, we also need to specify relationships between actors, such as ways in which they interact, etc.

In an ecosystem, predators chase preys and preys run from predators. In a dating simulator, a guy tries to flirt with girls and girls reject him. In a social simulator (such as The Sims), people are either friends or enemies of each other, or somewhere in between. In the game of chess, a bishop devours a rook diagonally and a rook devours a bishop orthogonally. These are all relationships out of which the game's dynamics emerge.

Defining actor-to-actor relationships in Prolog is pretty straightforward. Just like an unary predicate can be used to characterize a single actor, a binary predicate can be used to characterize a relationship between a pair of actors. And by means of a horn clause, such a relationship can be dynamically deduced from a set of requisite conditions.

The following code is an example of a relationship. Suppose that there is a third actor called "actor3", and that we have declared it as a human (by attaching the tag "human" to it). Since a human is able to eat a piece of bread, we can confidently assert that "X can eat Y if X is a human and Y is a piece of bread". Here, "X can eat Y" is a relationship which holds whenever X is associated with tag "human" and Y is associated with tag "bread".

#$
human(actor3).
canEat(X, Y) :- human(X), bread(Y).
#$

<e07>

Here is another example. Since a piece of bread is decomposable (because anything which is identified as "bread" must also be identified as "decomposable"), we know that microbes such as fungi are capable of spoiling it. If there is an actor with the tag "fungus" attached to it, therefore, we will be able to tell that it must be able to spoil any other actor which is "decomposable". This is yet another case of a relationship between two types of actors; it is a relationship which says, "X can spoil Y if X is a fungus and Y is decomposable". The following code shows its definition.

#$
fungus(actor4).
canSpoil(X, Y) :- fungus(X), decomposable(Y).
#$

<e08>

There is something still missing here, though. While I have demonstrated that it is possible to assign characteristics to individual actors as well as their mutual connections (i.e. relationships), I have not shown yet how to make these characteristics change over time. They all have been static so far, and the declarative nature of Prolog does not seem to offer an easy solution to make things dynamic.

If we want to create a game rather than a fixed landscape of how things are shaped permanently, we better let them move and interact as time goes by. In the next part of the series, I will explain how the game loop shall be conceptualized in Prolog.

(Will be continued in {%a href="https://thingspool.net/morsels/page-11.html"%}Part 2{%/a%})









:d:This article explains how a game can be made in Prolog by leveraging the hidden power of logic programming. Inspired by the elegance of data-driven design and declarative programming paradigms, I will be explaining a new way of designing gameplay systems which is way more robust, concise, and error-free than traditional methods.
:k:Prolog, Logic Programming, Declarative Programming, Data Driven Design, GM Tool, Technical Game Design, Gameplay Systems, Emergent Systems, Game Design, Game Development, Game Systems Design, Game Mechanics, Systems Engineering, Design Patterns, Simulations, Computer Science, Computer Engineering, Software Engineering, Ludology, Game Science, LISP, Functional Programming
:l:2024-08-29

[Game Programming in Prolog - Part 2] August 29, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 2 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Numerical Attributes</b></h3>

So far, I have been demonstrating ways in which we can assign tags and relationships to each of the gameplay agents (aka "actors"). The key takeaway is to use predicates to specify them, as well as leverage the power of logical relations for letting the program automatically instantiate such predicates.

By the same spirit, we are also able to assign a numerical attribute to an actor. Suppose that an actor called "actor3" is tagged "human", and that we would like to ensure that every human actor has an attribute named "numLegs" which indicates the person's number of legs (i.e. 2). The following horn clause, then, will fulfill this objective.

#$
numLegs(X, 2) :- human(X).
#$

<e09>

The binary predicate, "numLegs", is a numerical attribute of every human actor which tells us that the actor's number of legs is 2. This differs from a simple tag (i.e. keyword) in the sense that it also contains a number. This allows us to specify different "numLegs" values to different species of actors, like the ones shown below.

#$
numLegs(X, 2) :- human(X).
numLegs(X, 4) :- dog(X).
numLegs(X, 4) :- cat(X).
numLegs(X, 3) :- martianTripod(X).
#$

<e10>

If every martian tripod were a faithful reader of George Orwell and happened to interpret every single phrase of his novel "Animal Farm" in the most blatantly literal manner, it would be reasonable to conclude that a martian tripod is likely to protect four-legged creatures and kill two-legged creatures ("Four Legs Good, Two Legs Bad"). These behavioral patterns can be implemented using horn clauses, which are illustrated below.

#$
shouldProtect(X, Y) :- martianTripod(X), numLegs(Y, 4).
shouldKill(X, Y) :- martianTripod(X), numLegs(Y, 2).
#$

<e11>

And of course, it is equally feasible to devise a numerical attribute which involves multiple actors, similar to the concept of relationship I have demonstrated before. For instance, imagine that a dog's degree of loyalty to a human being is 6, while a cat's degree of loyalty to a human being is only 2. These two numerical relationships can be modeled as two slightly different ternary relations, like the ones shown below.

#$
loyalty(X, Y, 6) :- dog(X), human(Y).
loyalty(X, Y, 2) :- cat(X), human(Y).
#$

<e12>*

This sort of reasoning can be expanded indefinitely. For example, one may as well define a numerical attribute which carries not just a single number, but multiple numbers (i.e. vector quantity). One may also define a relationship which involves not just two actors, but three or more actors, such as: "This girl hates her boyfriend for showing too much affection to the other girl", etc.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>State and Time</b></h3>

Things have been looking good so far. We know how to create attributes and relationships, as well as how to assign them to our gameplay agents, and so forth. However, we cannot make a game out of these building blocks alone.

What has been missing here is a sense of change over time. We want actors to move, interact, and make impacts upon the world as well as upon themselves. What we've got so far, instead, is a mere snapshot of how things are related to each other; there is no moving part at all.

So, how to turn this static world into something dynamic? First of all, let us recall the way in which an imperative programming language would approach this problem. In a typical imperative language such as C, C++, or Java, creating a sense of change is simple and straightforward.

Suppose that there is a clock which ticks at regular intervals. Every time it ticks, it calls a function called "Update". If there is an actor who is supposed to get hungrier and hungrier as time passes by, all we have to do in an imperative language is to access the actor's state variable called "hunger" and increase its value whenever the "Update" function runs (See the code below).

#$
void Update(Actor x)
{
    x.hunger = x.hunger + 1;
}
#$

This kind of logic is possible because the variable we are dealing with (i.e. hunger) is a state variable; we are allowed to assign a new value to it at any moment.

In a declarative language such as Prolog, unfortunately, we cannot just declare a state variable and modify its value whenever we want to. Logical relations are timeless beings; they exist outside of the realm of time, which means that it is nonsensical to try to associate them with variables which are bound to certain points in time.

What do we do, then? In order to mimic state transition in logic programming, we must approach the concept of time from a different angle. Rather than trying to directly manipulate the current state of the game while it is running, we ought to instead define a set of time-invariant statements which tell us how the past and present are related.

<e13>

The figure above illustrates the core difference between the imperative and declarative means of running the game. Suppose that the game's state is being recorded in the computer's memory space (e.g. RAM), which is just an array of data slots.

In the imperative case, there is one chunk of data called "state". The game looks up this chunk of data, computes the new state, and overwrites this new state on top of the original chunk of data. This is what the assignment operator (i.e. "=") does in an imperative language.

In the declarative case, on the other hand, direct mutation of data is prohibited. At the beginning of each frame, the game first accesses the chunk of data at which the previous state was located. It computes the new state based on the previous state, and allocates this new state to a location which is currently not being used. The system does not tamper with the previous state; it simply appends the new state to the history of states without erasing or modifying the existing data.

<e14>

The main advantage of this approach is that it gracefully prevents race conditions. Since it does not "change" any existing piece of data, it never has to worry about inadvertently disrupting another computational process which may have been accessing the same location in memory.

Of course, continually adding new copies of the game's state without deleting anything is too wasteful. Such an ever-growing list of states (which altogether constitute the game's "history"), unless the gameplay is either turn-based or very short in duration, is likely to eat up too much space in memory. This is clearly not desirable.

Such a problem, however, can easily be mitigated by limiting the maximum duration of time through which an event's effect is able to propagate. For example, if the game's current state is entirely determined by events which happened only up to N steps back in time, it will imply that the system only needs to retain the memory of N previous states (which corredpond to the N previous time steps) and nothing older than that. As you can see in the image below, this means that memory slots which are sufficiently old can simply be recycled for other purposes.

<e15>

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>State Transition</b></h3>

So, how do we implement such a declarative state transition mechanic in the language of Prolog?

Let us first examine how the functional paradigm would approach this problem. In functional programming (e.g. LISP), the game's "Update" function simply needs to take the previous state of the game as the input, instantiate the new state based off of the given previous state, and return this new state as the output. The returned output will then be appended to the game's state history as the most recent state, and the game loop (which is another function which is responsible for calling the "Update" function) will call the "Update" function once again, and again, and again, and so on, thereby periodically updating the game (For more details, please read: {%a href="https://thingspool.net/software-development/page-21.html"%}Functional Programming for Game Development{%/a%}).

In logic programming (e.g. Prolog), on the other hand, we cannot use such a functional methodology because functions are not a thing here. Instead, we must specify relations between the current and previous states, in a manner which resembles that of the so-called "difference equations" in mathematics.

In order to demonstrate how it works, let me first augment the syntax of Prolog a bit by introducing a number of additional symbols. These are not part of the standard Prolog (which means whichever Prolog interpreter you use won't be able to recognize them), so please keep that in mind. Any Prolog code you are going to see from now on should be taken as pseudocode, meant to serve as a mere proof of concept.

The snippet below is a list of notations which will be used to illustrate the game's temporal relations.

#$
n = (current time step)
n-1 = (previous time step)
X[n] = (X at the current time step)
X[n-1] = (X at the previous time step)
X = (X at any time)
#$

Suppose that the game loop keeps track of time in discrete time steps, beginning with n = 0 and periodically incrementing it one by one (i.e. n = 1, n = 2, n = 3, etc). The symbol 'n' refers to the game's current time step, which means that 'n-1' refers to the previous time step, 'n-2' refers to the previous-previous time step (i.e. two steps back in time), and so on.

What's important here is the bracketed notation (e.g. "X[n]"). So far, I have only shown Prolog statements which involved timeless entities. Things like "actor1", "actor2", and "actor3", for instance, involved no concept of time whatsoever. Thus, there was no need to state their associations with respect to time.

When it comes to indicating an actor at a specific point in time, on the other hand, we can no longer just stick to a simple notation such as "X" because, if we do, we will be referring to the presence of the actor throughout the entirety of time. So in this case, we ought to attach an additional time parameter to the actor's identifier (e.g. "X[n]" for current X, "X[n-1]" for previous X, etc).

<e16>

Before elaborating further, let me first introduce a couple of arithmetic relations which I will be using quite frequently from now on (See the snippet below). The "equal(...)" relation holds whenever its parameters are equal in value, meaning that "equal(3, 3)" and "equal(5, 5)" are TRUE, whereas "equal(1, 2)" and "equal(3, 5)" are FALSE. The "add(...)" relation holds whenever the sum of its first two parameters yields the value of its last parameter, meaning that "add(2, 2, 4)" and "add(3, 4, 7)" are TRUE, whereas "add(1, 2, 5)" and "add(4, 0, 6)" are FALSE. The "multiply(...)" relation works in a similar fashion.

#$
equal(A, B) = (TRUE if A = B)
add(A, B, C) = (TRUE if A + B = C)
multiply(A, B, C) = (TRUE if AB = C)
#$

I will now explain how time-dependent relations can be used to implement gameplay dynamics. Imagine that there is an actor which is tagged as "human". Also, let us assume that this actor was spawned at some point in time. What we want here is to let this actor have its own state variable called "hunger", which starts at 0 (when the actor spawns) and increments itself by 1 every time the clock ticks.

The code below shows how it can be formulated in terms of executable rules.

#$
hunger(X[n], 0) :- human(X[n]), spawnTime(X, n).
hunger(X[n], Curr) :- hunger(X[n-1], Prev), add(Prev, 1, Curr).
#$

<e17>

The first horn clause says that, if there is a human actor who just spawned right at the present moment (i.e. "n"), we must initialize its hunger to 0. This clause gets executed only once when the actor spawns, since it is the only moment at which "spawnTime(X, n)" can be evaluated as TRUE (Note: "spawnTime(X, n)" basically asks the question, "Is the current time the same as X's spawn time?").

The second horn clause says that, if there was an actor which had a state variable named "hunger" during the previous time step, its current hunger must be 1 greater than the previous hunger. This clause gets executed each time the clock ticks (i.e. whenever the time step increments by 1). It does NOT get executed during the moment at which the actor spawns, since "X[n-1]" is nonexistent during that time.

The first clause initializes the hunger, and the second clause periodically increments the hunger (because a human being is supposed to get hungrier and hungrier as time goes by).

But of course, the game will be pretty boring if all we can do is watch a human character starve. If we are to design a life simulator (like The Sims), for instance, there better be a way to quench the person's hunger by letting him/her eat some food.

Here is a bit of a trouble, though. We already have a rule which tells us that the hunger must increase by 1 each time the clock ticks. If we add a new rule which describes how much the hunger must go down when the actor eats food, this new rule will be incompatible with the existing one because it is logically contradictory to have two different horn clauses which are both trying to define the same piece of data (i.e. "X[n]") simultaneously.

There is a pretty neat solution to this, fortunately. All we have to do is separately compute the amount of natural increment in hunger (aka "naturalChangeInHunger") and the amount of reduction in hunger due to the act of eating (aka "digestiveChangeInHunger"), and then combine them together into a single differential. Their implementations are shown below.

#$
naturalChangeInHunger(X[n], 1) :- hunger(X[n], _).
digestiveChangeInHunger(X[n], ChangeInHunger) :- hunger(X[n], _), eat(X[n], Food[n]), calories(Food[n], NumCalories), multiply(NumCalories, -1, ChangeInHunger).
digestiveChangeInHunger(X[n], 0) :- hunger(X[n], _), !eat(X[n], Food[n]).
#$

<e18>

The first clause is easy to understand; it simply states that the natural change in hunger is always 1 (i.e. If the actor doesn't do anything, it naturally gets hungrier by the degree of 1 after each time step). The meaning of the second/third clauses is that, if an actor is currently eating some food, its hunger must be going down by the number of calories in the food (or 0 if the actor is not eating anything. This negatory relation is denoted by "!eat(...)").

One of the notable benefits of such mutually independent clauses is that they can run in parallel (by means of multi-threading or even GPU-based programs such as "compute shaders"). This provides us with yet another reason why logic programming is a great paradigm for gameplay engineering.

Anyways, once the application obtains the results of "naturalChangeInHunger" and "digestiveChangeInHunger", the only remaining step is to sum up these two results (which will be carried out by the predicate called "netChangeInHunger") and then add this sum to the actor's hunger, just as shown below.

#$
netChangeInHunger(X[n], NetChange) :- naturalChangeInHunger(X[n], Change1), digestiveChangeInHunger(X[n], Change2), add(Change1, Change2, NetChange).

hunger(X[n], Curr) :- hunger(X[n-1], Prev), netChangeInHunger(X[n-1], NetChange), add(Prev, NetChange, Curr).
#$

<e19>

(Will be continued in {%a href="https://thingspool.net/morsels/page-12.html"%}Part 3{%/a%})









:d:This article explains how you can use the language of Prolog to develop a game. It leverages the built-in syntactic elegance of Prolog, as well as its data-driven and declarative design philosophy.
:k:Prolog, Logic Programming, Declarative Programming, Functional Programming, Data Driven, LISP, Scheme, MIT Scheme, Metalinguistic, Systems Engineering, Signals And Systems, Linear Systems, DSP, Digital Signal Processing, Game Design, Game Mechanics, Game Programming, Game Development, Ludology, Game Science, Game Research, AI, Artificial Intelligence, Discrete Math, Computer Science, Data Structure, Algorithm, Theory Of Relativity, Concurrent Programming, Multithreading, Parallel Computing
:l:2024-09-02

[Game Programming in Prolog - Part 3] September 2, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 3 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Causality</b></h3>

So far, I have shown how the parameterization of time steps can indeed be a powerful tool for triggering state transitions in the system. In order to better understand the reasoning behind this, however, we ought to take a step back and really try to see the overall picture of what is going on behind the formulas.

Whenever we are dealing with the system's state and its means of transition, we are essentially thinking in terms of causes and their corresponding effects. A horn clause, for instance, is a rule which tells us what kind of effect can be generated based upon a given set of causes, just as illustrated below.

#$
effect(...) :- cause1(...), cause2(...), cause3(...).
#$

<e20>

A nice way of visualizing such a causal phenomenon is to imagine each of the predicates (i.e. either a cause or effect) as a point in spacetime.

Spacetime is simply a dimensional representation of the game's history; it consists of spatial axes as well as a time axis. When you throw a rock in the upward direction, for example, you will be able to plot its trajectory in spacetime as a parabola (because it will rise, stop, and fall).

Here is the catch, though. An effect is a product of causes, yet such an effect itself may as well be a cause of another effect. Thus, it does not quite make sense to try to establish a strict distinction between causes and effects. Depending on how our causal chains are interwoven, an effect could as well be identified as a cause and vice versa.

A unifying terminology between cause and effect is "event". Our spacetime is filled with events; each point in spacetime is an event, and an directed line segment (i.e. arrow) between two points in spacetime is a causal connection which leads one event to another. The code below is an example of a horn clause which defines "event3" as a product of two such connections (one between "event1" and "event3", and the other one between "event2" and "event3"). Here, "event1" and "event2" are the causes of "event3", and "event3" is the effect of "event1" and "event2".

#$
event3(...[n]) :- event1(...[n-1]), event2(...[n-2]).
#$

<e21>

In general, our gameplay system can be thought of as a collection of causal rules, each of which specifies a type of event which can be generated out of a set of preceding events. These rules, as they get applied to the game loop over and over as time elapses (in a periodic manner), gradually map out the fabric of causal connections in spacetime, revealing us the full picture of which events are related to which. This implies that the full history of the gameplay itself can be modeled as an "event graph" - an instance of a DAG (Directed Acyclic Graph), which is reminiscent of the so-called "blockchain", "hashgraph", and other event sourcing protocols.

"But," someone might say, "But! Don't you think that not all predicates represent events? If a horn clause happens to contain a relation called 'bread(X)', for instance, it must be obvious that this particular relation simply serves as a tag which declares that X is a piece of bread. It is by no means an event; it is just an indicator, and nothing more than that."

Such a line of thought definitely makes sense from a layman's point of view. An indicative relation such as "bread(X)", as it comprises a simple noun, is indeed something which feels hardly anything more than a mere semantic reference. From a strictly spacetime-oriented perspective, however, one must be able to consider every logical predicate as an event, even if it happens to serve as an identifier.

Let me show you an example. Suppose that there is an arbitrary hydrogen atom called "X". The identity of such an atom can be described by the code below:

#$
hydrogen(X).
#$

<e22>

What this relation really means, though, is: "There is an atom called 'X' which can be identified as 'hydrogen' at every moment of its existence". Thus, a more comprehensive means of expressing this relation would be the one shown below:

#$
hydrogen(X[n]) :- spawnTime(X, n).
hydrogen(X[n]) :- hydrogen(X[n-1]).
#$

<e23>

The true meaning of "hydrogen(X)" is that there is a chain of events in spacetime which consistently keep telling us that there has been a hydrogen atom called "X", whose line of existence began at X's moment of birth (aka "spawnTime") and has henceforth been growing itself through the passage in time. The first horn clause establishes the base case (i.e. first occurrence of the "hydrogen" event), and the second horn clause establishes the recursive case which generates the succeeding chain of "hydrogen" events.

In a way, therefore, a simple name tag such as "hydrogen(X)" can be interpreted as a connected sequence of points (events) in spacetime. The key takeaway here is that the very concept of "object" (i.e. a distinct body of existence) itself should be understood as a line in the hyperdimensional geometry of our universe, similiar to what physicists refer to as a "world line" - a four-dimensional path of an object in spacetime.

And of course, when individual atoms bond with one another, they form a molecule. Such a molecule, too, can be considered a discrete object with its own line of existence in spacetime.

An example case is demonstrated below. When two hydrogen atoms (X, Y) and an oxygen atom (Z) bond, they altogether form a water molecule. In this case, the birth of the water molecule (which is an event) may as well be considered an effect which was produced by the four causes listed below:

(1) The existence of the first hydrogen atom X at time n-1.
(2) The existence of the second hydrogen atom Y at time n-1.
(3) The existence of the oxygen atom Z at time n-1.
(4) The bonding of the aforementioned three atoms at time n-1.

#$
water(X[n], Y[n], Z[n]) :- hydrogen(X[n-1]), hydrogen(Y[n-1]), oxygen(Z[n-1]), bond(X[n-1], Y[n-1], Z[n-1]).
#$

<e24>

The inverse scenario of the bonding process is the act of split, which in this case can be depicted as the splitting of the water molecule into its individual component atoms (2 hydrogens and 1 oxygen). This, too, should be able to be rendered as a set of causal connections between events, just as shown below.

#$
hydrogen(X[n]) :- water(X[n-1], Y[n-1], Z[n-1]), split(X[n-1], Y[n-1], Z[n-1]).
hydrogen(Y[n]) :- water(X[n-1], Y[n-1], Z[n-1]), split(X[n-1], Y[n-1], Z[n-1]).
oxygen(Z[n]) :- water(X[n-1], Y[n-1], Z[n-1]), split(X[n-1], Y[n-1], Z[n-1]).
#$

<e25>

A Prolog-based gameplay system is extremely straightforward in nature, if you think about it for a second. In this virtual universe, everything is an event and events are causally related to each other via horn clauses (aka "rules").

As time passes by, events which are sufficiently old (i.e. so old that they no longer influence any of the future events) get discarded because they are obsolete. Meanwhile, the game loop keeps ticking its clock, generating new events in spacetime (i.e. those which belong to time 'n'). These new events get registered to the memory, while the oldest ones get thrown away. This means that there is a "window of remembrance" in spacetime which covers events that are fairly recent (see the image below).

<e26>

Events which fall within this window are the ones which are being kept in the computer's memory. As old events get discarded (i.e. exit the window through the left edge), their corresponding memory slots get freed up. And as new events get created (i.e. enter the window through the right edge), they get stored in these freed up slots. Thus, the same array of memory slots get recycled over and over again, just like in any other dynamic memory allocation system. This proves that Prolog is a sound choice even from the perspective of memory optimization.

(Note: If you force every event to occupy the same exact amount of space in memory, you will be able to simplify the allocation scheme even further because the system will only need to keep track of free slot indices, not how large those free slots are.)

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>On Theory of Relativity</b></h3>

Here is something I would like to point out before proceeding to the next chapter. The model of spacetime which I have explicated by far is a strictly Newtonian one, meaning that every "present event" is nicely aligned within the same exact time step (i.e. "n"). This is because all present events get generated by the gameplay system in a completely synchronous (aka "lockstep") manner. Here, time is an independent variable and we can easily tell which events are simultanous with each other and which ones are not. If two or more events belong to the same time step, they must be considered simultaneous.

<e27>

When a multitude of game loops (i.e. threads) are running concurrently, however, we can no longer easily tell which events are simultaneous with which. Besides, the presence of multiple game loops implies the presence of multiple clocks running independently, suggesting that we cannot even be sure which events belong to the "present moment" and which ones do not (because there would be more than a single frame of reference in time).

<e28>

Furthermore, depending on the order in which the game loops update themselves and which clusters of events they happen to be updating at each clock cycle, there is likely to be some kind of "propagation delay" among the events' forces of influence (due to the limit in the speed of light - the maximum rate at which information travels in space).

Such lack of simultaneity in events and their causal connections inevitably forces us to reimagine space as a fabric of causal relations (i.e. event graph), rather than a fixed coordinate system (i.e. Euclidean space) in which the notion of time can simply be expressed as an independent dimension.

This apparent lack of absolute synchronicity among events, introduced by the coexistence of multiple concurrent event-generating processes of the universe, reminds us of two analogous topics in academia, one of which belongs to computer science and the other one of which belongs to modern physics.

In computer science, the aforementioned notion of concurrency is considered the main source of many time-related algorithmic errors such as race conditions, where the evil can be attributed to the misordering of operations (which is quite common in imperative programming) which may have been caused not only by the programmer's coding mistake, but also by the lack of certainty in the speed at which the result of operation gets broadcasted from thread to thread.

In modern physics, concurrency of events and their apparent lack of ability to sync up instantly (due to the fact that their waves of influence cannot move faster than light) comprise one of the core pillars of Einstein's Theory of Relativity, where space and time can be "warped" based on the way in which events are causally connected.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Lockstep</b></h3>

In the case of a single-threaded gameplay system, though, we do not have to worry about any of the aforementioned perils of asynchronicity. As long as our Prolog program sticks its mode of operation to a single game loop, we will be safe from any of the bizarre relativistic effects such as time dilation, etc. This also means that we may imagine the game world as a simple Newtonian model of spacetime, in which the spatiotemporal location of every event can be specified in terms of Cartesian coordinates.

The only potential source of error in a single-threaded Prolog application is the very logical ambiguity in the code itself, and nothing else. As long as the rules (i.e. horn clauses) are formulated in a manner which won't allow a loophole (such as unintended reliance on the order of operation), everything is going to be fine. An example of such an undesirable loophole is demonstrated below.

#$
carryUmbrella(Person[n]) :- rainy(City[n]), resident(Person[n], City[n]).
rainy(City[n]) :- cloudy(City[n-1]).
#$

<e29>*

This scenario tells us that, whenever a city gets cloudy, it must be rainy at the next time step. This is fine so far.

It also tells us that a rainy city must instantly make its residents carry umbrellas without any time delay. But alas! The rule which enforces the carrying of umbrellas is written BEFORE the rule which updates the "rainy" status of the city, which means that, by the time the city gets tagged as "rainy", the "carryUmbrella" rule would have already been examined and ignored.

This is the kind of race condition which may occur if we do not take sufficient care when ordering horn clauses whose lefthand and righthand sides both reference the same time step (i.e. "n"). There are multiple ways of preventing this kind of error, such as:

(1) Forcing the Prolog interpreter to scan the list of rules twice instead of just once, so that the "carryUmbrella" predicate will be recognized and be activated during the second scan (because the "rainy" predicate would have been activated by the end of the first scan), or,
(2) Just writing the rules in the correct order.

Both of these solutions will work, although they both involve their own tradeoffs. The first solution allows the two horn clauses to be written in any order, yet the necessity of scanning the whole code multiple times decreases the efficiency of the program. The second solution is great for efficiency, yet it requires extra care when writing the code.

(Will be continued in {%a href="https://thingspool.net/morsels/page-13.html"%}Part 4{%/a%})










:d:This article explains how to code in Prolog to make a game. By reading this, you will learn how the data-driven (declarative) grammar of Prolog will help developers create gameplay systems which are way more robust than their imperative counterparts, such as ones written in C++, C#, or Java.
:k:Prolog, Logic Programming, Declarative Programming, Data Driven, Design Patterns, Programming Paradigm, Metacircular, Metalanguage, DSP, Signal Processing, Game Design, Game Mechanics, Game Programming, Gamedev, Game Science, Games Study, AI, Artificial Intelligence, Expert System, Game Systems, Gameplay Systems, Technical Design
:l:2024-09-04

[Game Programming in Prolog - Part 4] September 4, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 4 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Space</b></h3>

A playable game must have its own space and time. It is because space without time is a mere snapshot, and time without space is a mere point.

In the last article, I explained the nature of time and how its progression could be conceptualized in the language of Prolog. However, I have not explained yet how to express the concept of space in Prolog. Since spatial reasoning is an indispensable part of almost all video games (except ones that are entirely text-based), being able to construct spatial elements and let them spatially interact with one another is crucial for the design of game mechanics.

So, how to express the idea of space in Prolog? In order to achieve this goal, we must first unlearn the traditional methods in computational geometry which are only appropriate for the imperative paradigm. Then, we ought to figure out how to model space as a collection of relations such as position, proximity, distance, direction, etc.

Let us first start with a few actors, assuming that we are able to specify each actor's spawn time as well as spawn position (The notation "<x, y>" refers to a vector quantity). Suppose that there are three of them, named "actor1", "actor2", and "actor3", respectively. Their declarations are displayed in the following code.

#$
spawnTime(actor1, 0).
spawnPosition(actor1, <0, 0>).
spawnTime(actor2, 0).
spawnPosition(actor2, <1, 0>).
spawnTime(actor3, 1).
spawnPosition(actor3, <2, 0>).
#$

<e30>

In this scenario, actor1 was born at time 0 and position <0, 0>, actor2 was born at time 0 and position <1, 0>, and actor3 was born at time 1 and position <2, 0>. This allows us to locate these three actors not just in time but also in space.

Of course, the statements above only show us where they were located when they were born. If there is no additional rule, we will be forced to assume that the positions of these three actors will simply be "undefined" shortly after they were born (because there won't be any "position(...)" predicate which will correspond to future time steps).

Thus, further elaboration is needed in order to ensure their spatial persistence. The following code illustrates how it can be achieved.

#$
position(X[n], P) :- spawnTime(X, n), spawnPosition(X, P).
position(X[n], P) :- move(X[n-1], P).
position(X[n], P) :- !move(X[n-1], _), position(X[n-1], P).
#$

<e31>

The first horn clause defines the base case, which says, "If actor X is created right now at position P, its current position must be P". This makes sense, doesn't it? If something is initially placed somewhere and absolutely no time has passed since then, we must be able to assert that its current position is identical to its initial position.

The second and third horn clauses specify the two alternative cases of recursion (This is an example of the so-called "decision tree").

The second horn clause tells us that if X moved to P during the previous time step, its current position must be P. Here, the "move" relation is plays the role of a differential which gets accumulated (integrated) into X's position as time elapses. This horn clause, thus, can be thought of as an accumulator (integrator) which produces the cumulative sum of the input stream of moves.

The third horn clause defines the "fallback" condition, which tells us that X's position should stay as it was before if X did not move at all. This, together with the second clause, ensures that X's position is always defined regardless of whether X has moved during the preceding time step or not. If X moved, the second clause would be activated. If X did NOT move, the third clause would be activated instead. This is Prolog's way of implementing the IF-ELSE logic.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Spatial Reasoning</b></h3>

This sounds reasonable so far. However, the rules above only tell us how to update an object's position based on its momentum. They do not tell us how the momentum itself shall be generated in the first place.

What makes an object move? There really are innumerable forces which may contribute to its motion, so it is probably a bit too cumbersome to list them all here. Thus, I will first begin with one of the most common means of triggering a movement in a video game - a keyboard-based character control.

The logic I am going to expound here is pretty simple. Suppose that there is a main character I want to control in a top-down 2D game. If I were to play it on a PC, I would expect myself to be able to control the character's left, right, up, and down movements by pressing the four arrow keys on the keyboard (i.e. "left arrow", "right arrow", "up arrow", and "down arrow").

In order to implement this mechanic, we ought to first let Prolog know what we mean by "left", "right", "up", and "down". The semantics of these four words are specified below.

#$
left(P1, P2) :- x(P1, X1), x(P2, X2), y(P1, Y1), y(P2, Y2), equal(Y1, Y2), add(X1, C, X2), greaterThan(C, 0).
right(P1, P2) :- x(P1, X1), x(P2, X2), y(P1, Y1), y(P2, Y2), equal(Y1, Y2), add(X2, C, X1), greaterThan(C, 0).
up(P1, P2) :- x(P1, X1), x(P2, X2), y(P1, Y1), y(P2, Y2), equal(X1, X2), add(Y1, C, Y2), greaterThan(C, 0).
down(P1, P2) :- x(P1, X1), x(P2, X2), y(P1, Y1), y(P2, Y2), equal(X1, X2), add(Y2, C, Y1), greaterThan(C, 0).
#$

<e32>

The "x(P, Xc)" relation asserts that the x-component of position P is Xc, and the "y(P, Yc)" relation asserts that the y-component of position P is Yc. This means that, in all of the four horn clauses listed above, the following definitions hold:

#$
P1 = <X1, Y1>
P2 = <X2, Y2>
#$

The idea here is to identify the type of direction which can be implied by a pair of positions: P1 and P2. For example, if it is possible to make P1 identical to P2 by adding a positive number to P1's x-component, we can say that P1 is to the left of P2. Or, if it is possible to make P2 identical to P1 by adding a positive number to P2's x-component, we can say that P1 is to the right of P2.

These four directional relations, however, are not descriptive enough to define all the spatial properties we need. For instance, they only tell us about directions; they do not involve the concept of distance whatsoever (which means that they cannot answer questions such as, "How much do I have to travel from P2 to the left to reach P1?", etc).

A slight revision ought to be made to fill out the missing information. The following code shows the same set of horn clauses demonstrated above, except that they are now equipped with the third parameter ("C") which tells us how far apart P1 is from P2.

So, for example, if you write the predicate "left(P1, pos2, c)", with the value of "pos2" and "c" specified and the value of "P1" being left as unknown, it will compute the value of P1 which is to the left of "pos2" by the distance of "c".

#$
left(P1, P2, C) :- x(P1, X1), x(P2, X2), y(P1, Y1), y(P2, Y2), equal(Y1, Y2), add(X1, C, X2), greaterThan(C, 0).
right(P1, P2, C) :- x(P1, X1), x(P2, X2), y(P1, Y1), y(P2, Y2), equal(Y1, Y2), add(X2, C, X1), greaterThan(C, 0).
up(P1, P2, C) :- x(P1, X1), x(P2, X2), y(P1, Y1), y(P2, Y2), equal(X1, X2), add(Y1, C, Y2), greaterThan(C, 0).
down(P1, P2, C) :- x(P1, X1), x(P2, X2), y(P1, Y1), y(P2, Y2), equal(X1, X2), add(Y2, C, Y1), greaterThan(C, 0).
#$

<e33>

Now that we've got all the necessary ingredients, let us devise the keyboard-based control logic. Suppose that Prolog is equipped with a special library called "IO", which provides built-in predicates for the computer's input/output signals such as "key pressed", "mouse button pressed", "mouse position", "speaker volume", and so on. "IO::keyPressed(X)", for instance, will be interpreted as TRUE whenever key X is being pressed.

With this hypothetical library in mind, we can devise motion-related control flags as predicates, like the ones written below.

#$
moveLeft(X[n]) :- player(X[n]), IO::keyPressed(IO::leftKey).
moveRight(X[n]) :- player(X[n]), IO::keyPressed(IO::rightKey).
moveUp(X[n]) :- player(X[n]), IO::keyPressed(IO::upKey).
moveDown(X[n]) :- player(X[n]), IO::keyPressed(IO::downKey).
#$

<e34>

The basic idea is that there are four different commands for the player's movement - "moveLeft", "moveRight", "moveUp", and "moveDown". Whenever "moveLeft" gets triggered, the player character (i.e. any actor which is labeled as "player") should move to the left, and whenever "moveRight" gets triggered, the player character should move to the right, and... you get the idea.

And as you can see from the above horn clauses, the keyboard's left, right, up, and down arrow keys will respectively trigger these four commands, thereby letting the player move in four different directions.

But of course, these commands are not going to do anything unless we give them specific instructions as to the actual movement of the character.

You may recall that I have previously introduced the "move(...)" predicate as means of changing the actor's current position. "move(X[n], NewPos)", for example, will generate a force which will set the position of actor "X" to the value of "NewPos" by the moment at which the time step shifts from "n" to "n+1" (i.e. when the clock ticks).

So in order to construct the movement logic, all we need to do is come up with rules which will set the value of the "move(...)" predicate to TRUE whenever the right set of conditions are satisfied. In our case, such rules can be specified as the ones listed below.

#$
move(X[n], NewPos) :- moveLeft(X[n]), position(X[n], P), left(NewPos, P, 1).
move(X[n], NewPos) :- moveRight(X[n]), position(X[n], P), right(NewPos, P, 1).
move(X[n], NewPos) :- moveUp(X[n]), position(X[n], P), up(NewPos, P, 1).
move(X[n], NewPos) :- moveDown(X[n]), position(X[n], P), down(NewPos, P, 1).
#$

<e35>*

The four horn clauses above are responsible for handling the four movement commands (i.e. "moveLeft", "moveRight", "moveUp", and "moveDown").

Let us take a look at the first one. If the "moveLeft" command is raised and actor X is currently located at P, "left(NewPos, P, 1)" will find the position "NewPos" which is located to left of P by the distance of 1 (because that's the only value of "NewPos" which makes "left(...)" true). This position, then, will be the destination of actor X in its subsequent motion. The other 3 horn clauses work the same way, just in different directions.

There is something missing here, though. The rules stated so far do let us control our player using the arrow keys, yet there is no limit when it comes to locomotive freedom. We can move the character in any way we want, which is not the kind of mechanic we would like to have in a game where the presence of movement constraint is crucial (e.g. maze escape game).

A simple way to fix this flaw is to add an extra predicate to each horn clause to check whether the destination (i.e. NewPos) is blocked by an obstacle. This check can be done by trying to find an actor which is labeled as an "obstacle" and is located at the given position. If such an actor is found, the position must be considered "blocked". The "positionBlocked(...)" predicate in the following code carries out this task, which will be used for the purpose of allowing the player's move only if the destination is NOT being blocked (i.e. "!positionBlocked(NewPos)").

#$
positionBlocked(P) :- obstacle(X[n]), position(X[n], P).

move(X[n], NewPos) :- moveLeft(X[n]), position(X[n], P), left(NewPos, P, 1), !positionBlocked(NewPos).
move(X[n], NewPos) :- moveRight(X[n]), position(X[n], P), right(NewPos, P, 1), !positionBlocked(NewPos).
move(X[n], NewPos) :- moveUp(X[n]), position(X[n], P), up(NewPos, P, 1), !positionBlocked(NewPos).
move(X[n], NewPos) :- moveDown(X[n]), position(X[n], P), down(NewPos, P, 1), !positionBlocked(NewPos).
#$

<e36>

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Spatial Race Conditions</b></h3>

There is something fishy in the solution I just illustrated, however. As you may have already noticed, a problem arises when the player and an obstacle happen to be moving to the same exact location at the same exact time, in which case they will overlap. This is clearly undesirable because the player is not supposed to be able to penetrate through an obstacle.

<e37>

This bug, of course, is caused by the fact that the rules are only checking the obstacle's current location. In order to prevent the player and the obstacle from colliding due to simultaneous movement, we must make sure that no obstacle is going to be present at the player's destination not only during the current time step, but also during the next time step. The following code amends the rules to meet this requirement.

#$
currOrNextPositionBlocked(P) :- obstacle(X[n]), position(X[n], P).
currOrNextPositionBlocked(P) :- obstacle(X[n]), move(X[n], P).

move(X[n], NewPos) :- moveLeft(X[n]), position(X[n], P), left(NewPos, P, 1), !currOrNextPositionBlocked(NewPos).
move(X[n], NewPos) :- moveRight(X[n]), position(X[n], P), right(NewPos, P, 1), !currOrNextPositionBlocked(NewPos).
move(X[n], NewPos) :- moveUp(X[n]), position(X[n], P), up(NewPos, P, 1), !currOrNextPositionBlocked(NewPos).
move(X[n], NewPos) :- moveDown(X[n]), position(X[n], P), down(NewPos, P, 1), !currOrNextPositionBlocked(NewPos).
#$

Still, however, we cannot fully guarantee that nothing buggy is going to occur. What if the obstacle's intention to move to the player's destination (i.e. "move(...)") gets activated AFTER the "currOrNextPositionBlocked(...)" check has already been done? In such a case, collision may ensue.

Of course, just as I have mentioned in the last article, this kind of subtlety (which is due to the order of operation) may be circumvented by letting the Prolog interpreter scan the rules twice instead of just once, etc. But again, it is computationally expensive.

A more elegant solution is to introduce an interleaving mechanism to the game loop, forcing it to update only half of the world's 2D array of positions at every even-numbered time step, and the other half at every odd-numbered time step. Each half consists of positions which are guaranteed not to immediately influence each other during the current time step. A graphical depiction of this technique is shown below.

(Side Note: I have previously suggested a similar idea in: {%a href="https://thingspool.net/software-development/page-4.html"%}Parallel Adjacent-Cell Modification Support for General-Purpose Cellular Automata{%/a%})

<e38>

And the following lines are the corresponding code implementation. Note that "mod(A, B, C)" computes C based upon the rule "A % B = C", and "xor(A, B, C)" computes C based upon the rule "A ^ B = C".

#$
inEvenTimeSlot(P) :- x(P, Px), y(P, Py), mod(Px, 2, Mx), mod(Py, 2, My), xor(Mx, My, 0).
inOddTimeSlot(P) :- x(P, Px), y(P, Py), mod(Px, 2, Mx), mod(Py, 2, My), xor(Mx, My, 1).
shouldUpdatePosition(P) :- mod(n, 2, 0), inEvenTimeSlot(P).
shouldUpdatePosition(P) :- mod(n, 2, 1), inOddTimeSlot(P).

...
position(X[n], P) :- move(X[n-1], P), position(X[n-1], PrevPos), shouldUpdatePosition(PrevPos).
#$

(Will be continued in {%a href="https://thingspool.net/morsels/page-14.html"%}Part 5{%/a%})









:d:In this article, I will explain how a variety of game mechanics can be designed and implemented in Prolog. The reader will learn that logic programming is an inexplicably powerful paradigm when it comes to creating a dynamic and emergent network of interactions inside the game world.
:k:Prolog, Logic Programming, Declarative Programming, Data Driven, Emergence, Serious Games, Simulation Games, Ludology, Game Science, Game Design, Game Mechanics, Game Programming, Game Development, AI, Artificial Intelligence, Expert Systems, Game Tech, Emergent Systems, Systems Thinking, System Dynamics, Gameplay Engineering, Gameplay Systems, Sandbox Games, Roguelike
:l:2024-09-07

[Game Programming in Prolog - Part 5] September 7, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 5 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Interactions</b></h3>

So far, I have explained how the concept of space and time could be represented in the language of Prolog. These two are inarguably the most fundamental backbones of a gameplay sytem, for otherwise the range of things which the gamer is able to do would be extremely limited (Lack of time means absence of progression, and lack of space means absence of visual/physical elements).

The very presence of space and time, however, does not automatically give us toys to play with. A game is an interactive medium; it needs to have interactions between the player and the rest of the game world, as well as interactions within the world itself. A great game is a system which involves a rich network of such interactions.

Fortunately, devising interactions in Prolog is fairly straightforward (perhaps even more so than in an imperative language), due to the fact that each of them can be defined as a mapping of one set of relations to another. This is exactly what Prolog is designed for.

Let us begin with one of the most rudimentary forms of interactions - collision. When two actors get sufficiently close to each other, they collide.

The very definition of collision depends on what kind of physics we have in our minds. It could vary depending on whether the space is discrete or continuous, whether the game is turn-based or in real time, and so forth. For the sake of convenience, though, I will simply assume here that two actors "collide" whenever they are located at the same position (defined below).

#$
collide(X[n], Y[n]) :- position(X[n], P), position(Y[n], P).
#$

<e39>

Now, we know how to tell at which moment a pair of actors happen to collide. The predicate "collide(X[n], Y[n])" tells us that actor X and Y collide at time 'n'. Let us decide what to do when this happens.

A great example of an interaction could be found in the context of resource gathering. Imagine that there is a creature which is capable of feeling hunger (i.e. possesses a "hunger" stat). It feels hungry whenever its hunger level gets sufficiently high. And whenever it feels hungry, it eats any food that is nearby.

The following code is an implementation of the logic I just mentioned. The first rule states that any actor must be considered "hungry" whenever its hunger level becomes greater than 5, and the second rule states that a hungry actor must eat any colliding object which is edible.

#$
hungry(X[n]) :- hunger(X[n], H), greaterThan(H, 5).
eat(X[n], Y[n]) :- hungry(X[n-1]), canEat(X[n-1], Y[n-1]), collide(X[n-1], Y[n-1]).
#$

<e40>

This will guarantee that, once you drop a food (i.e. anything which can be eaten) right at the spot at which a hungry creature is located, the creature will devour it.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Generic Interactions</b></h3>

Here is another example, which more thoroughly demonstrates the notion of emergence in gameplay. Suppose that there are two actors named "actor1" and "actor2". The first actor represents fire, the second actor represents a piece of bread, and they were both spawned at the same exact time and place (see the code below).

#$
fire(actor1).
bread(actor2).

spawnTime(actor1, 0).
spawnTime(actor2, 0).

spawnPosition(actor1, <0, 0>).
spawnPosition(actor2, <0, 0>).
#$

<e41>

Since these two actors are equipped with their own identities (i.e. "fire" and "bread"), we are able to formulate an identity-based rule of interaction between them. For instance, we may come up with a clause which says that a fire should burn any piece of bread it happens to touch.

#$
burn(X[n], Y[n]) :- fire(X[n-1]), bread(Y[n-1]), collide(X[n-1], Y[n-1]).
#$

<e42>

Here is the catch, though. First of all, bread is not the only type of object which can be burned by fire; there are innumerable things in our world which are supposed to be burned when they get exposed to fire. Furthermore, fire is not the only type of object which is capable of burning other things; lava, oven, death ray, and myriad other sources of intense heat all possess such an ability.

What we need here is a "general rule" as opposed to a specific rule. For sure, you wouldn't want to be writing a bunch of rules which are mere variants of the same underlying pattern, like the ones listed below.

#$
burn(X[n], Y[n]) :- fire(X[n-1]), bread(Y[n-1]), collide(X[n-1], Y[n-1]).
burn(X[n], Y[n]) :- fire(X[n-1]), tree(Y[n-1]), collide(X[n-1], Y[n-1]).
burn(X[n], Y[n]) :- fire(X[n-1]), paper(Y[n-1]), collide(X[n-1], Y[n-1]).
burn(X[n], Y[n]) :- lava(X[n-1]), bread(Y[n-1]), collide(X[n-1], Y[n-1]).
burn(X[n], Y[n]) :- lava(X[n-1]), tree(Y[n-1]), collide(X[n-1], Y[n-1]).
burn(X[n], Y[n]) :- lava(X[n-1]), paper(Y[n-1]), collide(X[n-1], Y[n-1]).
...
#$

A rule which is generic enough to cover all these specific cases will be way more desirable. This leads us to the idea of tagging actors not only with their specific identities (such as "fire" and "bread"), but also with their general properties (e.g. adjectives).

For example, fire, lava, and oven are "similar" in the sense that they are all hot. This means that they all share the same general property called "hot".

In the same spirit, we may claim that bread, tree, and paper are "similar" in the sense that they are all flammable. This means that they all share the same general property called "flammable".

#$
hot(X) :- fire(X).
hot(X) :- lava(X).
hot(X) :- oven(X).

flammable(X) :- bread(X).
flammable(X) :- tree(X).
flammable(X) :- paper(X).
#$

<e43>

Mathematically speaking, such a grouping mechanism may as well be thought of as a process of defining sets. That is, it could be said that fire, lava, and oven are elements of the set called "hot", while bread, tree, and paper are elements of the set called "flammable".

The main advantage of doing this is that it allows us to define a general rule which states that any hot object should be able to burn any flammable object it happens to touch. It does not matter whether the hot object is fire, lava, or oven, and it does not matter whether the flammable object is bread, tree, or paper. As long as there is something hot and something flammable colliding with each other, we will be able to tell that the former will burn the latter.

#$
burn(X[n], Y[n]) :- hot(X[n-1]), flammable(Y[n-1]), collide(X[n-1], Y[n-1]).
#$

<e44>

So, there you have it. This single rule covers all possible permutations between the potential sources of burn ("fire", "lava", "oven") and their potential targets ("bread", "tree", "paper"). Even if the designer happens to come up with hundreds (or even thousands) of unique object names, this mechanic will still work flawlessly as long as hot objects are labeled as "hot" and flammable objects are labeled as "flammable".

This is not the end of the story, though. Note that nothing prevents us from attaching more than just a single property (e.g. adjective) to an actor; we are allowed to attach as many as we want, reflecting the multifacetedness of the actor's characteristics.

For example, a piece of bread is not only flammable, but is also a source of food for human beings (Note: Even someone who is fatally allergic to it can still manage to eat it at least once in his/her lifetime, so there is no logical contradiction here). This means that we should attach two different tags to each bread actor - "flammable" and "foodForHuman".

This allows each piece of bread to interact with two distinct types of actors - those which are identified as "hot", and those which are identified as "human". When something hot (such as fire) touches the bread, it will be burned. But when a hungry person touches the bread, it will be eaten. Two alternative responses, depending on which tag is associated with which interaction!

#$
flammable(X) :- bread(X).
foodForHuman(X) :- bread(X).

canBurn(X[n], Y[n]) :- hot(X[n]), flammable(Y[n]).
burn(X[n], Y[n]) :- canBurn(X[n-1], Y[n-1]), collide(X[n-1], Y[n-1]).

canEat(X[n], Y[n]) :- human(X[n]), foodForHuman(Y[n]).
eat(X[n], Y[n]) :- hungry(X[n-1]), canEat(X[n-1], Y[n-1]), collide(X[n-1], Y[n-1]).
#$

<e45>*

Adding more and more tags to our actors will exponentially increase the number of ways in which they may interact. This is the kind of emergence we want in video games, especially ones whose main source of entertainment originates from "mix and match" mechanics such as crafting rules, puzzles, etc.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Delayed Interactions</b></h3>

Not all interactions are instantaneous, though. Sometimes, games involve interactions which take effect after some delay. Think of a war game in which the soldiers attack each other by shooting projectiles such as bullets, arrows, and rocks.

For the case of bullets, we may simply assume that there is no delay at all because a bullet is so fast that no one is able to feel any noticeable delay. It is not the case with much slower projectiles such as arrows and rocks. They take considerably more time to reach their targets, and we must take this into account when implementing games.

Fortunately, delays of any reasonable length can be implemented fairly easily by doing a bit of arithmetic. Recall that 'n' indicates the current time step and 'n-1' indicates the previous time step. Likewise, 'n-2' must indicate 2 steps in the past, 'n-3' must indicate 3 steps in the past, and so on.

This means that, if a projectile takes N time steps to hit the target, the "hitting" event must occur at the current time step (n) if and only if the projectile was fired at time 'n-N'. So, if we assume that a bullet takes 1 time step, an arrow takes 3 time steps, and a rock takes 5 time steps to reach the destination, we could formulate such delays by specifying rules as shown below:

#$
hit(Y[n], Projectile[n]) :- shoot(X[n-1], Y[n-1], Projectile[n-1]), bullet(Projectile).
hit(Y[n], Projectile[n]) :- shoot(X[n-3], Y[n-3], Projectile[n-3]), arrow(Projectile).
hit(Y[n], Projectile[n]) :- shoot(X[n-5], Y[n-5], Projectile[n-5]), rock(Projectile).
#$

<e46>

It is also possible to design a number of interesting game mechanics out of this. A good example can be found in the case of a boomerang, which reaches the target AND comes back to its owner after some additional delay. The following code implements such a mechanic.

#$
hit(Y[n], Projectile[n]) :- shoot(X[n-2], Y[n-2], Projectile[n-2]), boomerang(Projectile).
hit(X[n], Projectile[n]) :- shoot(X[n-4], Y[n-4], Projectile[n-4]), boomerang(Projectile).
#$

<e47>

But of course, these simple rules may not suffice for nuanced gameplay. A projectile might need to be "interceptable" while its movement is still in progress. For instance, a flying rock should be able to change its trajectory due to a sudden force of knockback summoned by a wizard, etc.

This problem can be solved by constructing definitions on a step-by-step basis. Instead of waiting for 5 clock cycles and then raising the "hit" event, for example, a rock may initiate a chain of "motionProgress" events throughout the course of its 5-step movement. Each of these intermediary events, then, would be triggered by the preceding "motionProgress" event which was invoked just one clock cycle ago, not 5. The code below demonstrates how it can be done.

(Note: The fact that these rules only look up 1 step in the past, instead of 5, implies that the computer will no longer be obliged to store 5 past snapshots of the game in its memory. This is a nice way of saving computational resources.)

#$
motionProgress(rock, Y[n], Projectile[n], 0.0) :- shoot(X[n], Y[n], Projectile[n]), rock(Projectile).
motionProgress(rock, Y[n], Projectile[n], 0.2) :- motionProgress(rock, Y[n-1], Projectile[n-1], 0.0).
motionProgress(rock, Y[n], Projectile[n], 0.4) :- motionProgress(rock, Y[n-1], Projectile[n-1], 0.2).
motionProgress(rock, Y[n], Projectile[n], 0.6) :- motionProgress(rock, Y[n-1], Projectile[n-1], 0.4).
motionProgress(rock, Y[n], Projectile[n], 0.8) :- motionProgress(rock, Y[n-1], Projectile[n-1], 0.6).
motionProgress(rock, Y[n], Projectile[n], 1.0) :- motionProgress(rock, Y[n-1], Projectile[n-1], 0.8).
hit(Y[n], Projectile[n]) :- motionProgress(rock, Y[n], Projectile[n], 1.0).
#$

Want to be able to interrupt the rock's motion in the midst of its trajectory? No problem. All we need to do is add an extra condition to each of these rules which tells the system to terminate the chain of "motionProgress" if the rock was interrupted during the previous time step. The amended rules are listed below.

#$
motionProgress(rock, Y[n], Projectile[n], 0.0) :- shoot(X[n], Y[n], Projectile[n]), rock(Projectile).
motionProgress(rock, Y[n], Projectile[n], 0.2) :- !interrupt(Projectile[n-1]), motionProgress(rock, Y[n-1], Projectile[n-1], 0.0).
motionProgress(rock, Y[n], Projectile[n], 0.4) :- !interrupt(Projectile[n-1]), motionProgress(rock, Y[n-1], Projectile[n-1], 0.2).
motionProgress(rock, Y[n], Projectile[n], 0.6) :- !interrupt(Projectile[n-1]), motionProgress(rock, Y[n-1], Projectile[n-1], 0.4).
motionProgress(rock, Y[n], Projectile[n], 0.8) :- !interrupt(Projectile[n-1]), motionProgress(rock, Y[n-1], Projectile[n-1], 0.6).
motionProgress(rock, Y[n], Projectile[n], 1.0) :- !interrupt(Projectile[n-1]), motionProgress(rock, Y[n-1], Projectile[n-1], 0.8).
hit(Y[n], Projectile[n]) :- motionProgress(rock, Y[n], Projectile[n], 1.0).
#$

(Will be continued in {%a href="https://thingspool.net/morsels/page-15.html"%}Part 6{%/a%})











:d:This article explains how real-time gameplay systems can be created in the language of Prolog, based on a set of advanced concepts such as time-binding of relations, decomposition of discrete events, and compound symbols. This model of technical game design will be especially helpful for constructing highly emergent systems, such as ones which comprise the backbone of scientific simulation games (e.g. The Sims, SimCity, SimEarth, SimLife, etc).
:k:Prolog, Logic Programming, Declarative Programming, Gameplay Design, Procedural Generation, Time Series, Discrete Time Signal Processing, DSP, Digital Signal Processing, Game Development, Game Design, Indie Game, Data Driven Design, Game AI, Intelligent Systems, Systems Thinking, Expert Systems, Data Structures, Algorithms, Database Systems, Theory Of Computation, Discrete Math, Systems Engineering, Simulations, Computer Science
:l:2024-09-19

[Game Programming in Prolog - Part 6] September 19, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 6 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Time Allocation of Events</b></h3>

In {%a href="https://thingspool.net/morsels/page-12.html"%}Part 3{%/a%}, I mentioned that an event can be represented as a relation in the language of Prolog, as long as it belongs to a certain point in time. An event is usually a result of a set of preceding events (i.e. causes).

The time-related notations I have been using, though, may not reflect this underlying concept with a sufficient degree of accuracy. The main reason why this is so is that I have been attaching time parameters to the individual arguments of an event, rather than the event itself.

The example below is a simple instance of causation. In this case, the occurrence of "event1" during the previous time step (n-1) caused "event2" to happen during the current time step (n).

#$
event2(X[n]) :- event1(X[n-1]).
#$

<e48>

Here is another example. In this case, we can still see that "event1" caused "event2" to happen. The time steps involved here are a bit different, though. What we see in this scenario is that "event1" is based not only on the state of X one step back in time (n-1), but also on the state of X two steps back in time (n-2). In other words, "event2" is caused by what happened at two distinct points in the past (n-1 and n-2).

#$
event2(X[n]) :- event1(X[n-1], X[n-2]).
#$

<e49>

An event which belongs to multiple points in time, like the one shown above (i.e. "event1(X[n-1], X[n-2])"), is not logically absurd at all; such a kind of formulation makes perfect sense, both from pragmatic and theoretical points of view. However, it makes our representation of events a bit unnecessarily convoluted. And I say "unnecessarily" here because there really is no need for an event to stick itself to more than a single moment in time.

Let me ask you a question. Have we ever seen so far, from the very first part of this series, any Prolog code which demonstrated a relation with more than one time samples, such as "event1(X[n-1], X[n-2])"? The truth is that we have never seen one, and the reason is that it often makes a lot more sense to just break it down into two or more simpler events, just like the ones shown below (i.e. "event1A" and "event1B"). Think of these two events as the result of decomposing "event1" into two components (A and B).

#$
event2(X[n]) :- event1A(X[n-1]), event1B(X[n-2]).
#$

<e50>

Let me show you a more specific example. Imagine that there is a guy (called "X") who is lost in the middle of wilderness. In order to notify his presence to the outside world, he decides to broadcast the word "SOS" using his telegraphic device, for the hope of being rescued by anyone who receives it.

The telegraphic communication protocol, however, only allows him to send one letter at a time, so he must transmit "s" first, wait for a moment, transmit "o", wait for another moment, and then finally transmit "s" to finish transmitting the word "SOS".

There are two alternative ways of implementing this.

#$
rescue(X[n]) :- sendThreeLetters(X[n-1], s[n-1], X[n-2], o[n-2], X[n-3], s[n-3]).
#$

<e51>

#$
rescue(X[n]) :- send(X[n-1], s[n-1]), send(X[n-2], o[n-2]), send(X[n-3], s[n-3]).
#$

<e52>

In the first case, there is an event called "sendThreeLetters" which tells us that X has successfully sent the three letters (i.e. "s", "o", "s") during the last three time steps (i.e. n-1, n-2, n-3). When this event is detected, X gets rescued.

In the second case, there are three different "send" events. Each of these events represents the transmission of one of the three letters of the word "SOS". When all of these three events are detected, X gets rescued.

These two implementations are both valid, yet the second one is much more elegant because it ensures that each event is anchored to a single time step. This lets us associate each time parameter (such as "n-1") not with the event's individual arguments, but with the event itself. Thus, our horn clause can be re-written in a much simpler manner, like the one shown below:

#$
rescue[n](X) :- send[n-1](X, s), send[n-2](X, o), send[n-3](X, s).
#$

In general, this new method of denoting time in Prolog applies to every case in which no event (i.e. relation) is bound to more than one moments in time. The rules of converting the old notations to their simplified equivalents are listed below.

#$
r(X[n]) ---> r[n](X)

r(X[n], Y[n]) ---> r[n](X, Y)

r(X[n-1]) ---> r[n-1](X)

r(X[n-1], Y[n-1]) ---> r[n-1](X, Y)

r(X[n], Y[n-1]) ---> r1[n](X), r2[n-1](Y)
(... where "r = r1 AND r2")

r(X[n], Y) ---> r[n](X, Y)

r(X[n], n) ---> r[n](X, n)

r(X[n], n-1) ---> r[n](X, n-1)
#$

From now on, I will be using this new way of writing horn clauses.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Built-In Data Types</b></h3>

There is another subtlety in Prolog-based game programming which I have not gone over yet; it is the problem of data types.

As you might have guessed already, I have been implicitly supposing the presence of a number of built-in data types when coding in Prolog. First of all, we all know that the language of Prolog consists of building blocks called "horn clauses", each of which is a mapping of multiple relations (i.e. conditions) into a single relation (i.e. result). Each relation may optionally have one or more arguments in it. The code below is a generic example of a horn clause:

#$
relation3(arg3A, arg3B) :- relation1(arg1A, arg1B, arg1C), relation2(arg2A, arg2B).
#$

It is not hard to tell what horn clauses (aka "rules") and relations are, from a data abstraction point of view. If we are to embed the language of Prolog within a popular programming environment such as C#, we can easily define them as custom data types (i.e. classes or structs), like the ones shown below:

#$
public class Rule
{
    public Relation Result;
    public Relation[] Conditions;
}

public class Relation
{
    public string Name;
    public int TimeOffset = -99; // -99 if the relation is timeless
    public RelationArg[] Args;
    public bool Negate;
}
#$

When it comes to the individual arguments of a relation, however, a bit of ambiguity should creep in. To which data type does an argument belong? As keen readers may be able to tell already, there are multiple of them. The following types are the ones which I consider to be the most fundamental in my imaginary version of Prolog.

#$
Variables:
    Foo, X, Num, W3, Pos_1, Y, Value, NextVal52-0

Symbols (Constants):
    foo, 123hello, x_3, 5, -42, 0.8, 1/3, 2.0/3.47

Vectors (Constants):
    <3, 6.75>,
    <value3, y, z1>,
    <x, -95>
#$

<e53>

An argument whose name begins with an uppercase letter denotes a variable. A variable is basically a reference; it is an indicative entity which points itself to a constant value.

An argument whose name does NOT begin with an uppercase letter, on the other hand, denotes a constant. It is a specific piece of information, stored somewhere in the computer's memory. The question is, "What kind of information?"

If we were dealing with a "pure" version of Prolog, intended to be used solely for academic purposes, I would say that only the atomic ones (i.e. symbols) must qualify as part of the language's dictionary of build-in data types. A pristine system of logic, which is supposed to be devoid of any superfluous posture of complexity, would probably be obliged to exclude non-atomic data types (such as List, Set, Map, Graph, etc) from its ground-level semantics.

For the sake of convenience and efficiency, however, it is sometimes necessary to break free from such a harsh constraint unless we are conducting a purely theoretical research (e.g. proving a theorem in mathematics, etc). Since the topic of this article is game programming, it will be helpful if we just "extend" the language of Prolog a bit to bypass a myriad of potential challenges.

Now you may understand why I listed "Vector" as one of the built-in types. A vector is not necessarily an innate part of the original Prolog, but its addition nicely solves a great deal of trouble in the context of general-purpose computing.

Being able to put an arbitrary number of things together (i.e. vector) is an indispensable feature to have in a programming language. Thus, why not just let us assume that we are using a special Prolog interpreter which is designed to support this by default?

<e54>*

One might argue that introducing Vector as a built-in type should be considered a source of innumerable pitfalls, due to the possibility of forming weird nested structures such as a variable inside a vector, a vector inside a vector, and so forth.

Such a concern, however, is not going to matter if we enforce the rule that a Prolog vector must only permit symbols (atomic constants) as its components. This means that, for the sake of simplicity, there should not be any inner variables or inner vectors inside a vector.

The benefit of this constraint is that it allows vectors to be treated as literal values (similar to string literals), which then won't demand any special treatment at all. Each of them will simply be understood as a result of concatenating multiple symbols together in the form of an array. And whenever the Prolog application wants to bind a variable to a vector, all it needs to do is let that variable point to the vector's location in memory and regard it as a "compound symbol" - a symbol which is made out of more elementary (primitive) symbols, just like a molecule is made out of atoms.

<e55>

And whenever the program is to perform a pattern-match between two constants (to see if a predicate evaluates to TRUE), all it needs to do is apply one of the two different protocols depending on their type. If they both belong to the type "Symbol", a simple equality check (=) will suffice. If they both belong to the type "Vector", their equality check will be carried out in a pairwise manner (i.e. compare the first elements, compare the second elements, and so on).

The code below is a rough draft of how the matching of relations and their arguments may be done in a C# implementation of Prolog, based on the data types I have mentioned so far.

#$
public abstract class RelationArg
{
}

public class Variable : RelationArg
{
    public string Name;
}

public abstract class Constant : RelationArg
{
}

public class Symbol : Constant
{
    public string Value;
}

public class Vector : Constant
{
    public Symbol[] Components;
}

public class VariableBinding
{
    public VariableBinding Prev;
    public string VariableName;
    public RelationArg BoundArg;
}

public static class RelationUtil
{
    public static VariableBinding MatchRelations(Relation r1, Relation r2, VariableBinding newestBinding)
    {
        if (r1.Name != r2.Name)
            return null;

        int size1 = r1.Args.Length;
        int size2 = r2.Args.Length;
        if (size1 != size2)
            return null;

        for (int i = 0; i < size1; ++i)
        {
            VariableBinding newBinding = MatchRelationArgs(r1.Args[i], r2.Args[i], newestBinding);
            if (newBinding != null)
                newestBinding = newBinding;
            else
                return null;
        }
        return newestBinding;
    }

    public static VariableBinding MatchRelationArgs(RelationArg arg1, RelationArg arg2, VariableBinding newestBinding)
    {
        if (arg1 == null || arg2 == null)
        {
            return null;
        }
        if (arg1 is Symbol s1 && arg2 is Symbol s2)
        {
            return (s1.Value == s2.Value) ? newestBinding : null;
        }
        else if (arg1 is Vector v1 && arg2 is Vector v2)
        {
            int size1 = v1.Components.Length;
            int size2 = v2.Components.Length;
            if (size1 != size2)
                return null;

            for (int i = 0; i < size1; ++i)
            {
                if (v1.Components[i].Value != v2.Components[i].Value)
                    return null;
            }
            return newestBinding;
        }
        else if (arg1 is Variable var1 && arg2 is Variable var2)
        {
            if (var1.Name == var2.Name)
                return newestBinding;
            RelationArg found1 = FindBinding(var1.Name, newestBinding);
            RelationArg found2 = FindBinding(var2.Name, newestBinding);

            if (found1 != null && found2 != null)
            {
                return MatchRelationArgs(
                    (found1 != null) ? found1 : var1,
                    (found2 != null) ? found2 : var2,
                    newestBinding);
            }
            else
            {
                newestBinding = AddBinding(var1.Name, (found2 != null) ? found2 : var2, newestBinding);
                newestBinding = AddBinding(var2.Name, (found1 != null) ? found1 : var1, newestBinding);
                return newestBinding;
            }
        }
        else if (arg1 is Variable va1 && arg2 is Constant co2)
        {
            return MatchVarAndConst(va1, co2, newestBinding);
        }
        else if (arg1 is Constant co1 && arg2 is Constant va2)
        {
            return MatchVarAndConst(va2, co1, newestBinding);
        }
        else
        {
            return null;
        }
    }

    public static RelationArg FindBinding(string variableName, VariableBinding newestBinding)
    {
        if (newestBinding.VariableName == variableName)
            return newestBinding.BoundArg;
        else
            return newestBinding.Prev != null ? FindBinding(variableName, newestBinding.Prev) : null;
    }

    public static VariableBinding AddBinding(string variableName, RelationArg argToBind, VariableBinding prevBinding)
    {
        VariableBinding newBinding = new VariableBinding();
        newBinding.Prev = prevBinding;
        newBinding.VariableName = variableName;
        newBinding.BoundArg = argToBind;
        return newBinding;
    }

    public static VariableBinding MatchVarAndConst(Variable variable, Constant constant, VariableBinding newestBinding)
    {
        RelationArg found = FindBinding(variable.Name, newestBinding);
        if (found != null)
            return MatchRelationArgs(found, constant, newestBinding);
        else
            return AddBinding(variable.Name, constant, newestBinding);
    }
}
#$

(Will be continued in {%a href="https://thingspool.net/morsels/page-16.html"%}Part 7{%/a%})











:d:In this article, I will demonstrate how to spawn new objects (actors) in Prolog and give them unique IDs. This feature will let us design dynamic gameplay agents with their own lifecycles.
:k:Prolog, LogicProgramming, DeclarativeProgramming, GameDesign, GameDev, GameDevelopment, TechnicalDesign, ProgrammingParadigm, DataStructure, Algorithms, ComputerGames, SimulationDesign, ComputerScience, ComputerEngineering, CSE, EE, DesignPatterns, ExpertSystems, AI, ArtificialIntelligence, GameMath, IndieGames, LISP, FunctionalProgramming
:l:2024-09-22

[Game Programming in Prolog - Part 7] September 22, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 7 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Dynamic Allocation</b></h3>

There is one major feature which has been missing so far. It is the ability to create brand new actors while the game is running.

In all of the preceding examples, I declared the presence of actors by manually typing their names (i.e. IDs) and manually designating spawn-times and spawn-positions to them. If you have read my previous articles, you will definitely be able to tell that I had to explicitly write the following lines to spawn an actor called "actor1" at time 0 and position <0, 0>.

#$
spawnTime(actor1, 0).
spawnPosition(actor1, <0, 0>).
#$

<e56>

Here, the word "actor1" is something I just typed right inside the Prolog code - an arbitrary symbol which was not generated by the computer, but was entirely made up by the programmer. And in order to have multiple actors inside the game, I had to come up with a multitude of such made-up words and associate each one of them with its appropriate parameters. The code below is what I had to write in order to let the game have 3 actors in it, for instance.

#$
spawnTime(actor1, 0).
spawnPosition(actor1, <0, 0>).
spawnTime(actor2, 0).
spawnPosition(actor2, <1, 0>).
spawnTime(actor3, 0).
spawnPosition(actor3, <2, 0>).
#$

<e57>

This is an okay approach, as long as there are only a handful of actors in total. If there are too many of them, however, it will be too cumbersome to write code for all of them individually. So, whenever that's the case, we usually find it helpful to contrive some kind of "code generator" which will automatically write a bunch of repetitive code for us. The following code snippet is a Javascript implementation of such a generator; it creates a chunk of Prolog code which spawns 100 actors (named "actor0", "actor1", "actor2", ... , "actor99") at random locations, right at the beginning of the game (n = 0).

#$
function writeSpawningCode(actorId, time, posX, posY, prologCodeLines)
{
    prologCodeLines.push(`spawnTime(${actorId}, ${time}).`);
    prologCodeLines.push(`spawnPosition(${actorId}, <${posX}, ${posY}>).`);
}

function generatePrologCode()
{
    const prologCodeLines = [];
    for (let i = 0; i < 100; ++i)
    {
        const posX = Math.floor(Math.random() * 10);
        const posY = Math.floor(Math.random() * 10);
        writeSpawningCode(`actor${i}`, 0, posX, posY, prologCodeLines);
    }
    return prologCodeLines.join("\n");
}
#$

Even this fairly cunning technique, however, does not solve the very essence of the problem.

The fact that we are able to conveniently allocate a huge number of actors is indeed a good news, and it does open up a plethora of opportunities in regard to the richness of gameplay. However, we still have not figured out how to spontaneously create new actors out of nowhere while the game is running, instead of pre-defining them beforehand.

<e58>

The ability to dynamically spawn new actors is crucial for implementing the concept of life and death in our gameplay system. As time passes by, old things die and new things are born. And every time a new thing comes into existence, it must be given its own identifier (ID) to let the system distinguish it from other things. The key is to come up with a unique identifier every time the game decides to create something new.

What is so tricky is that it is quite difficult to come up with an identifier which is truly unique, as opposed to one which may coincide with those which have already been hanging out elsewhere.

Certain types of constraints may let us easily bypass this issue, of course. If we only allow the game world to spawn up to 1 actor per time step, for example, we will be able to tell that simply using the current time step (i.e. value of 'n') as the new actor's ID will neatly solve the problem of uniqueness.

<e59>

Obviously, we do not want such a harsh technical limitation in our game. Multiple actors should be able to be born at each time step, without having to wait in some kind of "spawn queue" before entering the world. Such a forced delay will be so awkward in cases in which we are required to instantiate things immediately (e.g. shooting bullets).

Another potential solution is to assume that only up to 1 actor will be born at each position in space, at each time step. As long as this supposition holds, each tuple formed by the actor's spawn-time and spawn-position (i.e. "n_x_y") will be guaranteed to be unique. This too, however, is a bit too restrictive since it disallows us from spawning multiple actors at the same spot simultaneously (which may sometimes be necessary, such as when spawning a mother kangarooo with a baby kangaroo in its pouch).

<e60>*

We may as well consider building the actor's ID by concatenating not just its spawn-time and spawn-position, but also the ID of the source of its birth (i.e. the actor from which it originated). So, if an actor called "foo" gave birth to a new actor at time 'n' and position <x,y>, the ID of the new actor could be expressed as "foo_n_x_y".

This, however, does not handle all the plausible edge cases either. What if "foo" decides to give birth to two different actors at the same exact spot at once? When that happens, the IDs of the two offsprings will be identical.

<e61>

One may wonder why I am so morbidly concerned with such details, while we could just create a global integer variable (e.g. "int lastUsedId = 0"), increment it by 1 and use it as the new ID each time we spawn something. This is perhaps the most straightforward way of doing it in an imperative and single-threaded programming environment, where events are happening sequentially.

Note, however, that multiple events may occur concurrently in our Prolog environment if they belong to the same time step. Enforcing a specific order of operation among them will unjustly limit the power of declarative programming, and invalidate the reason why one would even bother to code in Prolog in the first place. One of the main reasons why logic programming is so great is that its procedures are order-independent (which prevents all sorts of race conditions and enables a significant portion of the code to run in parallel); we've really got to preserve this aspect of the language we are using.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Context-Driven ID Generation</b></h3>

Fortunately, there is a trick we can use to solve the problem of ID generation quite nicely. In order to demonstrate how this trick works, I will first come up with a scenario which involves a chicken and its eggs.

Imagine that there is a chicken which lays an egg each time the clock ticks (i.e. time step increments by 1). Suppose, for now, that it is only capable of laying up to 1 egg at a time (That is, no two or more eggs can be laid simultaneously). The predicate which denotes the act of laying an egg is shown below, where "n" is the time at which the egg was born and X is the ID of the chicken which laid it.

#$
chicken[n](X) :- chicken[n-1](X).
layEgg[n](X) :- chicken[n](X).
#$

<e62>

This means that, as long as we know that an egg happened to spawn at time "k" due to the act of "laying an egg" which was committed by a chicken called "foo", we are able to assure that this is the only egg which could have possibly been produced by "foo" at time "k". Why? Because "foo" and "k" are the only differentiating factors during the process of instantiation of the "layEgg[k](foo)" predicate.

The event "layEgg" is unique to a particular combination between the egg's source (X) and the time at which it was born (n). At each moment in time, therefore, there can only be at most one instance of "layEgg" which could originate from a particular chicken. The implication of this is that the expression "n_Src_layEgg", in which "n" is the time at which the event "layEgg" took place and "Src" is the ID of the chicken which laid the egg, must be unique for every single egg. Do you know what this means? It means that "n_Src_layEgg" can be used as the egg's unique ID.

The following code shows how this logic works.

#$
layEgg[n](X) :- chicken[n](X).
spawn[n](X, layEgg, Pos) :- layEgg[n](X), position[n](X, Pos).
spawned[n]("{n}_{Src}_{Cause}", Src, Cause, Pos) :- spawn[n-1](Src, Cause, Pos).
#$

<e63>

The first horn clause simply states that a chicken is supposed to lay an egg at each time step. The second clause says that, whenever a chicken lays an egg at position "Pos", it must trigger an event called "spawn" with 3 parameters:

(1) The ID of the actor which triggered the "spawn" event (i.e. the ID of the chicken),
(2) The name of the event which caused the "spawn" event (i.e. "layEgg"), and
(3) The position at which the egg is supposed to spawn (i.e. Pos).

The "spawn" event, then, will complete the spawning process (of the egg) by invoking the "spawned" event. This is where the ID generation takes place. As you can see in the first argument of "spawned(...)", the rule basically creates a brand new symbol (i.e. a string literal) by concatenating the 3 existing symbols - the integer which denotes the current time, the ID of the source, and the name of the cause of the spawning process. This is the ID of the new actor (i.e. egg), and it is guaranteed to be unique because each chicken can only trigger up to one "layEgg" event at a time.

(Note: Think of the notation "{n}_{Src}_{Cause}" as an instance of string interpolation which you can see in many programming languages including C#, Javascript, etc. I am supposing here that the Prolog interpreter is capable of creating new symbols (string-based literal expressions) based off of any interpolated strings and memorizing them.)

Now, for instance, if the following event occurs:

#$
spawned[16](16_foo_layEgg, foo, layEgg, <3, 4>)
#$

We will be able to tell that at time [n = 16], chicken "foo" gave birth to an egg called "16_foo_layEgg" at position <3, 4>.

One may argue that such a method of spawning actors feels a bit too restrictive, since it does not seem to allow the chicken to lay more than one eggs at each time step. A game designer might ask, "Hey, what if I want to create a special magic spell which lets a chicken lay 2 or 3 eggs at once, instead of just 1?"

The solution is pretty simple. You just come up with more types of events to be able to trigger the spawning of extra eggs, like the ones listed below.

#$
layEgg[n](X) :- chicken[n](X).
layEgg2[n](X) :- chicken[n](X), extraEggBoost[n](X, NumExtra), greaterThan(NumExtra, 0).
layEgg3[n](X) :- chicken[n](X), extraEggBoost[n](X, NumExtra), greaterThan(NumExtra, 1).

spawn[n](X, layEgg, Pos) :- layEgg[n](X), position[n](X, Pos).
spawn[n](X, layEgg2, Pos) :- layEgg2[n](X), position[n](X, Pos).
spawn[n](X, layEgg3, Pos) :- layEgg3[n](X), position[n](X, Pos).
#$

<e64>

Suppose that the "extraEggBoost" predicate denotes the presence of that magic spell the designer talked about, under the assumption that "X" is the ID of the chicken and "NumExtra" indicates the number of extra eggs that the chicken is required to lay each time the clock ticks. The rules above, then, show us that the following three scenarios are possible depending on what the value of "NumExtra" is:

(1) If either NumExtra is 0 or "extraEggBoost(X, NumExtra)" does not even exist for X (meaning that chicken X is currently not endowed with any active extra-egg spell), only "layEgg" will be triggered.
(2) If NumExtra is at least 1, both "layEgg" and "layEgg2" will be triggered.
(3) If NumExtra is at least 2, both "layEgg" and "layEgg2", as well as "layEgg3", will be triggered.

And since "layEgg", "layEgg2", and "layEgg3" are distinct types of events which will separately contribute to the same chicken's egg-spawning process (since they belong to 3 different causes and thus generate 3 different IDs), we can modulate the number of simultaneously spawnable eggs by activating a subset of these 3 events.

If a chicken called "foo" gave birth to 3 eggs at time 16 and position <3, 4>, for example, the following three events will be invoked. As you can clearly see, all of these 3 eggs are given unique IDs because they all originated from unique causes (i.e. layEgg, layEgg2, and layEgg3).

#$
spawned[16](16_foo_layEgg, foo, layEgg, <3, 4>)
spawned[16](16_foo_layEgg2, foo, layEgg2, <3, 4>)
spawned[16](16_foo_layEgg3, foo, layEgg3, <3, 4>)
#$

At this point, a programmer might come over and say, "Dude, what if we want to allow the chicken to lay hundreds of eggs instead of just a handful? Do you expect me to write hundreds of lines of code?" Such a concern, too, can be resolved without too much hassle. All we have to do is stop treating every single egg as an individual actor.

What I mean by this is that we are not obliged to give a unique ID to every egg (It will be quite detrimental to the system's performance if we do that to hundreds of eggs anyways). Instead, we could just create an actor which represents a group of multiple eggs.

<e65>

This approach will work as long as it is not necessary to separately keep track of each egg. The only thing we need to do is convert the "Cause" argument of the spawning process into a vector, and pass the number of eggs as its second component. The resulting "numCopies" attribute, then, will signify the number of eggs within the spawned egg-group object. Its code implementation is displayed below.

#$
layEggs[n](X, 1) :- chicken[n](X).
layEggs[n](X, NumEggs) :- chicken[n](X), extraEggBoost[n](X, NumExtra), add(1, NumExtra, NumEggs).

spawn[n](X, <layEggs, NumEggs>, Pos, NumEggs) :- layEggs[n](X, NumEggs), position[n](X, Pos).
spawned[n]("{n}_{Src}_{Cause}", Src, Cause, Pos) :- spawn[n-1](Src, Cause, Pos).

numCopies(Id, NumCopies) :- spawned[n](Id, Src, Cause, Pos), y(Cause, NumCopies).
#$

(Will be continued in {%a href="https://thingspool.net/morsels/page-17.html"%}Part 8{%/a%})












:d:How to design a gameplay system using Prolog? This part of the series explains the construction and destruction of actors, as well as how their types can be handled in a data-driven way. This will be one of the most essential mechanics of a Prolog-based game system.
:k:LogicProgramming, Prolog, DatabaseSystems, QuerySystems, CS, ComputerScience, AI, ArtificialIntelligence, GameSystems, GameMechanics, GameDesign, GameMath, GameScience, Ludology, GameDevelopment, SystemsEngineering, DifferenceEquations, DiscreteSimulation, DiscreteMathematics, SignalProcessing, DSP, DynamicSystems, SystemDynamics, SystemsThinking, Semantics
:l:2024-09-24

[Game Programming in Prolog - Part 8] September 24, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 8 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Constructor and Destructor</b></h3>

In the last article, I demonstrated how to spawn brand new actors (objects) out of nowhere, with the help of a unique ID generation algorithm. I have not, however, yet explained how to initialize the properties of a dynamically spawned actor.

You may recall that there are attributes which must be available to let us know the actor's exact time and place of birth. One of them is "spawnTime", and the other one is "spawnPosition". The following two predicates reveal us, for example, that an actor called "actor1" was born at time 0 and at position <0, 0>.

#$
spawnTime(actor1, 0).
spawnPosition(actor1, <0, 0>).
#$

<e56>

And since these two predicates are not bound to a specific point in time (i.e. they do not have time parameters, such as "[n]"), we know that both the spawn-time and spawn-position of "actor1" will be fully exposed to the rest of Prolog's environment throughout the entirety of time.

Such a static and timeless way of defining an actor's properties, though, cannot be used for those which have been spawned dynamically. We cannot pre-define their spawn-times and spawn-positions explicitly in the source code itself, since we can never be sure beforehand exactly when and where they are going to spawn, as well as what their IDs are going to be, while the game is running.

Each of the properties of a dynamically allocated actor, therefore, must be modeled as a sequence of events which gets created when the actor spawns, and gets destroyed when the actor despawns.

The most rudimentary of them is the special attribute called "alive", which tells us whether the actor is still living or not. The presence of "alive[n](Id)", for instance, will signal that the actor whose identifier is the value of "Id" must be alive at time "n" (or dead otherwise).

The two rules listed below defines such a relation, the first of which is the base case and the second one is the recursive case. First of all, we know that an actor must be alive the very moment it comes into existence (i.e. when its "spawned" event kicks off). After this initial moment of birth, we know that the actor will stay alive as long as the "despawn" event does not occur. Think of "despawn" as a signal which orders the given actor (Id) to stop existing.

#$
alive[n](Id) :- spawned[n](Id, Src, Cause, Pos).
alive[n](Id) :- alive[n-1](Id), !despawn[n-1](Id).
#$

<e66>

With this "alive" attribute, we are now free to define numerous other properties which are supposed to persist only during the actor's lifetime. All we need to do is represent them as chains of events which last only as far as the actor's "alive" event keeps firing itself.

Let us start with "spawnTime". The moment the actor spawns, we know that the current time (denoted by "n") must be the time at which the actor was born. Thus, the time (n) to which the "spawned" event belongs should be defined as the actor's spawn time.

The thing is, I am now obliged to include the time notation ("[n]") in the "spawnTime" relation. This is because a dynamically created actor's "spawnTime" is meant to be defined only while it is alive. Defining it before the actor's birth is a nonsense because it would imply that the relation predicted exactly when the instance of birth would take place beforehand. Defining it after the actor's death is not so sensible either, since it is wasteful (from a performance point of view) to let obsolete properties linger and accumulate as time passes by, allowing more and more actors to die and leave their ghostly remnants which are permanently stuck in the overworld.

Thus, it should make sense to ensure that an actor whose time of birth is determined during the game's runtime must have its "spawnTime" relation only exist as long as the actor itself exists.

The two rules below illustrate how this can be achieved. The first one initializes the first "spawnTime" event the moment the actor comes into existence (This is the beginning of the chain reaction). The second rule, then, keeps reproducing the "spawnTime" event over and over, up until the point at which the actor is no longer "alive".

#$
spawnTime[n](Id, n) :- spawned[n](Id, Src, Cause, Pos).
spawnTime[n](Id, T) :- spawnTime[n-1](Id, T), alive[n-1](Id).
#$

<e67>

The actor's place of birth, too, can be defined in the same spirit. Just like "spawnTime", "spawnPosition" should be considered a chain of events which gets created when the actor is born, persists itself as long as the actor is still alive, and destroys itself as soon as the actor is found to be dead. The following code is the implementation.

#$
spawnPosition[n](Id, Pos) :- spawned[n](Id, Src, Cause, Pos).
spawnPosition[n](Id, Pos) :- spawnPosition[n-1](Id, Pos), alive[n-1](Id).
#$

<e68>

But of course, the gameplay system needs to know the actor's current position besides its initial position. This is pretty straightforward to define; all it takes is to modify the previous rules of the "position" relation a bit, so as to ensure that the current position will no longer be defined once the actor disappears from the world. The code below demonstrates how it might be done.

#$
position[n](X, Pos) :- spawned[n](Id, Src, Cause, Pos).
position[n](X, P) :- move[n-1](X, P), alive[n-1](X).
position[n](X, P) :- !move[n-1](X, _), alive[n-1](X), position[n-1](X, P).
#$

<e69>

As you can see, we now have the "alive" condition as part of the current position's recursive cases. Once "alive" no longer becomes available, "position" discontinues its chain of self-reproduction regardless of whether the actor wants to move or not.

Here is something I have not gone over yet. An actor, besides its own temporal and spatial state variables, needs to possess its own type. Otherwise, all actors will appear to be identical, and the game will be pretty boring. Actors must be able to carry distinct characteristics, such as their own colors, shapes, behavioral tendencies, functionalities, and so forth.

Such differentiation can be done by assigning a tag to each actor. An actor with the "egg" tag, for example, will let us treat it as an egg and use it for egg-related purposes. In this case, the word "egg" serves as the actor's type.

Here is a technical problem, though. When an actor spawns, how do we know that this actor is supposed to be an egg instead of something else, such as a pineapple, chocolate bar, or salmon?

We have a clue, fortunately. Do you remember that the "spawn" event is required to carry its own contextual argument called "Cause" in order to guarantee that the generated ID will be unique? The good news is that we can simply use this piece of information to decide which tag to attach to the spawned actor.

If the "Cause" argument of the "spawned" event is set to "layEgg", for instance, we will be able to tell that the actor was spawned because a chicken decided to lay an egg (i.e. The chicken raised the "layEgg" event, which in turn caused the "spawn" event to happen). Under such a circumstance, therefore, it should make sense to label the actor with the word "egg" in order to indicate that it is an egg, and preserve such a label as long as the actor is alive. The code below shows how it is done.

#$
egg[n](Id) :- spawned[n](Id, Src, layEgg, Pos).
egg[n](Id) :- egg[n-1](Id), alive[n-1](Id).
#$

<e70>*

If the "Cause" argument were set to something else such as "makeSandwich", the tag attached would have been different (e.g. "sandwich"). This is how we are able to spawn actors of specific types.

Once we manage to assign a tag (i.e. type) to an actor, the rest is history. As soon as the system recognizes the actor as an egg, for instance, it will automatically apply all the egg-related rules to this particular actor, such as the ones stated below.

#$
edible(X) :- egg(X).
hasProtein(X) :- egg(X).
breakable(X) :- egg(X).

boiledEgg[n](X) :- egg[n-1](X), boil[n-1](X).
brokenEgg[n](X) :- egg[n-1](X), breakable[n-1](X), break[n-1](X).
stirredEgg[n](X) :- brokenEgg[n-1](X), stir[n-1](X).
omelet[n](X) :- stirredEgg[n-1](X), panFry[n-1](X).

omurice[n](Z) :- friedRice[n-1](X), omelet[n-1](Y), stack[n-1](X, Y, Z).
#$

The first three clauses are characteristics which can be derived from the fact that the actor is an egg. An egg is edible, has protein in it, and is breakable. These attributes do not need to be given to the actor individually, since they will all automatically be induced once the actor is tagged as "egg".

The succeeding clauses are a set of behavioral traits which are common to all eggs. If you boil an egg, for example, it will turn itself into a boiled egg. If you break an egg, it will become a broken egg. If you stir a broken egg, it will become a cupful of stirred egg. And if you pan-fry it, it will be transformed into an omelet. And of course, you can make omurice by stacking the omelet on top of fried rice.

(Note: These transformative rules are incomplete and have logical flaws in them. For example, once an egg becomes a broken egg, it should no longer be breakable (while still maintaining its status as an egg because breaking it does not make it a "non-egg"). Also, a broken egg should stay as a broken egg as long as no event interferes with its state. In the upcoming article, I will be dealing with this sort of problem.)

<e71>

Such a "chain-reaction of thought" is theoretically boundless. Nothing really prevents it from being extended indefinitely, as long as a sufficient degree of freedom is provided. We began with the word "egg" alone, yet this was enough to give birth to its own vast tree of meaning, furnished with all sorts of ways in which an egg could be treated and/or manipulated. We call this kind of phenomenon a "butterfly effect".

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Lifecycle of an Actor</b></h3>

Being able to spawn and despawn actors during runtime is such an indispensable feature for a gameplay system to have. It opens up a gateway to a plethora of opportunities in regard to the concept of life and death, as well as the cycle of nature in general (which encompasses the idea of reincarnation, karma, etc). It makes things far more dynamic than they would have been if they were statically declared as though they were parts of a stone sculpture.

The mechanic of spontaneous creation and destruction evinces its full potential in simulation games (e.g. ecosystem simulator, management simulator, social simulator, etc), in which actors oftentimes play the roles of either producers, consumers, or both.

Some actors are called "producers" because they produce brand new actors. Examples of them are plants, factories, power generators, as well as living things in general (because they reproduce).

Some actors are called "consumers" because they consume (destroy) existing actors. Examples of them are weapons, garbage disposers, decomposers, and animals (because they eat other lifeforms to survive).

An example can be found in the case of a food chain. Imagine that there is a chicken and a snake at the same location, meaning that they are able to interact with each other at any moment. Let's say that the chicken lays an egg every time the clock ticks (The code below illustrates this mechanic).

#$
layEgg[n](X) :- chicken[n](X).
spawn[n](X, layEgg, Pos) :- layEgg[n](X), position[n](X, Pos).
#$

Meanwhile, the snake devours any egg it happens to find in proximity. Whenever the snake eats an egg, the egg despawns (since it is "consumed" by the act of eating). The following code shows how it works.

#$
eat[n](X, Y) :- snake[n-1](X), egg[n-1](Y), collide[n-1](X, Y).
despawn[n](Y) :- eat[n](X, Y).
#$

<e72>

At this point, you are probably aware of the grand cycle of production and consumption in this example. The chicken produces an egg, the snake consumes it, the chicken produces another egg, the snake consume it, and so on, thus exhibiting an oscillatory pattern. From an ecological point of view, this should (with a list of additional rules) eventually lead to fluctuations in the populations of chickens, their eggs, and snakes, as well as their long-term positive/negative feedback loops.

Analogous scenarios may be found in agriculture (i.e. seeding followed by harvesting), dairy (i.e. raising of cows followed by milking), and countless other phenomena.

(Will be continued in {%a href="https://thingspool.net/morsels/page-18.html"%}Part 9{%/a%})









:d:How to construct gameplay elements in Prolog? This article illustrates how a wide range of objects in a video game, such as actors and items, are able to be expressed in terms of logical relations.
:k:Game Design, Gameplay Systems, Game Development, Logic Programming, Prolog, Discrete Systems, LISP, Functional Programming, Declarative Programming, Data Driven, Haskell, Lambda Calculus, Relational Database, Set Theory, Discrete Mathematics, Simulation, Computational Logic, Computer Science, Computer Engineering, Electrical Engineering, Signal Processing, DSP, ECS, Entity Component System
:l:2024-09-29

[Game Programming in Prolog - Part 9] September 29, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 9 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Transformation</b></h3>

Last time, I talked about the things we can do at the moment of an actor's birth (or death). As soon as an actor comes into existence, for example, we are able to define its own set of characteristics which are promised to last as long as it lives. Each characteristic is basically a sequence of events which keeps growing, up until the point at which the actor dies.

This time, I will be talking about things which may happen during an actor's course of life. Besides spawning and despawning, an actor must also be capable of "changing" itself in some way or another while it is alive, unless it is an idle being which never interacts with anything outside of itself.

Whenever an actor interacts with something external, it is usually expected to undergo some kind of transformation. What kind? There are many, and I am here to illustrate how to implement transformative events in the language of Prolog.

If you remember the egg analogy from the last article, you will be able to recall that the system should be able to convert an egg into a broken egg with the help of the "break" event. Since an egg is breakable, we can break it. And whenever we break it, it transforms into a broken egg (i.e. The tag "brokenEgg" gets assigned to it).

#$
breakable(X) :- egg(X).
brokenEgg[n](X) :- egg[n-1](X), breakable[n-1](X), break[n-1](X).
#$

<e73>

Here is something fishy, though. Even after we break an egg and turn it into a broken egg, it should still be considered an "egg" because breaking it does not disqualify it from being an egg. Mathematically speaking, the set of broken eggs is a subset of the set of all eggs.

And of course, this is exactly what we are presuming in the rules above. When we assign the tag "brokenEgg" to X, we are not removing the tag "egg" from it because a broken egg is still an egg. An egg may or may not be a broken egg, but a broken egg is always an egg.

<e74>

The problem is that, once an egg gets broken, it should no longer be breakable. So the first horn clause, "breakable(X) :- egg(X)", won't work for broken eggs; it will simply allow broken eggs to be broken again and again, which is a nonsense.

Thus, we are required to explicitly state that an egg is breakable only if it is NOT a broken egg. The following code is the result of such modification:

#$
breakable[n](X) :- egg[n](X), !brokenEgg[n](X).
brokenEgg[n](X) :- egg[n-1](X), breakable[n-1](X), break[n-1](X).
#$

<e75>

From the perspective of set theory, one may as well explain this logic by saying that a breakable egg is an element of the set of all eggs MINUS the set of broken eggs. The first of the two rules above, therefore, could be considered an instance of set operation (i.e. "breakableEggs" = "eggs" - "brokenEggs").

<e76>*

Now, one might question the necessity of having the "breakable" tag in our code. Why not just directly embed the egg's condition of breakability right inside the second horn clause, like the one displayed below? This way, we will be able to get rid of the word "breakable" entirely, thereby making the code a bit more succinct.

#$
brokenEgg[n](X) :- egg[n-1](X), !brokenEgg[n-1](X), break[n-1](X).
#$

This is a valid way of implementing the system. However, we should also be aware of the fact that eggs are not the only things which may be breakable. Suppose that there is some sort of generic "breaker" in our game, which has a tendency of breaking any breakable object it happens to touch. In such a case, we would like to label any breakable object with the word "breakable", so that the only thing that the breaker will need to do is check the presence of the word "breakable" in whichever actor it encounters, and proceed to break it if so (See the following code).

#$
break[n](Y) :- breaker[n-1](X), breakable[n-1](Y), collide[n-1](X, Y).

breakable[n](X) :- egg[n](X), !brokenEgg[n](X).
breakable[n](X) :- window[n](X), !brokenWindow[n](X).
breakable[n](X) :- bottle[n](X), !brokenBottle[n](X).

brokenEgg[n](X) :- egg[n-1](X), breakable[n-1](X), break[n-1](X).
brokenWindow[n](X) :- window[n-1](X), breakable[n-1](X), break[n-1](X).
brokenBottle[n](X) :- bottle[n-1](X), breakable[n-1](X), break[n-1](X).
#$

This is a bit ugly, though. Here, we are introducing a bunch of new terminologies, such as "brokenEgg", "brokenWindow", "brokenBottle", and so forth, just for the sake of making a distinction between the broken states and not-broken states of a bunch of objects. If there are 100 types of breakable entities, this kind of coding practice will force us to come up with 100 new words (which all begin with "broken(...)") as well as 200 new horn clauses just to take account of their breakability.

There is a pretty neat solution to this, fortunately. Instead of assigning a distinct tag to each actor's broken state (such as "brokenEgg"), we may simply choose to assign a generic tag called "broken" to any actor which is considered broken. The "breakable" predicate, then, will only need to set itself to TRUE when the actor has been breakable but NOT been broken recently. The following code demonstrates how this logic works.

#$
breakable[n](X) :- egg[n](X), spawnTime[n](X, n).
breakable[n](X) :- window[n](X), spawnTime[n](X, n).
breakable[n](X) :- bottle[n](X), spawnTime[n](X, n).

breakable[n](X) :- breakable[n-1](X), alive[n-1](X), !broken[n](X).

broken[n](X) :- breakable[n-1](X), break[n-1](X).
broken[n](X) :- broken[n-1](X), alive[n-1](X).
#$

<e77>

Instead of "brokenEgg", we now have an "egg" which can optionally be labeled as "broken" depending on whether it has been broken or not. The composition of the two words, "egg" and "broken", implies that the object is a broken egg. The absence of the latter implies that the egg has not been broken yet.

As you can clearly see in the code above, the only type-specific rules (i.e. the ones which have to be repeated for different types of actors) are ones responsible for initializing the "breakable" tag for all object types which are considered initially breakable. The state of being breakable, then, will persist as long as the object to which it is bound is neither dead nor broken. The state of being broken, too, will persist in a similar manner.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>State Space</b></h3>

The overall idea is to use multiple tags to represent an actor, instead of just one. In other words, we may as well claim that the current state of an actor is the combination of all the tags it happens to possess right now.

For the case of an egg, for instance, we could say that:

(1) A default egg (That is, a plain raw egg which has just been laid by a chicken) is an actor with one state-related tag called "egg",
(2) A broken egg is an actor with two state-related tags called "egg" and "broken", and
(3) A stirred egg is an actor with three state-related tags called "egg", "broken", and "stirred" (because an egg must first be broken in order to be stirred),

... and so on.

A state transition of an actor, then, can be interpreted as a process of reconfiguring the actor's inventory of tags. The event of breaking the egg, for example, resulted in attaching an additional tag called "broken" to the egg but did not take away any of its existing tags. If the event were something really extraordinary such as "throwIntoLava", the system would have removed the tag "egg" from the actor because no egg is capable of maintaining its identity as an egg despite being exposed to such an extreme circumstance.

<e78>

From the viewpoint of set theory, an actor's state transition (i.e. addition/removal of tags) may as well be thought of as a displacement of the actor's "conceptual location" from one set to another. The act of breaking an egg, for example, will put it inside the intersection of two sets - eggs and any broken objects. The act of throwing an egg into lava, on the other hand, will put it outside of the set of eggs entirely.

<e79>

What's interesting is that there are alternative ways in which an actor may be transformed, some of which are mutually exclusive with one another. Once you throw an egg into lava, for instance, you cannot break it later on because it will no longer be an egg (Instead, it will perhaps be a morsel of ash, which is definitely not breakable). But if you break the egg first, you will still be able to throw it into lava and turn it into ash-omelet. Thus, we may conclude that the "throwIntoLava" event excludes the "break" event from occurring, while the "break" event does NOT exclude the "throwIntoLava" event from occurring.

<e80>

The reason why this sort of distinction exists is that the current state of an actor is basically a node in a graph (aka "state transition diagram"), in which each node is one of the actor's possible states and each directed edge is an event which triggers a transition from one state to another.

Let me come up with a more interesting example which contains two alternative choices of actions - pay-frying and stirring (You may recall them from the previous article, in which their definitions were left incomplete).

The most intriguing aspect of these two choices is that choosing one of them prevents the other one from taking place, thus rendering two alternative pathways (in space space) through which the egg can travel. In order to explain why this is so, I will first come up with a number of rules which will eventually lead to such a scenario.

The two clauses below are what one may refer to as "enablers"; they are responsible for enabling the egg to be either pan-fried or stirred, the very moment the egg gets broken. An egg which has NOT yet been broken is neither pan-fryable nor stirrable.

#$
payFryable[n](X) :- egg[n-1](X), break[n-1](X).
stirrable[n](X) :- egg[n-1](X), break[n-1](X).
#$

<e81>

After the initial moment of enablement, of course, the system should let the broken egg stay pan-fryable and stirrable unless some change takes place. The following two rules ensure that anything which is pan-fryable will stay pan-fryable until it either gets destroyed or pan-fried, as well as that anything which is stirrable will stay stirrable until it either gets destroyed, stirred, or pan-fried (because the process pan-frying solidifies the object, thus preventing it from being stirred).

#$
panFryable[n](X) :- panFryable[n-1](X), alive[n-1](X), !panFried[n](X).
stirrable[n](X) :- stirrable[n-1](X), alive[n-1](X), !stirred[n](X), !panFried[n](X).
#$

The presence of the "!panFried[n](X)" predicate in the second rule implies that pan-frying blocks the subsequent stirring of the object, while the absence of the "!stirred[n](X)" predicate in the first rule implies that stirring does NOT block the subsequent pay-frying of the object.

<e82>

When an actor is pan-fryable, we can pan-fry it by attaching the tag "panFried" to it; once pan-fried, the actor will stay pan-fried as long as it exists. And when an actor is stirrable, we can stir it by attaching the tag "stirred" to it; once stirred, the actor will stay stirred as long as it exists. The code below shows how these lines of logic could be implemented in Prolog.

#$
panFried[n](X) :- panFryable[n-1](X), panFry[n-1](X).
panFried[n](X) :- panFried[n-1](X), alive[n-1](X).

stirred[n](X) :- stirrable[n-1](X), stir[n-1](X).
stirred[n](X) :- stirred[n-1](X), alive[n-1](X).
#$

Furthermore, here is how the act of either pan-frying or stirring might be initiated (See the code below). Whenever a heated pan encounters an actor which is marked as "payFryable", the pan will pan-fry it (i.e. attach the tag "panFried" to it), thus preventing it from being stirred afterwards (or being pan-fried twice). And whenever an oscillating stirrer encounters an actor which is marked as "stirrable", the stirrer will stir it (i.e. attach the tag "stirred" to it), thus preventing it from being stirred twice.

#$
panFry[n](Y) :- pan[n-1](X), heated[n-1](X), panFryable[n-1](Y), collide[n-1](X, Y).
stir[n](Y) :- stirrer[n-1](X), oscillating[n-1](X), stirrable[n-1](Y), collide[n-1](X, Y).
#$

And of course, sometimes we feel the necessity to indicate each unique combination of the actor's tags with a single term. An egg which has been stirred and pan-fried, for example, would be referred to as an omelet, whereas an egg which has been pan-fried WITHOUT being stirred would just be referred to as a fried egg.

#$
omelet[n](X) :- egg[n](X), stirred[n](X), panFried[n](X).
friedEgg[n](X) :- egg[n](X), !stirred[n](X), panFried[n](X).
#$

(Will be continued in {%a href="https://thingspool.net/morsels/page-19.html"%}Part 10{%/a%})











:d:Here is how to make a Prolog game. Using the logical syntax of Prolog, we can construct systems which enforce a wide range of complex rules based upon a simple set of declarative statements (similar to how a few differential equations can be used to describe complex physical phenomena). In this article, I will be explaining how the concept of birth and death are able to be expressed in Prolog's logic programming environment.
:k:Prolog Game, Prolog, Logic Programming, Computational Semantics, Computational Logic, Data Driven Game Design, Game Development, Game Programming, Indie Game, Functional Programming, Haskell, Computer Science, Computer Engineering, Discrete Math
:l:2024-10-05

[Game Programming in Prolog - Part 10] October 5, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 10 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Composition and Decomposition</b></h3>

So far, I have been demonstrating how an actor's transformations (i.e. state transitions) could be represented in logic programming syntax. An example I came up with, as you may remember from the last article, was a set of alternative ways of handling an egg.

A perfectly normal egg, which has just been laid by a chicken, is able to be broken because it is being protected by a solid shell. Once you break it, it becomes a handful of liquid, thereby allowing you to either just pan-fry it directly (in which case it will be turned into a fried egg), or to first stir it an then pan-fry the result (in which case it will be turned into an omelet). This is a rudimentary example of an egg's tech tree.

There is yet another aspect of transformations which I have not explained yet - the concept of merging and splitting. Sometimes, multiple objects combine into a single unit to form a compound structure (like atoms bonding with each other to form a molecule), or sometimes a compound structure gets broken down to multiple smaller units.

This means that transformation (i.e. state transition) is not all about a single line of progression in spacetime. In some cases, multiple lines (objects) merge into a single line, signifying an event where multiple things combine into one thing. In some other cases, a single line (object) splits into multiple lines, signifying an event where one thing decomposes itself into multiple things.

<e83>

In fact, we have already seen an instance of combination before (in Part 8). Remember when I mentioned that you can make omurice by stacking an omelet on top of fried rice? This is clearly a scenario in which multiple objects come together to form a single compound. When they (i.e. omelet and fried rice) were hanging out individually, they were merely two separate entities, having nothing to do with each other. Once they get stacked up, however, they suddenly become parts of one shared object called "omurice". I will restate the formula below for a reminder.

#$
omurice[n](Z) :- friedRice[n-1](X), omelet[n-1](Y), stack[n-1](X, Y, Z).
#$

There is something missing in this recipe, though. How shall we figure out the name (id) of this new actor called "Z"? Apparently, Z is supposed to indicate the omurice which has just been made by the act of stacking up an omelet on top of fried rice. But where does this come from?

This is the place where the definition of "multiple things combining into one thing" starts to get tricky. There are two ways of resolving this problem, so I will go over them one by one.

The first method is to simply assume that the omurice is represented not by a brand new actor, but by one of the existing actors. Before jumping directly into demonstration, I first ought to redefine the "stack" relation; its revised definition is shown in the following snippet, along with a new relation called "below":

#$
below[n](X, Y) :- stack[n-1](X, Y).
below[n](X, Y) :- below[n-1](X, Y), alive[n-1](X), alive[n-1](Y), !unstack[n-1](X, Y).
#$

<e84>

Here, the "stack" relation no longer takes 3 arguments (where the third one was meant to indicate the result of stacking two things). Instead, it now only takes 2 arguments, where the first one (X) represents what is below the other argument (Y). In other words, "stack[n](X, Y)" means, "Y has just been stacked on top of X at time n".

Once we finish stacking Y on top of X, X will of course be "below" Y (because if Y is above X, X must be below Y, right?). And this relation (i.e. "below") will continue to hold, up until the point at which the stack gets destroyed either by the process of "unstacking" or by the destruction of either one of its parts (X or Y).

With this new definition, we are now able to come up with a more concrete depiction of what an omurice is. First of all, let me remind you that we can make an omurice by stacking an omelet on top of fried rice. This process can be carried out by raising the event "stack[n](X, Y)", where X is the fried rice and Y is the omelet.

The main issue is, which actor should the resulting omurice be? Spawning a brand new actor is definitely a valid option, yet it is also possible to avoid such a step altogether.

When we are putting an omelet on top of fried rice, we are not really creating a separate piece of matter out of nowhere; all we are doing is, we are simply "assembling" two existing pieces of matter together, without introducing anything new from a purely physical point of view (aka "Conservation of Mass"). Our habit of giving a distinct name (such as "omurice") to the result of such a process is just for the sake of efficiency in communication - an abstract means of referencing a collection of things, so as to avoid the necessity of repeating a verbose description (such as "omelet on fried rice") every time we refer to it.

So, representing an omurice as a separate actor is not really an absolute requirement, since such an actor will merely be used as a reference and hardly anything else. And the role of a reference can simply be played by an existing actor, such as the fried rice.

When I put an omelet on a plate of fried rice, an intuitively satisfying way to think about it is that I just "transformed" the plain old fried rice into something more advanced (aka "omurice"). I do not consider myself as a wizard who summoned something new out of nowhere.

After all, an ice cream with a cherry on top of it is still an ice cream, and a slice of cheese pizza with an anchovy on it is still a slice of cheese pizza. In both of these cases, the original identity of the subject has never been destroyed; it simply augmented itself to something slightly more complex (such as "cherry topped ice cream" or "anchovy pizza").

The same philosophy applies to the case of omurice. A plate of fried rice with an omelet added on top of it is still a plate of fried rice; it just happens to be carrying an additional constituent in it (i.e. omelet). Therefore, it is perfectly fine to say that this "augmented" fried rice should also be identified as an omurice. The following code demonstrates how this line of reason works.

#$
omurice[n](X) :- friedRice[n-1](X), omelet[n-1](Y), stack[n-1](X, Y).
omurice[n](X) :- omurice[n-1](X), friedRice[n-1](X), below[n-1](X, Y), omelet[n-1](Y).
#$

<e85>

What is happening in the two rules above is quite straightforward. The first rule says that a plate of fried rice will also qualify as an omurice as soon as we put an omelet on top of it. The second rule says that such a resulting omurice will continue being an omurice as long as it is a plate of fried rice sitting below an omelet.

Here, the actor which represents the fried rice also simultaneously represents the omurice, thereby letting us keep track of a new conceptual entity without spawning any brand new actor. This is reminiscent of how a set is often being modeled in computer science, where one of the set's elements plays the role of its representative (Just like how the Eiffel Tower is often used to represent Paris).

<e86>

But of course, this is just one of many examples of composition/decomposition. In some other examples, it might make more sense to come up with a brand new actor to represent the result of a combination. And if that happens to be the case, we better just spawn a new actor (i.e. generate a new unique ID) and use it as a reference.

To be able to manage such a type of reference, however, we will need to utilize yet another concept called "parent-child relation" (Game developers are probably already familiar with this). Once we know how to leverage its full power, we will be able to construct a hierarchy of objects - a neat way of organizing a compound structure. The root node of such a hierarchy (aka "tree"), then, will represent a complex object which is made up of simpler objects.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Parent-Child Relation</b></h3>

Greetings, fellow game developers! I know that you guys are familiar with the so-called "scene hierarchy" or "object hierarchy" in game programming. The vast majority of game engines (such as Unity) include this as one of their core built-in features, due to the fact that it solves a myriad of potential organizational problems. Just like a computer keeps track of files inside a hierarchy of directories (i.e. folders), a game engine keeps track of in-game elements (such as game-objects, prefabs, UI components, etc) inside the project's internal hierarchy.

Why keep things in the form of a hierarchy? The answer to this question is so obvious in most cases, that hardly anyone even feels the necessity of answering it.

We know that a game, as a whole, is one gigantic system which is fairly complex. And because it is complex, we feel that we will be having an easier time developing it if we break it down into a group of somewhat simpler systems, such as "graphics", "physics", "UI", "gameplay", "networking", "config", and so on. Each one of these subsystems, however, is still too complex to handle, so we tend to realize that it will be even better if we break each of them into even simpler components.

This kind of reasoning eventually leads to a hierarchical breakdown of systems (i.e. tree), where each parent node represents the ensemble of its child nodes.

<e87>

The example I just described is a general overview of how a large-scale project might be managed, yet the same exact idea may as well be applied to pretty much any instance of composition. As we have seen before, multiple ingredients can be joined together to form a single compound. In this case, the ingredients are the "children" of their compound (i.e. parent).

<e88>

In the hierarchical worldview, an "omurice" is a parent with at least two children - fried rice and omelet. A "cheeseburger" is a parent who has at least four children - two buns (top and bottom), a patty, and a slice of cheese. Pretty much any object is the parent of its constituent parts.

The definition of the parent-child relation is shown below. First of all, the "addChild" event makes its first argument the parent of its second argument. This relation persists as long as we do not terminate it by raising the "removeChild" event.

#$
parent[n](Parent, Child) :- addChild[n-1](Parent, Child).
parent[n](Parent, Child) :- parent[n-1](Parent, Child), !removeChild[n-1](Parent, Child).
#$

The "addChild" and "removeChild" events are the consequences of the underlying "setChild" event (the details are shown in the code below). The "removeChild" event automatically gets called whenever we set the parent of the child to something other than the child's previous parent, and the "addChild" event automatically gets called whenever we set the parent of the child to something other than "null" (Setting the parent to "null" is the same thing as simply detaching the child from its current parent).

#$
removeChild[n](PrevParent, Child) :- setChild[n](NewParent, Child), parent[n](PrevParent, Child), notEqual(PrevParent, NewParent).
addChild[n](NewParent, Child) :- setChild[n](NewParent, Child), isNotNull(NewParent).
#$

In most cases, it is conventient to just use the "setChild" event to establish the parent-child relations among a group of actors. For example, the following code orders the game to construct a hierarchy which looks like the one displayed in the diagram below.

#$
setChild[0](actor1, actor2).
setChild[0](actor1, actor3).
setChild[0](actor3, actor4).
#$

<e89>

There is one thing I would like to point out, though, in regard to the positioning of child nodes. If you are a game developer, you are probably aware of the fact that there is some kind of "motion synchronization" going on in each parent-child relationship; that is, when a parent moves, its child usually follows its movement by the same exact distance and direction, whereas the converse is not usually true (unless they are part of a rigid body or something).

Such a mechanic can be implemented by first defining the (global) position of a child as the sum of its local position and its parent's global position (See the code below). The local position indicates the child's offset from the center of its parent. If an actor has no locatable parent (in which case only the negation of the "parentPosition" relation will be applicable), its global position will be identical to its local position.

#$
parentPosition[n](Child, PP) :- parent[n](Parent, Child), position[n](Parent, PP).
position[n](X, P) :- parentPosition[n](X, PP), localPosition[n](X, LP), add(PP, LP, P).
position[n](X, LP) :- !parentPosition[n](X, PP), localPosition[n](X, LP).
#$

<e90>

And the way we initialize an actor's local position follows a similar logic. When an actor spawns (i.e. before it acquires any parent), its spawn-position becomes its local position. When it acquires a parent, its global offset from the parent becomes its local position. When it loses its current parent, its global position becomes its local position.

#$
localPosition[n](X, P) :- spawnTime[n](X, n), spawnPosition[n](X, P).

localPosition[n](X, LP) :- addChild[n-1](Parent, X), alive[n-1](X),
    position[n-1](X, P), position[n-1](Parent, PP), subtract(P, PP, LP).

localPosition[n](X, P) :- removeChild[n-1](_, X), alive[n-1](X),
    position[n-1](X, P).
#$

And of course, this local position will persist through the passage in time up until the point of the actor's death, with occasional interceptions such as the "move" event (which forcibly overrides the current position).

#$
localPosition[n](X), NewLP) :- !addChild[n-1](_, X), !removeChild[n-1](_, X),
    move[n-1](X, NewP), alive[n-1](X),
    localPosition[n-1](X, PrevLP), position[n-1](X, PrevP), subtract(NewP, PrevP, Offset),
    add(PrevLP, Offset, NewLP).

localPosition[n](X, LP) :- !addChild[n-1](_, X), !removeChild[n-1](_, X),
    !move[n-1](X, _), alive[n-1](X),
    localPosition[n-1](X, LP).
#$

Here is another gameplay logic we should be aware of. When a parent gets destroyed, its children are usually expected to be destroyed as well (This is not an absolute requirement, but many game engines operate under such an assumption - including Unity). If we want this logic to be in action, we will need to write the following code as well.

#$
despawn[n](Child) :- parent[n](Parent, Child), despawn[n](Parent).
removeChild[n](Parent, Child) :- parent[n](Parent, Child), !alive[n](Child).
#$

The things I have mentioned so far are all the essential stuff we need to know to be able to play with parent-child relations. In the next article, I will explain how these building blocks can be used to represent an omurice as a standalone actor, rather than a mere extraneous identity which is superficially being attached to one of its components (i.e. fried rice).

(Will be continued in {%a href="https://thingspool.net/morsels/page-20.html"%}Part 11{%/a%})











:d:Prolog comes in handy when designing emergent gameplay systems. In this article, I will be explaining how abstract objects and their mutual interactions can be implemented in the language of Prolog.
:k:Prolog, Game Programming, Logic Programming, LISP, Functional Programming, Declarative Programming, Game Systems Design, Data Driven Systems, Digital Systems, Programming Paradigms, Game Development, Computer Science, Software Engineering, Data Structures, Gamedev, Game AI, Relational Databases, Gameplay Algorithms
:l:2024-10-07

[Game Programming in Prolog - Part 11] October 7, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 11 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Compound Object</b></h3>

As I have demonstrated recently, parent-child relations come in handy whenever we are dealing with hierarchical structures. In most cases, it is convenient to assume that a child is a component (i.e. part) of its parent, and a parent is a compound object which is made up of one or more of such components.

With this in mind, let us reimagine our omurice as a whole separate abstract entity which comprises two components (i.e. fried rice and omelet), rather than just an alternative interpretation of the fried rice we already have as an actor.

To do so, we ought to first make sure to spawn a new actor as soon as we stack the omelet on top of the fried rice, and then allow this new actor to represent the resulting omurice. The code below depicts the initial spawning portion of the logic.

#$
spawn[n](<X, Y>, makeOmurice, null) :- friedRice[n](X), omelet[n](Y), stack[n](X, Y).
#$

One thing I should point out here is that the "Src" (Source) parameter of the "spawn" event is designed to be the tuple of two IDs - one which belongs to the fried rice, and the other one which belongs to the omelet. The reason why this is necessary is that, by the time the omurice (i.e. the actor which is supposed to represent the omurice) spawns, we would like it to remember what it is made out of. Otherwise, it won't be able to tell exactly which fried rice and omelet must be associated with itself.

Once the omurice spawns, we will indeed explicitly label it as "omurice" so as to let the rest of the world recognize it as an omurice without analyzing its anatomy. Such a label, then, shall persist as long as the actor lives (See the code below).

#$
omurice[n](Id) :- spawned[n](Id, Src, makeOmurice, Pos).
omurice[n](Id) :- omurice[n-1](Id), alive[n-1](Id).
#$

This is not the end of the story, though. The omurice we just summoned into existence is supposed to represent the collective sum of its two components, which are called "fried rice" and "omelet", respectively. Therefore, we must establish a set of connections between the omurice and its components to explicitly state which ones are part of which.

Fortunately, we know how to do this. We know that the "spawned" event carries two IDs in its "Src" argument - the ID of the fried rice, and the ID of the omelet. So if we fetch the first item of "Src" (x), we will obtain the former, and if we fetch the second item of "Src" (y), we will obtain the latter.

The remaining task, then, is to make the omurice the parent of the given fried rice and omelet. The code implementation of this logic is displayed below.

#$
setChild[n](Id, X) :- spawned[n](Id, Src, makeOmurice, Pos), x(Src, X).
setChild[n](Id, Y) :- spawned[n](Id, Src, makeOmurice, Pos), y(Src, Y).
#$

<e91>

There we have it. Since the omurice is now the parent of an actor named "fried rice" and another actor named "omelet", the system is able to tell that this particular actor (i.e. omurice) is a compound object which is made out of its two components called "fried rice" and "omelet".

However, it is also important for us to ensure that this omurice will continue to exist as an omurice only as long as its internal structure qualifies itself as an omurice.

Let me give you a few examples. If I get rid of the omelet from the omurice, there will no longer be any "omurice" there because only the fried rice will be left. If I get rid of the fried rice from the omurice, there will no longer be any "omurice" there because only the omelet will be left. If I replace the existing omelet with another omelet, on the other hand, there will sill be an "omurice" there, although the question of whether this specific omurice is "the same thing" as the one which was there before is a bit tricky to answer (which reminds us of the Ship of Theseus).

Aside from philosophical ambiguities, however, we can pretty much agree on the point that an omurice will continue being an omurice only as long as it consists of fried rice and an omelet sitting on top of it. In other words, we need to detach the existing omurice from its current children and dispose it if we ever happen to find out that it is no longer identifiable as an omurice (See the code below).

#$
canBeOmurice[n](Id) :-
    parent[n](Id, X), friedRice[n](X),
    parent[n](Id, Y), omelet[n](Y),
    below[n](X, Y).

removeChild[n](Id, X) :- omurice[n-1](Id), !canBeOmurice[n](Id), parent[n](Id, X).
despawn[n](Id) :- omurice[n-1](Id), !canBeOmurice[n](Id).
#$

<e92>

And if we ever wish to manually dismiss an omurice by pulling its components apart, we may fancy that there is a special event called "disassemble" which, when invoked, detects the omurice's two core building blocks (i.e. fried rice and omelet) and unstacks them (Recall that the "unstack" event removes the stacking relation between the two given objects). Once unstacked, the fried rice will no longer be sitting "below" the omelet, which means that the omurice will no longer qualify as an omurice (i.e. The "canBeOmurice" predicate will be FALSE) and thus shall be despawned.

#$
unstack[n](X, Y) :- omurice[n-1](Id), disassemble[n-1](Id),
    parent[n-1](Id, X), friedRice[n-1](X),
    parent[n-1](Id, Y), omelet[n-1](Y),
    below[n-1](X, Y).
#$

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Hierarchical Data Structure</b></h3>

At this point, you may have realized that there are two major categories of objects - those which are made of single actors (aka "elements"), and those which are made of multiple actors (aka "compounds"). The former are reminiscent of individual atoms which cannot be broken down further, whereas the latter are reminiscent of molecules which can be separated into their atomic constituents.

A compound is basically a hierarchy of actors, in which the root (i.e. topmost parent) represents the whole thing and its children represent its parts. Thus, we may imagine that each hierarchy is itself a compound object.

In the previous example, I demonstrated how we are able to construct a compound by assembling a multitude of existing actors together (by means of the stacking operation, etc). However, it is also also possible to let the system automatically initialize the compound's internal structure by the time its root spawns.

Let's say, for instance, that there is an event called "makeBurger" which spawns a burger at the position of the source actor (i.e. X). When this event gets raised, an actor which represents a burger gets created.

Suppose, however, that a burger is defined as a parent of its three core ingredients - the bottom bun, the patty, and the top bun. If any of these three turns out to be missing, the parent will no longer be identifiable as a burger.

The following code illustrates how the "makeBurger" event triggers the spawning of a burger, as well as how it immediately kicks off its own chain reaction immediately upon its birth in order to initialize its own hierarchical structure. As you will see below, the spawning of the burger automatically causes 3 additional spawning processes - (1) Spawning of the bottom bun, (2) Spawning of the patty, and (3) Spawning of the top bun.

#$
spawn[n](X, makeBurger, Pos) :- makeBurger[n](X), position[n](X, Pos).
spawned[n]("{n}_{Src}_{Cause}", Src, Cause, Pos) :- spawn[n-1](Src, Cause, Pos).

spawn[n](Id, makeBurger_bottomBun, Pos) :- spawned[n](Id, Src, makeBurger, Pos).
spawn[n](Id, makeBurger_patty, Pos) :- spawned[n](Id, Src, makeBurger, Pos).
spawn[n](Id, makeBurger_topBun, Pos) :- spawned[n](Id, Src, makeBurger, Pos).
#$

Once spawned, these three component actors will instantly receive their appropriate labels (i.e. "bottomBun", "patty", and "topBun") and become the children of the burger. All these three processes will be executed in parallel because they all belong to separate causes (i.e. "makeBurger_bottomBun", "makeBurger_patty", and "makeBurger_topBun").

#$
bottomBun[n](Id) :- spawned[n](Id, Src, makeBurger_bottomBun, Pos).
bottomBun[n](Id) :- bottomBun[n-1](Id), alive[n-1](Id).
setChild[n](Src, Id) :- spawned[n](Id, Src, makeBurger_bottomBun, Pos).

patty[n](Id) :- spawned[n](Id, Src, makeBurger_patty, Pos).
patty[n](Id) :- patty[n-1](Id), alive[n-1](Id).
setChild[n](Src, Id) :- spawned[n](Id, Src, makeBurger_patty, Pos).

topBun[n](Id) :- spawned[n](Id, Src, makeBurger_topBun, Pos).
topBun[n](Id) :- topBun[n-1](Id), alive[n-1](Id).
setChild[n](Src, Id) :- spawned[n](Id, Src, makeBurger_topBun, Pos).
#$

<e93>

This completes the automatic initialization of the burger's internal hierarchy. All we had to do was spawn a burger; the rest of the processes were simply being handled by the predefined rules above.

There is one more thing we ought to do, though - the maintenance and disposal of the burger's identity. Just like an omurice is allowed to stay being an omurice only as long as it is made out of a stack of fried rice and omelet, a burger, too, must satisfy its own list of criteria in order to ensure its continued existence.

A burger is a compound which is made up of three children - the bottom bun, the patty, and the top bun. There might be additional children, but the presence of such extraneous ingredients do not really matter when it comes to the burger's identity as a generic "burger" (Because, you know, a "double-cheese bacon burger" is still a "burger"; it just happens to be a richer variant). If any of these three children turns out to be missing, the parent will no longer be considered a burger and thus will have to be exterminated.

The code listed here is the set of rules which tell us how such a criterion will be enforced.

#$
burger[n](Id) :- spawned[n-1](Id, Src, makeBurger, Pos).
burger[n](Id) :- burger[n-1](Id), alive[n-1](Id).

canBeBurger[n](Id) :-
    parent[n](Id, C1), bottomBun[n](C1),
    parent[n](Id, C2), patty[n](C2),
    parent[n](Id, C3), topBun[n](C3).

removeChild[n](Id, X) :- burger[n-1](Id), !canBeBurger[n](Id), parent[n](Id, X).
despawn[n](Id) :- burger[n-1](Id), !canBeBurger[n](Id).
#$

<e94>

The first two rules simply state that an actor which has just been spawned by the "makeBurger" event will initially be considered a "burger", and will continue being so as long as it stays alive. This part is structurally identical to that of the omurice example we saw before.

The last two rules, too, structurally resemble those of the omurice example. They are there to ensure that a burger will be safely disposed when it no longer qualifies as a burger.

The rule in the middle is the most important part. The "canBeBurger" predicate basically tells us whether the given burger can still be considered a "burger" during the current time step (i.e. 'n') - that is, whether it still consists of a bottom bun, a patty, and a top bun. If so, this burger will maintain its status as a burger. If not, it will be wiped out of existence.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Complexity Under Control</b></h3>

The ability to define a piece of data as a hierarchy (i.e. tree), either before or after instantiating its components, is an invaluable feature to have in complex and emergent systems.

Oftentimes, game developers feel the necessity to design in-game agents (aka "characters") which are equipped with their own stats, inventories, status effects, scheduled tasks, relationships with other agents, and other pieces of dependent data. In such cases, it is usually sensible to devise each agent as a root node (i.e. topmost parent) of its own subtree, within which all of its inner data entries are stored. The figure below is an illustration of it.

<e95>*

The main benefit of this conceptual model is that it is extremely scalable. Do you want to implement new gameplay features? No problem! Just add more children the actor to support such additional features. If you wish that every NPC had its own inventory of items, for instance, all you need to do is add a chunk of code which creates an "inventory actor" and attaches it to every freshly spawned NPC actor, like the one shown here:

#$
spawn[n](Id, makeInventory, Pos) :- spawned[n](Id, Src, makeNPC, Pos).

inventory[n](Id) :- spawned[n](Id, Src, makeInventory, Pos).
inventory[n](Id) :- inventory[n-1](Id), alive[n-1](Id).

setChild[n](Src, Id) :- spawned[n](Id, Src, makeInventory, Pos).
#$

Once an NPC gets equipped with its own inventory, we are able to let this NPC either pick up an item (by means of the "pickupItem" event) or drop an item (by means of the "dropItem" event).

#$
setChild[n](Y, Item) :- pickupItem[n-1](X, Item), parent[n](X, Y), inventory[n](Y).
removeChild[n](Y, Item) :- dropItem[n-1](X, Item), parent[n](X, Y), inventory[n](Y).
#$

<e96>

We may as well choose to design a rather interesting game mechanic, such as letting an actor steal an item from another actor. Such a feature could be implemented by using the following rule:

#$
setChild[n](Y2, Item) :- stealItem[n-1](Thief, Victim, Item),
    parent[n](Victim, Y1), inventory[n](Y1), parent[n](Y1, Item),
    parent[n](Thief, Y2), inventory[n](Y2).
#$

<e97>

A special exception to such a general rule, too, can be contrived by writing a few additional lines of code. Suppose that we want an NPC to be able to prevent its items from being stolen as long as it possesses an item called "stealShield". A steal-shield is an item which protects all other items in the inventory from thieves. The following code implements this steal-protection ability.

#$
hasStealShield[n](X) :-
    parent[n](X, Y), inventory[n](Y),
    parent[n](Y, Item), stealShield[n](Item).

setChild[n](Y2, Item) :- stealItem[n-1](Thief, Victim, Item),
    !hasStealShield[n-1](Victim),
    parent[n](Victim, Y1), inventory[n](Y1), parent[n](Y1, Item),
    parent[n](Thief, Y2), inventory[n](Y2).
#$

(Will be continued in {%a href="https://thingspool.net/morsels/page-21.html"%}Part 12{%/a%})










:d:Programming in Prolog offers us a new way of designing video games. In this article, I will illustrate the beauty of representing various in-game elements using Prolog's dynamic relations and their procedurally generated semantic data structures.
:k:Prolog, Logic Programming, Declarative Programming, Gameplay Design, Gameplay Engineering, Game Physics, Game Development, CSE, Software Architecture, Game Math, Discrete Math, Set Theory, Graph Theory, Cellular Automata, Game Science, Ludology, Procedural Generation
:l:2024-10-08

[Game Programming in Prolog - Part 12] October 8, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 12 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Emergent Identities</b></h3>

Let me go back to the omurice example and further elaborate upon its hidden intricacies. You may have noticed already, but there is one missing feature in the system I have been devising so far. It is the apparent lack of the system's ability to automatically recognize a specific pattern in the environment and conjure up an appropriately labeled actor for it.

For instance, the code I showcased in the previous article only describes how to explicitly construct an omurice by selecting a pair of specific ingredients (i.e. fried rice and omelet) and making a stack out of them. The rule which executes this logic is reproduced below.

#$
spawn[n](<X, Y>, makeOmurice, null) :- friedRice[n](X), omelet[n](Y), stack[n](X, Y).
#$

This rule, however, misses occasions during which the stacking of fried rice and omelet may occur "by accident" - that is, not by explicitly raising the event called "stack", but by unintentionally putting an omelet on a plate upon which fried rice happens to be situated. In such cases, it will be necessary to detect the presence of such a stack and instantiate an omurice off of them.

Such a line of reasoning can be handled by the additional rule shown below. Instead of listening to the stacking event, it observes the world, checks to see if there is any fried rice which happens to be below an omelet, and spawns an omurice if it is the case.

(Note: "mod(n, 3, 0)" ensures that the checking of the status only happens once during each 3-step time interval. Its purpose is to prevent the spawning of multiple copies of omurice.)

#$
spawn[n](<X, Y>, makeOmurice, null) :-
    mod(n, 3, 0),
    friedRice[n](X), below[n](X, Y), omelet[n](Y),
    !childrenOfOmurice[n](X, Y).

childrenOfOmurice[n](X, Y) :-
    parent[n](P, X), parent[n](P, Y), omurice[n](P).
#$

One might say, "Hey! This is unnecessary. There is no way to stack one thing upon another without calling the "stack" event anyways. So why even bother creating such a superfluous rule? If there ever happens to be a stack of fried rice and omelet, the original rule which listens to the "stack" event will handle such an occasion without missing anything."

This makes sense within the context of what has been demonstrated so far, yet let us not be so rash as to overlook some of the hidden pitfalls.

First of all, we better contemplate upon the meaning of the word "below". What does it mean to be "below" something? Take the anatomy of a burger for example. A typical American cheeseburger comprises a stack of many ingredients, such as buns, patty, cheese, onion, etc.

<f01>

If we imagine a guy who is making such a burger (e.g. Spongebob), we will be able to picture him putting a bun on the table, a patty upon the bun, a sliced cheese upon the patty, a sliced onion upon the cheese, a sliced tomato upon the onion, a lettuce upon the tomato, pickles upon the lettuce, and finally another bun upon the pickles. This process may as well be expressed by the following lines of code (I am assuming here that the guy was producing the burger during the time interval of 0 to 6).

#$
stack[0](bottomBun, patty).
stack[1](patty, cheese).
stack[2](cheese, onion).
stack[3](onion, tomato).
stack[4](tomato, lettuce).
stack[5](lettuce, pickles).
stack[6](pickles, topBun).
#$

<f02>

This is basically a chain of "stack" relations, leading from the lowermost to the upppermost ingredient. Such a chain obviously forms one large stack, which, as a whole, is commonly referred to as a "cheeseburger".

Here, let me ask you a question. Is the patty sitting below the cheese? Oh yes, indeed! The "stack" event which occurred at time 1 clearly says that the guy stacked the cheese on top of the patty, which meaning that the patty must be below the cheese.

Let me ask you another question. Is the patty sitting below the onion? Yes, of course. Since the patty is below the cheese and the cheese is below the onion, we must be able to infer that the patty is below the onion. Just because the patty is not directly touching the onion does not mean that the patty is not below the onion.

By the same spirit, we should also be able to assure that the lettuce is below the top bun, the onion is below the pickles, the bottom bun is below the top bun, and so on. This implies that the relation called "below" is transitive in nature - that is, if X is below Y and Y is below Z, then X must be below Z. And in order to reflect this property, we are obliged to include the following rule in the codebase:

#$
below[n](X, Z) :- below[n](X, Y), below[n](Y, Z).
#$

<f03>

It is not difficult to demonstrate how this works in our cheeseburger example. Once the burger-making guy finishes stacking up all the ingredients (from bottom to top), the Prolog environment will be left with the following predicates (See the code below) which are the results of the series of "stack" events shown previously. Here, we are looking at time 7, the moment after the end of the stacking process.

#$
below[7](bottomBun, patty)
below[7](patty, cheese)
below[7](cheese, onion)
below[7](onion, tomato)
below[7](tomato, lettuce)
below[7](lettuce, pickles)
below[7](pickles, topBun)
#$

So far, nothing explicitly mentions that the patty is below the onion, the lettuce is below the top bun, or that the onion is below the pickles. Using the transitive property of "below", however, we are able to derive the "below" relationships of the items which are not necessarily adjacent to one another. For example, the system is able to conclude that the patty is below the pickles by successively generating a chain of inferences, like the ones shown here:

#$
below[7](patty, pickles)
    ---> below[7](patty, Y), below[7](Y, pickles)
    ---> below[7](patty, Y = lettuce?) below[7](lettuce, pickles)

below[7](patty, lettuce)
    ---> below[7](patty, Y), below[7](Y, lettuce)
    ---> below[7](patty, Y = tomato?), below[7](tomato, lettuce)

below[7](patty, tomato)
    ---> below[7](patty, Y), below[7](Y, tomato)
    ---> below[7](patty, Y = onion?), below[7](onion, tomato)

below[7](patty, onion)
    ---> below[7](patty, cheese), below[7](cheese, onion)
#$

<f04>

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Procedural Tree of Abstraction</b></h3>

The ability to discover such indirect instances of the "below" relation comes in handy when we want the system to automatically detect certain types of abstract objects and give them unique identities.

For example, let us say that a sandwich refers to any stack which consists of two buns and anything in between (i.e. It will be called a "ham sandwich" if there is a ham between the buns, an "egg sandwich" if there is an egg between the buns, a "bun sandwich" if there is yet another bun between the two outermost buns, or even an "empty sandwich" if there is nothing in between). We can let the system spontaneously find out such a type of stack and generate a "sandwich actor" off of it, by means of the rules shown below:

#$
spawn[n](<X, Y>, makeSandwich, null) :-
    mod(n, 3, 0),
    bottomBun[n](X), below[n](X, Y), topBun[n](Y),
    !childrenOfSandwich[n](X, Y).

childrenOfSandwich[n](X, Y) :-
    parent[n](P, X), parent[n](P, Y), sandwich[n](P).

sandwich[n](Id) :- spawned[n](Id, Src, makeSandwich, Pos).
sandwich[n](Id) :- sandwich[n-1](Id), alive[n-1](Id).

setChild[n](Id, X) :- spawned[n](Id, Src, makeSandwich, Pos), x(Src, X).
setChild[n](Id, Y) :- spawned[n](Id, Src, makeSandwich, Pos), y(Src, Y).
...
#$

A stack which qualifies itself as a sandwich does not need to be bound to just one identity called "sandwich". We might as well let the environment detect a multitude of (potentially overlapping) identities and turn them into their own abstract objects, such as "burger", "cheese sandwich", etc.

A stack which comprises two buns and a patty between them can be referred to as a "burger". So, let us spawn a "burger actor" off of these three core components whenever that happens to be the case.

#$
spawn[n](<X, Y, Z>, makeBurger, null) :-
    mod(n, 3, 0),
    bottomBun[n](X), below[n](X, Y),
    patty[n](Y), below[n](Y, Z),
    topBun[n](Z),
    !childrenOfBurger[n](X, Y, Z).

childrenOfBurger[n](X, Y, Z) :-
    parent[n](P, X), parent[n](P, Y), parent[n](P, Z), burger[n](P).

burger[n](Id) :- spawned[n](Id, Src, makeBurger, Pos).
burger[n](Id) :- burger[n-1](Id), alive[n-1](Id).

setChild[n](Id, X) :- spawned[n](Id, Src, makeBurger, Pos), x(Src, X).
setChild[n](Id, Y) :- spawned[n](Id, Src, makeBurger, Pos), y(Src, Y).
setChild[n](Id, Z) :- spawned[n](Id, Src, makeBurger, Pos), z(Src, Z).
...
#$

Besides, a stack which comprises two buns and a slice of cheese between them can be referred to as a "cheese sandwich" because it is a sandwich with cheese in it (It may as well be called "grilled cheese sandwich" if the cheese were grilled).

#$
spawn[n](<X, Y, Z>, makeCheeseSandwich, null) :-
    mod(n, 3, 0),
    bottomBun[n](X), below[n](X, Y),
    cheese[n](Y), below[n](Y, Z),
    topBun[n](Z),
    !childrenOfCheeseSandwich[n](X, Y, Z).

childrenOfCheeseSandwich[n](X, Y, Z) :-
    parent[n](P, X), parent[n](P, Y), parent[n](P, Z), cheeseSandwich[n](P).

cheeseSandwich[n](Id) :- spawned[n](Id, Src, makeCheeseSandwich, Pos).
cheeseSandwich[n](Id) :- cheeseSandwich[n-1](Id), alive[n-1](Id).

setChild[n](Id, X) :- spawned[n](Id, Src, makeCheeseSandwich, Pos), x(Src, X).
setChild[n](Id, Y) :- spawned[n](Id, Src, makeCheeseSandwich, Pos), y(Src, Y).
setChild[n](Id, Z) :- spawned[n](Id, Src, makeCheeseSandwich, Pos), z(Src, Z).
...
#$

This means that, if we put a bun on the table, a patty on top of the bun, a cheese on top of the patty, and finally another bun on top of the cheese, this particular stack will be endowed with 3 concurrent identities - (1) "Sandwich" because it contains two buns as well as something additional in between, (2) "Burger" because it has two buns and a patty in between, and (3) "Cheese Sandwich" because it has two buns and a slice of cheese in between.

<f05>

But wait! There is more. Whenever we happen to discover a stack of ingredients which is simultaneously identifiable as both a burger and a cheese sandwich, we must be able to claim that such a stack is also identifiable as a cheeseburger. And if we ever wish to make sure that every cheeseburger be represented by its own separate entity (i.e. actor), we will need to write down the following code:

#$
spawn[n](<X, Y>, makeCheeseburger, null) :-
    mod(n, 3, 0),
    burger[n](X), parent[n](X, B1), bottomBun[n](B1), parent[n](X, B2), topBun[n](B2),
    cheeseSandwich[n](Y), parent[n](Y, B1), parent[n](Y, B2),
    !childrenOfCheeseburger[n](X, Y).

childrenOfCheeseburger[n](X, Y) :-
    parent[n](P, X), parent[n](P, Y), cheeseburger[n](P).

cheeseburger[n](Id) :- spawned[n](Id, Src, makeCheeseburger, Pos).
cheeseburger[n](Id) :- cheeseburger[n-1](Id), alive[n-1](Id).

setChild[n](Id, X) :- spawned[n](Id, Src, makeCheeseburger, Pos), x(Src, X).
setChild[n](Id, Y) :- spawned[n](Id, Src, makeCheeseburger, Pos), y(Src, Y).

canBeCheeseburger[n](Id) :-
    parent[n](Id, X), burger[n](Id, X),
    parent[n](Id, Y), cheeseSandwich[n](Id, Y).

removeChild[n](Id, X) :- cheeseburger[n-1](Id), !canBeCheeseburger[n](Id), parent[n](Id, X).
despawn[n](Id) :- cheeseburger[n-1](Id), !canBeCheeseburger[n](Id).
#$

<f06>

Here, the first rule says that if there is both a burger and a cheese sandwich which share the same exact pair of buns, their corresponding stack must be identified as a cheeseburger. A cheeseburger is an abstract object which justifies its own existence based upon the existence of two slightly less abstract objects (i.e. a burger and a cheese sandwich). As soon as at least one of these components dies out, the cheeseburger will cease to exist (Why? Because a burger which is not a cheese sandwich is not a cheeseburger, and a cheese sandwich which is not a burger is not a cheeseburger).

<f07>

The benefit of having multiple layers of abstraction is that it allows us to selectively manipulate the game world in all sorts of clever ways. Imagine, for example, that there is a monster which only eats cheese from cheeseburgers (It refuses to eat anything else for some reason). Whenever this monster eats, therefore, we must make sure to remove the cheese from whichever cheeseburger from which it happens to be stealing cheese.

Such a tricky mechanic can be implemented via the code shown below. As soon as the monster steals cheese from a cheeseburger (which corresponds to X) by invoking the event called "removeCheeseFromCheeseburger", the system searches for the given cheeseburger's cheese component by traversing its tree of abstraction and spotting the node which is labeled as "cheese", and proceeds to remove it.

#$
getCheeseFromCheeseburger[n](X, Cheese) :-
    cheeseburger[n](X),
    parent[n](X, CS), cheeseSandwich[n](CS),
    parent[n](CS, B1), bottomBun[n](B1),
    below[n](B1, Cheese), cheese[n](Cheese).

despawn[n](Cheese) :-
    removeCheeseFromCheeseburger[n-1](X),
    getCheeseFromCheeseburger[n](X, Cheese).
#$

This piece of logic, however, takes a bit of care to prevent undesirable side effects. When we are removing an element from the middle of a stack, for instance, we do not necessarily want the original stack to be permanently broken into two parts - the one below the removed element, and the one above the removed element. So, if we do not wish a cheeseburger to be split into two parts whenever a monster steals cheese from it, we better include yet another rule which ensures that the destruction of a node within a linked list of "below" relations will always be accompanied by the gluing of its neighbors (See the following code).

#$
stack[n](X, Z) :- despawn[n](X), below[n](Y, X), below[n](X, Z).
#$

<f08>

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Structural Minimalism</b></h3>

The things which have been demonstrated so far may look a bit too complicated, though. And indeed, it is a reasonable impression to have, especially when we consider the sheer amount of code we are compelled to write just to support the automatic creation and destruction of abstract entities.

If representing compound objects as their own separate actors (such as "burger actor", "cheeseburger actor", etc) is not an absolute requirement, therefore, it may be a better idea to just allow the bottommost elements of their corresponding ingredient-stacks to serve as their representatives (similar to what we did in the first omurice example).

The code below is the aforementioned rules of automatic identity detection, redesigned in a much more concise manner. Here, we are no longer spawning brand new actors to indicate the presence of abstract objects such as "sandwich", "burger", or "cheeseburger". Instead, we are simply attaching extra identities to the bottommost ingredient (i.e. bottom bun) and letting it reflect the characteristics of the whole stack.

#$
sandwich[n](X) :- bottomBun[n](X), below[n](X, Y), topBun[n](Y).
burger[n](X) :- sandwich[n](X), below[n](X, Y), patty[n](Y), below[n](Y, Z), topBun[n](Z).
cheeseSandwich[n](X) :- sandwich[n](X), below[n](X, Y), cheese[n](Y), below[n](Y, Z), topBun[n](Z).
cheeseburger[n](X) :- burger[n](X), cheeseSandwich[n](X).
#$

<f09>

The mechanic of stealing cheese from a cheeseburger, too, can be simplified tremendously under this new condition. Since we are no longer representing a cheeseburger as a tree of abstract nodes, all we have to do here is simply begin examining the burger's stack from the bottom (i.e. bottom bun), find the cheese, and remove it.

#$
despawn[n](Cheese) :-
    removeCheeseFromCheeseburger[n-1](X),
    cheeseburger[n](X), below[n](X, Cheese), cheese[n](Cheese).
#$

(Will be continued in {%a href="https://thingspool.net/morsels/page-22.html"%}Part 13{%/a%})










:d:Prolog offers us a new insight in the field of game programming. In this article, I will be explaining how some of the advanced gameplay features, such as status effects and passive abilities, can be designed in Prolog's beautiful symphony of logic.
:k:Prolog, Logic Programming, Declarative Programming, LISP, Haskell, Functional Programming, Programming Paradigms, Gameplay AI, Game Physics, Game Development, Algorithm Design, Software Design, Game Math, Discrete Math, Theory Of Automata, Game Science, Ludology, Procedural Content, Serious Games, Computer Science, Concurrent Programming, Signal Processing, DSP
:l:2024-10-12

[Game Programming in Prolog - Part 13] October 12, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 13 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>A Brief Recap</b></h3>

In the previous few articles, I primarily spent time illustrating how abstract (compound) objects could be represented in terms of logical relations. This time, I will change the subject a bit and start talking about some of the advanced sorts of interactions which may occur among gameplay agents.

Let me recapitulate the overall structure of the game world. First of all, we have this thing called "the world" which encompasses the entirety of what is happening in our Prolog environment. It is made up of facts (i.e. instances of logical relations), each of which may belong to a certain point in time. A fact which possesses such a time parameter can be referred to as an "event", since it is representative of what happened at the given moment in time.

Symbols which make up the arguments of each fact, on the other hand, usually represent actors. An actor is an in-game object which may contain its own set of states as well as behaviors (Think of an actor as a state machine). In general, game mechanics can be defined in terms of ways in which certain types of actors interact with one another.

<f10>

Actors interact in many ways. Sometimes they do when they touch each other (i.e. collide), or sometimes they do when they see each other from a distance. In some occasions, interactions appear in passive forms (e.g. An egg boiling because there is fire nearby, etc). Sometimes, they may even introduce effects which persist after their initial sources disappear.

An effect which "sticks" to its target and lasts longer than the event from which it originated, is often called a "status effect" (aka "status condition"). And we often find that it is quite convenient to keep track of such a parasitic entity as a child node of a tree, where the root is the actor (e.g. player) to which the effect is being applied.

<f11>

By modeling an actor as a hierarchical data structure (i.e. tree) instead of just a singleton with a bunch of keywords attached to it, we are able to manage a wide range of complex game mechanics without confusing ourselves too much. In this article, I will be demonstrating some of the hidden intricacies (as well as pitfalls) of such a hierarchy-oriented game design by outlining one of its most illustrative examples. It is what I would refer to as the "spell system".

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Spell System</b></h3>

The word "spell" is nothing more than an alternative terminology for "status effect"; I just chose this particular word because it happened to be more concise.

A spell is basically an effect which, when applied to an actor, occupies its body and lives in it for some duration. While a spell is alive, it keeps influencing its host's state in some way or another. Here are some of its typical examples:

(1) A damage-spell decrements the actor's health each time the clock ticks.
(2) A heal-spell increments the actor's health each time the clock ticks.
(3) A stun-spell blocks the actor's movement.
(4) A booster-spell amplifies the actor's movement speed.

... and so on.

Let me begin explaining how spells could be implemented in our Prolog-based gameplay system. Since an actor may contain a fairly huge number of ongoing spells, it will be sensible for us to assume that each spell is a child node of one of the actor's intermediary nodes called "spells". Just like "inventory" is the container of items, "spells" can be thought of as the container of spells.

<f12>

Imagine that there is an event called "addDamageSpell" which adds a new damage-spell to the target actor. Let's say that there are two actors, called "wizard" and "villain", and that the wizard decided to cast a damage-spell to the villain by calling this event. The following rule will then instantiate a damage-spell.

#$
spawn[n](<Caster, Target>, addDamageSpell, null) :- addDamageSpell[n](Caster, Target).
#$

<f13>

If we suppose that the wizard cast the damage-spell at time 5, the spell's spawning process will be carried out by the three steps shown below. Notice that the casting of the spell at time 5 (i.e. "addDamageSpell[5](...)") instantly raised the "spawn" event which, after the delay of a single time step, completed the birth of the spell by generating a new unique ID (i.e. "6_wizard&villain_addDamageSpell").

#$
(STEP 1):
addDamageSpell[5](wizard, villain)

(STEP 2):
spawn[5](<wizard, villain>, addDamageSpell, null)

(STEP 3):
spawned[6](6_wizard&villain_addDamageSpell, null)
#$

Once spawned, this damage-spell will keep existing as long as it is alive (i.e. does not despawn). Aside from ensuring its persistence through the passage in time, however, it also puts itself inside the target's body by making itself a child of the target's "spells" node. The code below ensures that these rules will apply to every damage-spell.

#$
damageSpell[n](Id) :- spawned[n](Id, Src, addDamageSpell, Pos).
damageSpell[n](Id) :- damageSpell[n-1](Id), alive[n-1](Id).

setChild[n](S, Id) :-
    spawned[n](Id, Src, addDamageSpell, Pos),
    y(Src, Target), parent[n](Target, S), spells[n](S).
#$

<f14>

How about removing the spell? You know, when we add a new spell, we better plan to get rid of it later on as well, for otherwise there will soon be truckloads of spells piling up over time.

First of all, a couple of the parent-child rules I had introduced in Part 10 will ensure that a spell will die out as soon as its parent dies out (i.e. When a parent despawns, all of its children are expected to despawn too). This means that, when the villain gets killed, its "spells" node (i.e. spell container) will despawn, which in turn will make all of its ongoing spells despawn automatically.

However, we do not want all spells to simply stick to their host up until the moment of its death. Therefore, we ought to include additional rules to allow other means of removing a spell (See the code below). The first rule simply enables us to delete a damage-spell by invoking an event called "removeSpell", and the other two rules ensure that each damage-spell will "expire" (become obsolete and die out) exactly 10 time steps after its birth.

#$
despawn[n](Id) :- damageSpell[n](Id), removeSpell[n](Id).

lifespan[n](Id, 10) :- damageSpell[n](Id).
despawn[n](Id) :- spawnTime[n](Id, T), lifespan[n](Id, Span), add(T, Span, EndTime), equal(n, EndTime).
#$

Now, let us suppose that the villain contains one active damage-spell in it. The job of a damage-spell, as you might have guessed, is to damage its host on a regular basis (i.e. during each time step). The rule listed below is what impels each damage-spell to apply a damage of magnitude "1" to its current host.

#$
damage[n](Target, 1) :- damageSpell[n](Id), parent[n](S, Id), parent[n](Target, S).
#$

<f15>

Changing the villain's health based upon the currently imposed damage is pretty straightforward. Imagine that the villain has a numerical attribute called "health", which is expressible as a relation such as "health[n](X, H)" where X is the ID of the villain and H is its health at time 'n'.

It will then make sense to update the current health of the villain by subtracting it by the amount of damage applied. When the resulting health is less than or equal to zero, the villain will die. The following code is the implementation of these mechanics.

#$
health[n](X, H2) :- health[n-1](X, H), damage[n](X, D), subtract(H, D, H2).

despawn[n](X) :- health[n](X, H), lessThan(H, 1).
#$

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Aggregate Effects</b></h3>

There is something fishy, though. The rule which updates the current health of the actor says that the new health is the result of subtracting the previous health by the incoming damage. But, what does this "incoming damage" mean, really? Is it just a single event, occurring just once at each moment in time? What if there are multiple sources of damage, then?

<f16>*

This is where the trouble begins. The wizard's damage-spell, which was cast at time 5, is not necessarily the only source of damage which the villain is going to receive. There might be other ongoing damage-spells inside the villain's body, or there might be other adversaries who have been actively attacking the villain. The idea is that there could be multiple causes of damage; if they are targeted against the same actor (i.e. villain), they ought to all add up.

The code below is a brute-force solution to handle this situation. Suppose that there are 4 separate sources of damage (e.g. damage-spells, melee attacks, explosions, etc), all contributing to the reduction in the target actor's health at time 'n'. It will then be technically possible to let these 4 sources independently activate 4 separate damage-events (called "subDamage_0", "subDamage_1", etc), and then make a rule which sums up their damage numbers and applies the resulting sum to the target.

#$
damage[n](Target, Sum) :-
    subDamage_0[n](Target, D0),
    subDamage_1[n](Target, D1),
    subDamage_2[n](Target, D2),
    subDamage_3[n](Target, D3),
    add(D0, D1, D2, D3, Sum).
#$

We all know that this is silly, of course. The number of sources of damage is not even fixed; there might be five, six, seven, or any indefinite number of instances of damage being applied to the same target at each given moment. Also, we are not sure which sources will be mapped into which "subDamage" events.

If there is a knight and a dwarf attacking the villain at the same time, should the knight's attack be mapped into the "subDamage_0" event and the dwarf's attack be mapped into the "subDamage_1" event? Or the other way around? Or something totally different such as "subDamage_2" and "subDamage_3"? How shall we even guarantee that there will never be two or more attackers who happen to be invoking the same exact "subDamage" event? If that happens to be the case, won't only one of their attacks be taken as part of the incoming damage and the rest be ignored?

Due to such concerns, we are not really able to come up with a rule which specifies exactly how the individual damages should be added together. We do not khow how many of them there will be, as well as which ones will be mapped into which "subDamage" events, and so on, at any arbitrary moment in time.

Here is a problem scenario which I will be attempting to solve. Let's say that the wizard decided to apply 3 damage-spells to the villain throughout the span of 3 consecutive time steps - from time 5 to time 7.

<f17>

At time 8, then, the villain will be equipped with 3 damage-spells. We know that these spells will all be simultaneously imposing damage upon their common host (i.e. villain), each of them contributing a damage of size 1. So our expectation is that the villain must be receiving 3 damage points at each time step.

<f18>

This, however, turns out to be not the case. As you can see from the snippet below, these 3 spells all invoke the same exact event called "damage[8](villain, 1)" at time 8 because they are all targeting the same host (i.e. villain) and have the damage strength of 1. In the end, the total damage of 1 will be applied to the villain at time 8 because "damage[8](villain, 1)" was the only event which was being triggered at time 8. The fact that it was triggered multiple times via multiple sources does not make any difference from Prolog's point of view.

#$
damage[8](villain, 1) :-
    damageSpell[8](6_wizard&villain_addDamageSpell),
    parent[8](spells, 6_wizard&villain_addDamageSpell),
    parent[8](villain, spells).

damage[8](villain, 1) :-
    damageSpell[8](7_wizard&villain_addDamageSpell),
    parent[8](spells, 7_wizard&villain_addDamageSpell),
    parent[8](villain, spells).

damage[8](villain, 1) :-
    damageSpell[8](8_wizard&villain_addDamageSpell),
    parent[8](spells, 8_wizard&villain_addDamageSpell),
    parent[8](villain, spells).

FINAL RESULT ---> damage[8](villain, 1).
#$

The problem is that the total amount of damage (i.e. second argument of "damage[8](...)") does not increment each time one of the 3 spells raises the event: "damage[8](villain, 1)".

This means that we need to somehow "enhance" the language of Prolog a bit in order to be able to implement such a cumulative effect. The goal is this: We need to come up with a way to accumulate (i.e. add up) one of the arguments of an event, even if it gets called repeatedly during the same exact time step.

And for the purpose of allowing this new feature, I will simply come up with a new attribute (i.e. special keyword) for an argument inside a Prolog relation. It is denoted by "[acc]" (stands for "accumulate"), and can be attached in front of any numerical argument. So for example, the damage-spell's logic can be adjusted to look like the one shown below:

#$
damage[n](Target, [acc]1) :- damageSpell[n](Id), parent[n](S, Id), parent[n](Target, S).
#$

This is the same exact rule as the one demonstrated before, except that now the second parameter of the "damage" event (i.e. damage amount) is prefixed by "[acc]". It basically orders the Prolog system to keep accumulating this number during the current time step, while it is evaluating the rules. Only after the end of the clock cycle, this number will be reset to 0.

The following snippet shows the result of the fix. As you can see, the amount of damage which is to be applied to the villain accumulates itself over the sequence of the "damage" event calls. The first spell increases the amount from 0 (initial value) to 1, the second spell increases the amount from 1 to 2, and the third spell increases the amount from 2 to 3. The net result is 3, which means that the villain's health will be reduced by the amount of 3 by the end of time step 8.

#$
damage[8](villain, [acc]1) :-
    damageSpell[8](6_wizard&villain_addDamageSpell),
    parent[8](spells, 6_wizard&villain_addDamageSpell),
    parent[8](villain, spells).

damage[8](villain, [acc]2) :-
    damageSpell[8](7_wizard&villain_addDamageSpell),
    parent[8](spells, 7_wizard&villain_addDamageSpell),
    parent[8](villain, spells).

damage[8](villain, [acc]3) :-
    damageSpell[8](8_wizard&villain_addDamageSpell),
    parent[8](spells, 8_wizard&villain_addDamageSpell),
    parent[8](villain, spells).

FINAL RESULT ---> damage[8](villain, [acc]3).
#$

(Will be continued in {%a href="https://thingspool.net/morsels/page-23.html"%}Part 14{%/a%})












:d:Here is a basic algorithm for building a Prolog game engine. By leveraging the elegance of logic programming, this engine will let game developers design a wide range of gameplay systems using Prolog's declarative syntax.
:k:Prolog, Logic Programming, Declarative Programming, Game Science, Game Research, Game Development, Game Developers, Game Design, Automata, LISP, Functional Programming, Haskell, Prolog Systems, Gameplay Systems, Gameplay Engineering, Serious Games, Simulation, Robotics, AI, Expert Systems
:l:2024-10-14

[Game Programming in Prolog - Part 14] October 14, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 14 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Pitfalls of Logic Programming</b></h3>

So far, I have demonstrated quite a variety of game mechanics and how they could be designed in the language of Prolog. I have not yet, however, carefully dealt with the matter of optimization in this subject.

Those of you who have learned the basics of Prolog, or logic programming in general, would have realized that a program which is based upon logical relations does not necessarily run efficiently unless we take extra precautions on how it is being implemented. A standard Prolog application, for example, is not so computationally elegant in the sense that it is prone to perform exhaustive searching and pattern matching of relations in order to find the right answer to a query.

A typical Prolog system, unless it is provided with clever algorithmic shortcuts, exhibits a tendency to solve problems by means of recursive tree search, which is reminiscent of initiating a tree of function calls but more "comprehensive" in the sense that it often needs to force itself to traverse all the alternative pathways via which a solution could be derived.

Whereas a function only requires the system to apply the given parameters to the body of the expression and return the result of evaluation, a logical statement (such as a horn clause) requires the system to come up with every possible permutation of parameters which could manifest themselves to a valid answer. And the process of searching for all such possibilities can oftentimes waste a great deal of computational resources, both in terms of time and space.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Optimization via Specialization</b></h3>

In order to create a fairly efficient gameplay system based off of the language of Prolog, therefore, we better abandon the notion of simply letting Prolog take care of the given set of rules based upon its default mode of computation.

Instead, we ought to reimagine the language from the ground up and curtail any of the overgeneralized parts of its core algorithm, so as to specialize the engine of logic to fit our needs. This will help us optimize the system, letting it update the in-game relations (e.g. actors, events, etc) without going on a roundabout of unnecessary searching steps.

(Note: You may as well imagine this as a process of designing a zombie apocalypse game. Zombies do not require highly advanced pathfinding algorithms such as A-star, so we will end up wasting tons of computational power if we simply assume that every game character should be equipped its own A-star pathfinding behavior. This means that we can optimize our game by getting rid of such a superfluous form of intelligence. Likewise, we can optimize the way in which our Prolog system runs by getting rid of superfluous computational steps.)

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Derivation of Facts</b></h3>

So, let us start implementing the engine of Prolog from scratch, rather than simply grabbing its standard interpreter and using it for granted.

First of all, we all know that this language comprises a list of rules (i.e. horn clauses), each of which in turn comprises a list of relations. Whenever the program tries to see if a rule holds, it attempts to figure out a set of arguments which satisfy all the relations on the right-hand side of the rule. For a quick demonstration, let me give you a couple of examples of how this may work.

What is displayed below is the simplest case I could come up with. It does not yet involve any argument whatsoever, which makes answer-finding extremely straightforward. The only thing that the system needs to do is look up the list of facts and verify that the required ones are present.

#$
---------- Time = 0 ----------
FACTS:
    rainy.
RULES:
    humid :- rainy.

------------------------------
#$

The above rule says that, if the weather is rainy, it must be humid as well. We can easily imagine that the application will look at this rule, check to see if the fact "rainy" is available, and integrate "humid" as another fact if so. Since "rainy" is a fact, "humid" will be a fact, too.

#$
---------- Time = 0 ----------
FACTS:
    rainy.
RULES:
    humid :- rainy.

---------- Time = 1 ----------
FACTS:
    rainy.
    humid.
RULES:
    humid :- rainy.

------------------------------
#$

Let me add another rule which states that the weather is obnoxious as long as it is both humid and hot. Also, I have added a new initial fact called "hot" here, which means that one of the conditions is already met.

#$
---------- Time = 0 ----------
FACTS:
    rainy.
    hot.
RULES:
    humid :- rainy.
    obnoxious :- humid, hot.

------------------------------
#$

We can imagine that the Prolog interpreter will scan the first rule and conclude that "humid" must be listed as a fact because the weather is rainy. After doing that, it will scan the second rule and conclude that "obnoxious" should also be included as a fact because both "humid" and "hot" can be found within the list of facts.

#$
---------- Time = 0 ----------
FACTS:
    rainy.
    hot.
RULES:
    humid :- rainy.
    obnoxious :- humid, hot.

---------- Time = 1 ----------
FACTS:
    rainy.
    hot.
    humid.
    obnoxious.
RULES:
    humid :- rainy.
    obnoxious :- humid, hot.

------------------------------
#$

What if the two rules were ordered differently, like the ones shown below?

#$
---------- Time = 0 ----------
FACTS:
    rainy.
    hot.
RULES:
    obnoxious :- humid, hot.
    humid :- rainy.

------------------------------
#$

In this case, too, the result will be the same. I will tell you why.

When the interpreter scans the first rule, it will first try to find out if "humid" is a fact. Since "humid" is not explicitly listed as a fact yet, the interpreter will search for a rule from which "humid" could be inferred as a fact (This is plan B). And, voila! There indeed is such a rule; it is the second entry in the list of rules (i.e. "humid :- rainy.").

In this second rule, we can clearly see that "humid" must be a fact if "rainy" is a fact. So the interpreter will look up the list of facts and instantly be able to tell that "rainy" is definitely present in it, which qualifies it as a fact. Thus, "humid" will be included as a fact.

After making such a conclusion, the interpreter will go back to the original rule (i.e. "obnoxious :- humid, hot."), this time with the knowledge that "humid" is a fact. This implies that the first predicate (i.e. "humid") is satisfied, so the system will proceed to take a look at the second one, which is called "hot".

Is "hot" a fact? Oh yes, it is listed as one of the available facts. Since both "humid" and "hot" turned out to be facts, Prolog will conclude that "obnoxious" must also be a fact. So it will put "obnoxious" in the list of facts.

Having finished scanning the first rule, it will proceed to scan the second rule. But then, the goal of the second rule (i.e. "humid :- rainy.") is to figure out what makes "humid" a fact. Well! It already is listed as a fact, so we shouldn't even bother to evaluate this rule once again just to repeatedly verify its truthfulness. So, we will skip this one and wrap up the current clock cycle because there is no more rule to scan.

#$
---------- Time = 0 ----------
FACTS:
    rainy.
    hot.
RULES:
    obnoxious :- humid, hot.
    humid :- rainy.

---------- Time = 1 ----------
FACTS:
    rainy.
    hot.
    humid.
    obnoxious.
RULES:
    obnoxious :- humid, hot.
    humid :- rainy.

------------------------------
#$

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Conditional Facts</b></h3>

It's been pretty easy-going so far. You see, the Prolog environment only needs to keep track of two lists of data - one for the facts which have been identified so far, and the other one for rules which are to be scanned for the purpose of deriving new facts out of old ones.

In general, we should expect the system to scan the entire list of rules during each time step (i.e. clock cycle) and add the acquired facts to the list of existing facts, while discarding ones that are considered obsolete. Our previous example did not involve the removal of any of the existing ones (because none of them could be considered obsolete at any given moment in time), yet we will see instances of such an action later on.

Let me provide you with a slightly more complex example. This time, the relations will be carrying arguments in them (See the code below).

#$
---------- Time = 0 ----------
FACTS:
    rainy(seattle).
    near(seattle, bellevue).
RULES:
    humid(City) :- rainy(City).
    humid(City2) :- rainy(City1), near(City1, City2).

------------------------------
#$

Observe the list of facts which are initially given. The first one says that Seattle is a rainy city, and the second one says that Bellevue is a city located nearby Seattle.

Aside from the list of facts, we have the list of rules. The first rule tells us that if a city is rainy, it must be humid as well. The second rule states that a city which is nearby a rainy city must be considered humid as well.

Let's run our imaginary Prolog interpreter once again, and see what kinds of facts shall be derived from this initial set of definitions. First, it will take a look at the first rule (i.e. "humid(City) :- rainy(City)"), and ask itself:

"All right. I would like to know if 'humid(City)' can be included in the list of facts. In order to figure it out, I must first know which values of 'City' will enable 'humid(City)' to become a fact. I already know that these values are the ones which, when plugged into the rule, will qualify all the relations on the right-hand side as facts."

Thus, it will scan the right-hand side and realize that it only contains one relation, "rainy(City)", which implies that "humid(City)" will be a fact for any value of "City" which makes "rainy(City)" a fact.

To find out such values, the interpreter will first look up the list of facts, and immediately notice that "rainy(seattle)" is already listed as one of the given facts. It means that setting the value of "City" to "seattle" will make "rainy(City)" a fact, which in turn will make "humid(City)" a fact according to the first rule. Therefore, the conclusion will be that "humid(seattle)" must be declared as a fact, meaning that it ought to be included in the list of facts.

#$
FACTS:
    rainy(seattle).
    near(seattle, bellevue).
    humid(seattle).
#$

Since there is no other value of "City" which can be applied to the first rule, the system will then simply move on to the second rule.

The second rule says that a city is humid if it is nearby a rainy city. Such a city should refer to any value of "City2" which satisfies both "rainy(City1)" and "near(City1, City2)".

Let us solve the first relation. Which values of "City1" make "rainy(City1)" a fact? From the list of facts, we can instantly tell that "seattle" is the only "City1" which maps into an existing fact (i.e. "rainy(seattle)"). From the list of rules, we can tell that there is no rule from which a fact of type "rainy" can be derived (In other words, there is no horn clause whose left-hand side begins with the word "rainy"). Therefore, we know that "seattle" is the only possible value to which "City1" can be bound.

If we substitute "City1" with "seattle", then, the rule will appear like this:

#$
humid(City2) :- rainy(seattle), near(seattle, City2).
#$

We know that "rainy(seattle)" is a fact. The only remaining task is to find a value of "City2" which will make "near(seattle, City2)" a fact. What would that be?

Again, we will look back at the list of facts, and try to gather all the existing facts which begin with the word "near". Obviously, "near(seattle, bellevue)" is the only fact in this list which meets such a criterion. Since the second argument of "near(City1, City2)" is what "bellevue" is supposed to represent, we will bind the value of "City2" to "bellevue". This will result in the following set of substitutions:

#$
humid(bellevue) :- rainy(seattle), near(seattle, bellevue).
#$

Okay! Since "rainy(seattle)" and "near(seattle, bellevue)" are both listed as facts, the interpreter is now able to conclude that this rule holds as long as "City1" is bound to "seattle" and "City2" is bound to "bellevue", hence that "humid(bellevue)" must be included as yet another fact under such a set of bindings.

#$
FACTS:
    rainy(seattle).
    near(seattle, bellevue).
    humid(seattle).
    humid(bellevue).
#$

Now that the system has gone over all the listed rules (i.e. both the first and the second), it will terminate the current clock cycle and increment the time step by 1. The following record, therefore, will be the result of all the tasks which were carried out during the first time step (n = 0).

#$
---------- Time = 0 ----------
FACTS:
    rainy(seattle).
    near(seattle, bellevue).
RULES:
    humid(City) :- rainy(City).
    humid(City2) :- rainy(City1), near(City1, City2).

---------- Time = 1 ----------
FACTS:
    rainy(seattle).
    near(seattle, bellevue).
    humid(seattle).
    humid(bellevue).
RULES:
    humid(City) :- rainy(City).
    humid(City2) :- rainy(City1), near(City1, City2).

------------------------------
#$

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Time-Bound Facts</b></h3>

For the sake of designing a gameplay system as opposed to a mere answer-finder, though, we need to have temporal relations (aka "events") - that is, relations which belong to certain points in time, instead of existing timelessly as though they are pure ideas such as mathematical theorems, laws of nature, etc.

Just like I had mentioned during the early parts of the series (e.g. {%a href="https://thingspool.net/morsels/page-11.html"%}Part 2{%/a%} and {%a href="https://thingspool.net/morsels/page-12.html"%}Part 3{%/a%}), time plays a crucial role in the design of video games. It is because the concept of time is indispensable in a system which is driven by a sequence of events.

Many things happen inside a game, such as gunshots, explosions, births, deaths, and plenty of others. They can all be classified as "events", and events belong to certain points in time, as opposed to static facts which are considered "true" regardless of at which moment in time they are being asserted.

Unlike a timeless fact which does not possess a time parameter, an event is a time-dependent fact which is only "true" at a specific time step. An event called "gunshot[8]", for instance, is a gunshot which occurred only at time 8 and nowhere else on the timeline. If gunshots happened during three consecutive time steps, we would have to list three separate events which belong to three consecutive time steps such as: "gunshot[8], gunshot[9], gunshot[10]".

Since the vast majority of facts inside a video game are time-dependent in nature (i.e. they are "events" instead of pure ideas), we will definitely need to make sure that the Prolog interpreter is capable of handling relations which have time parameters in them.

So, here is an example:

#$
---------- Time = 0 ----------
FACTS:
    rainy[0](seattle).
    near(seattle, bellevue).
RULES:
    humid[n](City) :- rainy[n](City).
    humid[n](City2) :- rainy[n-1](City1), near(City1, City2).

------------------------------
#$

This one looks the same as the previous scenario, except that now the "rainy" and "humid" relations are bound to specific points in time.

A city which was raining at one moment in time is not necessarily rainy at another moment in time. Also, a city which was humid at one moment in time is not necessarily humid at another moment in time. This is why, in our updated example, facts concerning raininess or humidity of the cities are equipped with their own temporal offsets. On the other hand, the "near" relation is considered timeless because two nearby cities won't stop being nearby any time soon.

Let us analyze both the initial list of facts as well as the initial list of rules. The first given fact says "rainy[0](seattle)". This means that the city of Seattle was rainy at time 0. We can never be sure, based upon this fact alone, that Seattle will stay rainy at time 1, 2, 3, or else, but at least we can absolutely be sure that it was rainy at time 0.

The second fact, "near(seattle, bellevue)", simply states that Seattle and Bellevue have been close to each other, and will stay being close to each other forever. This fact, therefore, is timeless in the sense that its truth is eternal; it has been true all the time, and it shall stay true as long as we are alive to witness the passage in time.

What about the rules? The first rule claims that a city which is currently rainy must also be humid at the same time. The second rule says, on the other hand, that a city which is nearby a rainy city will become humid not immediately, but after a delay of 1 time step (Another way of putting it would be: "If a city was rainy during the previous time step, its neighboring cities will become humid during the current time step."). Recall that "n" refers to the current time.

The Prolog system will begin scanning this initial set of information, starting at time 0.

First, we can expect the interpreter to read the first rule and stumble upon the time parameter "n". As I just mentioned, "n" indicates the current time, which is 0. So we will first substitute all the "n"s in this rule with the value of 0, which yields:

#$
humid[0](City) :- rainy[0](City).
#$

Okay, now we know the exact point in time to which the associated facts ("humid" and "rainy") should belong. What else? Just like it was illustrated in the previous example, the interpreter will need to first look up the list of given facts to see if there are facts which correspond to the ones on the right-hand side of the rule (i.e. "rainy[0](City)").

And, you guessed it right. There is a fact called "rainy[0](seattle)", whose type ("rainy") and time (0) both match the ones on the right-hand side's relation which is "rainy[0](City)". This leads to the following substitution:

#$
humid[0](seattle) :- rainy[0](seattle).
#$

... which leads to the derivation of a new fact called "humid[0](seattle)". This makes sense because the rule says that if a city is rainy, it must simultaneously be humid. Since Seattle was rainy at time 0, we must be able to tell that Seattle was also humid at time 0.

#$
FACTS:
    rainy[0](seattle).
    near(seattle, bellevue).
    humid[0](seattle).
#$

Let's move on to the second rule. This rule states that in order for "humid[n](City2)" to be a fact, both "rainy[n-1](City1)" and "near(City1, City2)" must be evaluated as facts.

Before investigating these two requisite conditions, let us first substitute all the instances of "n" in this rule with the current time value (0). If we do that, the rule will look like this:

#$
humid[0](City2) :- rainy[-1](City1), near(City1, City2).
#$

The goal of the interpreter is to find the specific values of "City1" and "City2" which will turn both "rainy[-1](City1)" and "near(City1, City2)" into facts. Let me start with the first relation, "rainy[-1](City1)".

Let us take a look at the list of facts. Does any of the given facts begin its expression with "rainy[-1]"? No, absolutely not. There is a fact called "rainy[0](seattle)", yet it only tells us about the raininess of the city at time 0, not time -1. There is no given fact which explicitly shows us which city was rainy at time -1.

Since we cannot find a possible candidate of "rainy[-1](City1)", let us take a look at the other rules, for the hope of being able to derive a fact which may begin with "rainy[-1]". Unfortunately, none of the rules provides us with a way to infer a new fact of type "rainy" (i.e. None of the horn clauses begins its left-hand side with the word "rainy").

Since neither the list of facts nor the list of rules gives us a method of finding a fact which corresponds to the format "rainy[-1](...)", the right-hand side of the second rule (i.e. "humid[0](City2) :- rainy[-1](City1), near(City1, City2)") can never be satisfied during time 0, which implies that we are unable to derive a fact of form "humid[0](City2)" from this rule during the current clock cycle.

Now that there is no more rule to evaluate, the interpreter should stop at this moment and wrap up the current time frame. The updated list of facts will then be carried over to the next time step (n = 1), like the one displayed below:

#$
---------- Time = 0 ----------
FACTS:
    rainy[0](seattle).
    near(seattle, bellevue).
RULES:
    humid[n](City) :- rainy[n](City).
    humid[n](City2) :- rainy[n-1](City1), near(City1, City2).

---------- Time = 1 ----------
FACTS:
    rainy[0](seattle).
    near(seattle, bellevue).
    humid[0](seattle).
RULES:
    humid[n](City) :- rainy[n](City).
    humid[n](City2) :- rainy[n-1](City1), near(City1, City2).

------------------------------
#$

The new time step is now here to commence. The current time is now 1, instead of 0. The list of facts contains one extra fact called "humid[0](seattle)", which was something that the interpreter derived during the previous time step (n = 0). Other than that, everything else stays the same.

Now that the new clock cycle has begun, the system will of course have to repeat what it did before. It wlll begin scanning the list of rules. Let's see, what is the first rule in the list? Oh, it is: "humid[n](City) :- rainy[n](City)". Let us substitute all of its "n"s with the current time step (i.e. 1). This will give us:

#$
humid[1](City) :- rainy[1](City).
#$

The next step is to evaluate the right-hand side of the rule to see if the rule can be satisfied. Does any of the given facts begin with "rainy[1]"? No. There indeed is a fact which begins with "rainy[0]", but it only tells us which city was rainy during the previous time step. It does not tell us which city is rainy right now, at the present moment (n = 1). Thus, no fact of the form "humid[1](City)" can be derived from this rule.

What about the second rule? Again, we should first substitute its time parameters with their appropriate values. The result will then look like this:

#$
humid[1](City2) :- rainy[0](City1), near(City1, City2).
#$

Here, we are seeing something recognizable. One of the listed facts is "rainy[0](seattle)", which means that this rule might be satisfied if we bind the value of "City1" to "seattle". Keeping this in mind, let us proceed to the next relation called "near(City1, City2)".

Once more, we will look up the list of facts and try to see if any of them has the same format as "near(City1, City2)". And, indeed! There is a fact called "near(seattle, bellevue)", which also happens to expect us to bind the value of "City1" to "seattle". We are lucky in this case because such a binding already exists and does not introduce any contradiction. Meanwhile, it also expects us to bind "City2" to "bellevue" in order to make "near(City1, City2)" a fact. So, let us do that as well.

And guess what? As soon as we bind "City1" to "seattle" and "City2" to "bellevue", we are left with the following expression:

#$
humid[1](bellevue) :- rainy[0](seattle), near(seattle, bellevue).
#$

Since both "rainy[0](seattle)" and "near(seattle, bellevue)" are listed as facts, we now have the right to assert that "humid[1](bellevue)", the left-hand side of the horn clause, must be considered a fact as well.

#$
FACTS:
    rainy[0](seattle).
    near(seattle, bellevue).
    humid[0](seattle).
    humid[1](bellevue).
#$

There are no more rules to look at, so our process of deriving new facts in this current time frame is over. Now that we are also dealing with this new concept called "passage in time", however, we must also do our job of getting rid of facts which have become obsolete due to their old age.

A timeless fact (i.e. a fact without a time parameter) is destined to stay forever; its truth is everlasting, and no matter how much time passes by, it will always remain in our list of facts.

A fact which belongs to a certain point in time, on the other hand, is only true within the context of the given time step. For example, the fact called "rainy[0](seattle)" describes an event which occurred at time 0. Thus, we can guarantee that this particular fact will not be referenced if none of the rules happen to refer to any of the events which occurred at time 0.

Let us take a look at the list of rules:

#$
RULES:
    humid[n](City) :- rainy[n](City).
    humid[n](City2) :- rainy[n-1](City1), near(City1, City2).
#$

If you just look at the right-hand sides of the two given rules, you will realize that the most distant point in the past that any of these rules will ever happen to access is "n-1", which is one step back in time. This means that the rules will never have to look up a fact which is older than "n-1".

Up until time 1, we have been listing "rainy[0](seattle)" as a fact because, if the current time is 1 (i.e. n = 1), the relation "rainy[n-1](City1)" will definitely require us to observe a fact of type "rainy" at time 0 (since 1-1 = 0). So, we know that "rainy[0](seattle)" will still be used at time 1. The same logic applies to other available facts, such as "humid[0](seattle)".

However, the interpreter is now wrapping up this time step (n = 1) and is about to move on to the next time step (n = 2). When time step 2 begins, will any of the facts which belonged to time 0 still be referenced for the purpose of deriving new facts? Absolutely not! None of the events which occurred at time 0 will be used anymore, since 1 (= 2-1) is now the most distant point in the past that the rules will ever be looking back.

This means that both "rainy[0](seattle)" and "humid[0](seattle)" will be obsolete as soon as the current time becomes 2. So, let us make our interpreter get rid of them from the list of facts, leaving only the other two:

#$
FACTS:
    near(seattle, bellevue).
    humid[1](bellevue).
#$

Once this cleanup process is over, the system can then proceed to the next time step (n = 2).

#$
---------- Time = 0 ----------
FACTS:
    rainy[0](seattle).
    near(seattle, bellevue).
RULES:
    humid[n](City) :- rainy[n](City).
    humid[n](City2) :- rainy[n-1](City1), near(City1, City2).

---------- Time = 1 ----------
FACTS:
    rainy[0](seattle).
    near(seattle, bellevue).
    humid[0](seattle).
RULES:
    humid[n](City) :- rainy[n](City).
    humid[n](City2) :- rainy[n-1](City1), near(City1, City2).

---------- Time = 2 ----------
FACTS:
    near(seattle, bellevue).
    humid[1](bellevue).
RULES:
    humid[n](City) :- rainy[n](City).
    humid[n](City2) :- rainy[n-1](City1), near(City1, City2).

------------------------------
#$

Okay, here is the same cycle all over again. The system will scan the rules one by one, derive new facts from the given lists (based on the latest time step, which is 2), delete obsolete facts, and then move on to the next time step, go over the same cycle again, again, and again, etc.

We are able to tell that, at time 2, no more facts can possibly be inferred from any of the given rules. Both of the two rules require a fact of type "rainy" to exist, yet we can clearly see that none of the listed facts is of type "rainy". Also, we have no rule from which a new fact of type "rainy" is capable of being instantiated, either. Thus, none of the rules will be satisfied and no more fact is going to emerge.

What about obsolete facts? Now that the current time has been incremented to 2, we must once again inspect the list of facts and check to see if any of them has become obsolete.

"near(seattle, bellevue)" is timeless, so we should just skip over it (because we know it will never become obsolete). How about "humid[1](bellevue)"? Since none of the right-hand sides of the rules references an event of type "humid" which occurred at a point in time that is less than or equal to 1, we know that this particular fact has now become obsolete. So, we can wipe this out of the list, leaving only "near(seattle, bellevue)" and nothing else.

#$
FACTS:
    near(seattle, bellevue).
#$

This will lead to the following history of facts, their births, and their deaths:

#$
---------- Time = 0 ----------
FACTS:
    rainy[0](seattle).
    near(seattle, bellevue).
RULES:
    humid[n](City) :- rainy[n](City).
    humid[n](City2) :- rainy[n-1](City1), near(City1, City2).

---------- Time = 1 ----------
FACTS:
    rainy[0](seattle).
    near(seattle, bellevue).
    humid[0](seattle).
RULES:
    humid[n](City) :- rainy[n](City).
    humid[n](City2) :- rainy[n-1](City1), near(City1, City2).

---------- Time = 2 ----------
FACTS:
    near(seattle, bellevue).
    humid[1](bellevue).
RULES:
    humid[n](City) :- rainy[n](City).
    humid[n](City2) :- rainy[n-1](City1), near(City1, City2).

---------- Time = 3 ----------
FACTS:
    near(seattle, bellevue).
RULES:
    humid[n](City) :- rainy[n](City).
    humid[n](City2) :- rainy[n-1](City1), near(City1, City2).

------------------------------
#$

No more explanation will be necessary at this point. The interpreter will proceed to time step 4 and try to derive new facts, but fail once again. No existing fact will be thrown away either, since the only thing in the list is "near(seattle, bellevue)". This frozen state will stay as it is forever, no matter how much time passes by. This is the "heat death" of the system.

<f19>

(Will be continued in {%a href="https://thingspool.net/morsels/page-24.html"%}Part 15{%/a%})









:d:Developing a Prolog game engine is a challenge, but it is worth the effort. In this article, I will be illustrating subtle aspects of relational database design and how they constitute the core of Prolog's query-based game logic.
:k:Prolog, Logic Programming, Relational Database, SQL, MySQL, AI, Expert Systems, Search Engine, RDBMS, NoSQL, Database Design, Game Mechanics, Gameplay Systems, Emergent Systems, Game Programming, Game Development, Game Science, Functional Programming, LISP, Haskell, GraphQL, Game Engine
:l:2024-10-16

[Game Programming in Prolog - Part 15] October 16, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Before You Read...</b></h3>

This is Part 15 of the series, "Game Programming in Prolog". In order to understand what is going on in this article, please read {%a href="https://thingspool.net/morsels/page-10.html"%}Part 1{%/a%} first.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Implementation of the Game Loop</b></h3>

In the last article, I spent quite a bit of time demonstrating our "hypothetical Prolog game engine" in action. If you have gone through my seemingly verbose step-by-step description of what is supposed to happen during the application's runtime, you would have recognized a common protocol via which the code is expected to be interpreted.

Instead of just hopping from one example to another and making case-by-case analysis, I will try to write an actual piece of code which may reflect the underlying logic with a fair amount of accuracy. It may not be directly written in Prolog, since I am assuming here that Prolog itself could be treated as a scripting language which is embedded within a more general-purpose programming environment.

Imagine that we are constructing our own custom game engine which consists of two major parts - outer part and inner part.

<f20>

The outer part is written in a popular programming language such as C#, which runs on Unity or some other easy-to-use development framework. This way, we will be able to conveniently build portions of the game which do not necessarily offer distinctive benefits when they are written in Prolog. For instance, I do not think that writing the entire graphics engine (e.g. OpenGL) using Prolog is a good idea from a pragmatic standpoint; it may not be an impossible task, but I doubt if it is even worth doing it that way.

The inner part is where things start to get interesting. This is essentially a virtual machine which emulates the way a Prolog interpreter behaves. It is the central processing unit of the gameplay logic, which runs itself by executing rules which are written in declarative syntax (i.e. horn clauses).

The code below is a rough outline of what this "virtual Prolog machine" might look like if it were implemented inside a C# application.

#$
public class VirtualPrologMachine
{
    private int time = 0;
    private const farthestLookbackTime = 1;

    private HashSet<Fact> facts = new HashSet<Fact>();
    private List<Rule> rules = new List<Rule>();

    private List<Fact> factsTemp = new List<Fact>();

    public void Init(HashSet<Fact> initialFacts, List<Rule> initialRules)
    {
        facts.Clear();
        rules.Clear();

        foreach (var fact in initialFacts)
            facts.Add(fact);
        foreach (var rule in initialRules)
            rules.Add(rule);
    }

    public void Tick()
    {
        // Repeatedly scan the rules and evaluate them until we are unable to discover any more facts.
        do
        {
            int numNewFactsDerived = 0;

            // Look at the individual rules.
            foreach (var rule in rules)
            {
                // For each rule, look at each one of its required conditions.
                foreach (var condition in rule.Conditions)
                {
                    // Look up the available facts and pattern-match each one of them with the given condition.
                    // Remember the matching sets of arguments (i.e. bindings).
                    foreach (var fact in facts)
                    {
                        ...
                    }
                    ...
                }

                // Derive new facts from sets of arguments (i.e. bindings) which satisfy ALL the conditions,
                // Add these new facts to 'factsTemp'.
                ...
            }
        } while (numNewFactsDerived > 0);

        // Add the new facts.
        foreach (var fact in factsTemp)
            facts.Add(fact);
        factsTemp.Clear();

        // Remove obsolete facts.
        foreach (var fact in facts)
        {
            if (fact.Time < time - farthestLookbackTime)
                factsTemp.Add(fact);
        }
        foreach (var fact in factsTemp)
            facts.Remove(fact);
        factsTemp.Clear();

        // Increment the current time step.
        time++;
    }
}

public class Relation<T> where T : RelationArg
{
    public string Name;
    public int TimeOffset = -99; // -99 if the relation is timeless
    public T[] Args;
    public bool Negate;
}

public class Fact : Relation<T> where T : Constant
{
    public int Time;
}
#$

The answer-finding procedure has not been fully specified here (They are left as: "..."), yet I believe that such details can be elaborated later on if necessary. Pieces of utility code which were introduced in {%a href="https://thingspool.net/morsels/page-15.html"%}Part 6{%/a%} will probably be of help here.

Aside from the problem of figuring out all the valid bindings and converting them to facts, I would say that the overall goal of the "VirtualPrologMachine" class above is to serve as the central gameplay engine which is capable of evaluating the given set of rules and deriving new facts out of them whenever the "Tick()" method gets invoked.

Each call of the "Tick()" method represents a clock cycle (i.e. game loop). Every time it runs, it goes through all the given rules, identifies all the relevant facts as well as their appropriate bindings, and instantiates new facts (if applicable) out of such bindings. And in the end, it removes all the obsolete facts (i.e. ones that are too old) and increments the time step by 1.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Performance Issues</b></h3>

The main problem is that the process of exhaustively finding all possible solutions (i.e. sets of bindings) to a Prolog query is so computationally expensive.

Each rule forces us to compare every one of its requisite conditions with every one of the applicable facts, which provides us with multiple alternative ways in which the condition's arguments could be bound. This means that the total number of pattern-matching steps involved in analyzing even a single rule can be quite colossal.

If the system were asked to process just a handful of rules based upon a modest number of given facts, it would have not been too much of an issue. But since a gameplay system usually involves an immeasurably huge number of facts and rules interacting with one other during every fraction of a second, we must start seriously considering the performance implication of the standard Prolog algorithm.

Fortunately, there are many ways in which a Prolog application could be optimized. One of the most obvious methods is to parallelize the means of rule evaluation. So, for example, if there are groups of rules in the system whose requisite relations (i.e. those on the right-hand side of the horn clause) do not depend on each other, we will be able to hand these groups over to separate threads and let them be handled concurrently. This way, we will be able to considerably reduce the amount of time being spent by the system to answer all the rules.

Another way, which may as well be employed jointly with the aforementioned solution, is to exploit some of the algorithmic shortcuts while analyzing the rules. This approach will require us to come up with slightly more advanced data structures, yet doing so will definitely be worthwhile.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Structural Shortcuts</b></h3>

You might have realized that one of the most significant sources of inefficiency in the code I have shown above is the way in which the facts are being stored. What I did was, I simply used a HaseSet (i.e. a hash table) to store all the available facts, without any means of organization whatsoever. Each time the system evaluates a relation, therefore, it is forced to go through all the entries of the set to be able to select the matching ones.

This is too wasteful, of course, and we should definitely introduce a bit of shortcuts to let the interpreter access the relevant entries more efficiently. For the sake of demonstration, I will begin with the simplest example.

Let's say that the Prolog system is given the following list of facts:

#$
FACTS:
    hot(actor1).
    dense(actor1).
    little(actor1).
    hot(actor2).
    dense(actor2).
#$

<f21>

These are all unary facts, and they can be imagined as "tags" (i.e. adjectives) which are being attached to actors for the purpose of describing what they are. The constant "actor1", for example, can be depicted as "hot and dense and little" because it is associated with 3 tags: "hot", "dense", and "little". The constant "actor2", on the other hand, will be depicted as "hot and dense but not necessarily little" because it is associated with only 2 tags: "hot" and "dense".

Storing these facts is very straightforward. All we need to do is create a separate HashSet for each of the tags, so as to enable the interpreter to quickly access facts of the desired types (e.g. Whenever it wants to access facts which begin with the keyword "hot", it only needs to look up the entries in a set called "hot" and nowhere else).

The following code will show you how the aforementioned facts are able to be mapped into their corresponding HashSet entries.

#$
public class Facts
{
    public HashSet<string> hot;
    public HashSet<string> dense;
    public HashSet<string> little;

    public void Init()
    {
        hot.Add("actor1");
        dense.Add("actor1");
        little.Add("actor1");
        hot.Add("actor2");
        dense.Add("actor2");
    }
    ...
}
#$

So, here is the rule of thumb. Whenever you have a tag you want to attach to actors, create a HashSet to store all the actors which possess this tag. That's it! That's all you have to do.

All right, here is something more advanced.

#$
FACTS:
    health(actor1, 6).
    health(actor2, 3).
    likes(actor1, actor2).
    hates(actor2, actor1).
#$

<f22>

These ones involve multiple arguments, and they are somewhat more complicated than mere tags. The first two are numerical attributes, and they describe the actors' quantitative states. "health(actor1, 6)", for instance, represents the fact that the current health of "actor1" is 6.

The remaining two are relationships between actors which could be described in terms of simple keywords. "likes(actor1, actor2)", for instance, represents the fact that "actor1" likes "actor2". This kind of relation is binary in nature, since an actor either "likes" or "does not like" the other actor; there is no in-between (i.e. grayscale) state, as far as the semantic structure of "likes(X, Y)" goes.

Such facts can be accessed quite efficiently as long as we represent them as dictionaries (aka "HashMaps"), which are internally just hash tables. Each key of the dictonary will be the actor which is the "main subject" of the relation, and the key's corresponding value will be whatever thing that the subject is associated with in the context of the relation. The "likes" relation, for example, could be constructed as a dictionary in which each key indicates the subject who likes somebody else, and each value indicates that "somebody else" who is being liked by the subject.

#$
public class Facts
{
    public Dictionary<string, int> health;
    public Dictionary<string, string> likes;
    public Dictionary<string, string> hates;

    public void Init()
    {
        health["actor1"] = 6;
        health["actor2"] = 3;
        likes["actor1"] = "actor2";
        hates["actor2"] = "actor1";
    }
    ...
}
#$

So yeah, the underlying idea is that we can simply use a dictionary (i.e. a bunch of key-value pairs) to store facts which describe relationships between things - that is, between the subjects (i.e. keys) and their associated objects (i.e. values).

Oh, but here's the catch. What if a subject is involved in multiple relationships of the same type? For example, we could imagine a situation where "actor1" happens to like not only "actor2", but also "actor3" and "actor4" (See the list of facts below).

#$
FACTS:
    likes(actor1, actor2).
    likes(actor1, actor3).
    likes(actor1, actor4).
#$

<f23>

This problem is not hard to resolve at all. All we need is a dictionary whose values are sets of actors instead of just actors. This way, it will be possible to allow each key to reference multiple actors at once.

#$
public class Facts
{
    public Dictionary<string, HashSet<string>> likes;

    public void Init()
    {
        likes["actor1"].Add("actor2");
        likes["actor1"].Add("actor3");
        likes["actor1"].Add("actor4");
    }
    ...
}
#$

Now, let me come up with relations which comprise more than two arguments. The following three facts (shown below) describe relationships between actors with their own numerical quantities. "attacks(actor1, actor2, 1)", for instance, implies that "actor1" is attacking "actor2" with the strength of 1.

#$
FACTS:
    attacks(actor1, actor2, 1).
    attacks(actor1, actor3, 5).
    attacks(actor2, actor1, 2).
#$

<f24>

In each of these facts, the first argument indicates the subject who is attacking somebody else, the second argument indicates the object (i.e. target) who is being attacked, and the third argument indicates the strength of the attack. This means that, from the viewpoint of a dictionary, the first argument should be used as the key and the other 2 arguments should be used as its corresponding value. For convenience, let us just put these 2 arguments in a tuple and treat it as the data with which the key is associated. If we do so, the resulting data structure will look like this:

#$
public class Facts
{
    public Dictionary<string, HashSet<(string, int)>> attacks;

    public void Init()
    {
        attacks["actor1"].Add(("actor2", 1));
        attacks["actor1"].Add(("actor3", 5));
        attacks["actor2"].Add(("actor1", 2));
    }
    ...
}
#$

<f25>

Everything is the same as before, except that the set of values now consist of tuples instead of just singletons.

The idea of treating one of the arguments as the key and the rest as the value is pretty versatile, and is able to be extended as much as we desire. The act of handing over a certain number of items to another actor, for example, can be written as:

#$
FACTS:
    gives(actor1, actor2, healthPotion, 5).
#$

<f26>

This is a fact with 4 arguments, where the first two refer to the donor and receiver of the items, and the rest two refer to the type and number of items given. So in this case, the fact says that "actor1" is giving 5 bottles of health potion to "actor2".

Such a kind of relation can be constructed as a dictionary in which the set of values have 3-element tuples in them instead of 2, for the purpose of representing the receiver, the type, and the number of the items given.

#$
public class Facts
{
    public Dictionary<string, HashSet<(string, string, int)>> gives;

    public void Init()
    {
        gives["actor1"].Add(("actor2", "healthPotion", 5));
    }
    ...
}
#$

If the relation had 5 arguments in total, this tuple would have been 4 in length. If the relation had 6 arguments in total, this tuple would have been 5 in length, and so on. We just have to consider one of the arguments as the key, and the rest as parts of the value to which the key corresponds.

There are, however, cases in which treating only one of the arguments as the key may not be appropriate. If there is a relationship between two equally important subjects, for instance, we won't necessarily favor the notion of putting only one of them as the key of the dictionary and the other one as part of the mapped value. Here is a quick example which demonstrates such a scenario:

#$
FACTS:
    distance(actor1, actor2, 10).
#$

<f27>

The fact shown above tells us that the distance between "actor1" and "actor2" is 10. Here, should we say that "actor1" is the subject of this relation? Or should we say that "actor2" is the subject?

An honest answer would be that neither of them accurately reflects the symmetric nature of a distance. Both of the two given actors are of equal agency and, unlike in the previous examples, the "distance" relation does not suggest in any way that one of the actors is actively "doing something" against the other actor. In other words, "distance" is not a verb in which there is a clear distinction between the subject and the object.

In this case, therefore, it makes a lot more sense to consider both of the actors as the subject of the relation. It means that each key in the dictionary of "distance" relationships should be defined as the pair of actors involved.

#$
public class Facts
{
    public Dictionary<(string, string), float> distance;

    public void Init()
    {
        distance[("actor1", "actor2")] = 10f;
    }
    ...
}
#$

In general, though, choosing which arguments to use as the key of the dictionary can be quite tricky. It might appear as straightforward from a purely declarative standpoint, yet the problem is that we are also concerned about computational efficiency here.

When searching for facts of our interest, we want the lookup process to be as quick as possible. And in order to achieve this goal, we must try to minimize the number of dictionary lookups that the interpreter is required to perform when responding to a query.

In the next article, I will be talking about this aspect of database design, and how taking care of it will help us greatly improve the performance of the underlying system.

(Will be continued in Part 16)