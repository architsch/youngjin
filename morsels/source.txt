:d:A list of game design concepts.
:k:Game Design, Game Mechanics, Game Narratives, Technical Game Design, Game AI, Gameplay Systems, Game Development, Mechanical Narratives, Gameplay Algorithms, Gameplay Semantics, Game Logic
:l:2024-07-26

[Game Design Concepts] June 27, 2024 - July 26, 2024

This is a collection of game design concepts.

@@<hr>
@@<div class="l_spacer"></div>
<001>
@@<h3><b>1. Mechanical Narratives</b></h3>

A game is usually a combination of two factors - mechanics and narratives.

Mechanics represent the systematic aspects of the game, such as physics, AI, crafting rules, progression curves, and others which rely on the knowledge of math/engineering.

Narratives represent the volitional aspects of the game, such as lores, stories, personalities, goals, and others which rely on the knowledge of arts/humanities.

A problem we often experience is that it is too tricky to fit these two together in one place. Many ambiguous cases are prone to arise, such as:

(1) Having a cool story (narrative) for a video game, but not knowing how to turn it into gameplay (mechanic).
(2) Knowing how to implement a clever enemy AI (mechanic), but not knowing how to design an appropriate enemy character for it (narrative).
(3) Having an interesting NPC with a unique personality (narrative), but not knowing which in-game role it ought to play (mechanic).

A solution is to start designing the game with building blocks which can both be considered mechanics and narratives at the same time (aka "mechanical narratives").

If we start by laying out the game's narratives first, it will be difficult to devise mechanics which are compatible with the given narratives. If we start by laying out the game's mechanics first, on the other hand, it will be difficult to devise narratives which are compatible with the given mechanics.

Such a dilemma can be bypassed by simply collecting a number of "mechanical narratives" and assembling them together.

@@<hr>
@@<div class="l_spacer"></div>
<002>
@@<h3><b>2. Sensors, Filters, and Motors</b></h3>

In general, a gameplay agent can be constructed by assembling 3 types of modules - sensors, filters, and motors.

Sensors collect data from the environment, filters process the data (for analysis), and motors trigger the agent to take actions based upon the filtered data.

Here is an example. Imagine that there is an anti-aircraft gun whose role is to shoot down enemy airplanes in range. We can model this gun as a composition of:

(1) A sensor (i.e. radar) which detects anything within the specified range,
(2) A filter (i.e. computing module) which looks up the database to see if the detected object is an enemy airplane, and
(3) A motor (i.e. the gun itself) which fires bullets at any object which is identified as an enemy airplane.

The gun detects an aircraft, checks to see if it is an enemy, shoots at it if so, and then detects another aircraft, checks to see if it is an enemy, shoots at it if so, and then detects another aircraft... and so on.

This is just a simple example. For more complex behaviors, you may as well equip it with multiple sensors (e.g. radar, camera, antenna), multiple filters (e.g. distance filter, look-angle filter), multiple motors (e.g. gun, horizontal rotor, vertical rotor, ammunition reloader), etc.

Such a multitude of modules can then communicate with one another by means of series connections, parallel connections, or both.

@@<hr>
@@<div class="l_spacer"></div>
<003>
@@<h3><b>3. Psychological Force Field</b></h3>

Psychological force field is a useful concept in game design.

We typically imagine each individual game character as an observer, equipped with its own independent mind. It continuously scans the environment and makes decisions off of it.

Each observer carries its own psychological force field which permeates the entirety of the game world. Every entity other than the observer itself essentially "warps" the field nearby, modifying the magnitudes and directions of the force vectors which guide the observer's movement.

A repulsive entity adds outward forces to the field, whereas an attractive entity adds inward forces to the field. This makes the observer move away from repulsive entities and closer to attractive entities.

Whether an entity is repulsive or attractive is determined by the observer's personal preference.

The force that is to be applied to the observer can be computed by the function "PsyForce(id, X, Y)", where "id" is the unique ID of the observer and (X, Y) is the observer's current position. This function returns the psychological force vector which gets added to the observer's net force.

A real life example of psychological force field is Feng Shui, where architectural patterns are believed to shape the field in which the residents of the house reside, thereby influencing the way they behave.

@@<hr>
@@<div class="l_spacer"></div>
<004>
@@<h3><b>4. Parallel-Attention Timeline</b></h3>

A parallel-attention timeline is a pretty useful tool to use in gameplay AI.

It starts from a simple analogy.

When I am stirring a pot of spaghetti while also heating a plate of frozen garlic bread in the oven, you can say that I must be multitasking.

However, it should be noted that I am paying way more attention to the pot of spaghetti than to the oven because the latter basically takes care of itself and only demands occasional supervision.

When designing a game, it is convenient to assume that each game character carries its own schedule in its mind, filled with tasks which start and end at their own designated points in time.

It is sometimes even more desirable, though, to model a schedule not as a one-dimensional queue of tasks, but as a two-dimensional grid in which each column represents a time slot and each row represents what could be referred to as "attention priority".

A character which follows this two-dimensional schedule always runs the task which occupies the highest row (i.e. highest attention priority) among all the tasks which occupy the current time slot.

Whenever an "attention trigger" (i.e. any object which demands attention) tries to register a new task to the schedule, the schedule will either ignore this new task if it happens to collide with an existing one, or proceed to register it if not.

Each task possesses its own intrinsic attention priority (i.e. row) which cannot be modified.

@@<hr>
@@<div class="l_spacer"></div>
<005>
@@<h3><b>5. Partial Movement Constraints</b></h3>

Both too much freedom and too little freedom are undesirable in gameplay.

Suppose that there are enemy characters whom the player must defeat in order to finish the level.

If the enemies are able to move in any direction, it will be a bit too bland because it reduces the functional significance of the level's peculiar spatial configuration (e.g. If you are being chased by an enemy who can only move horizontally, you can take refuge in a vertical space).

If the enemies are completely immobile, on the other hand, it will be pretty bland as well because it makes gameplay less dynamic.

A nice middle ground which leverages the benefits of both is to confine each enemy's locomotive freedom to a set of simple pathways, as though it is a train following a railway.

This mixed approach has 3 main advantages:

(1) It makes it easy to diversify enemy behaviors and introduce a wide variety of in-game strategies.
(2) Its pathfinding algorithm is easier to implement and way less computationally expensive than, say, the A-Star algorithm.
(3) It prevents extreme gameplay scenarios, such as letting the player be completely surrounded by a truckload of enemies because they always keep chasing the player without a pause. By limiting each enemy's maximum range of movement, we can spread out the distribution of enemies throughout the level and prevent them from concentrating too much in one place.

@@<hr>
@@<div class="l_spacer"></div>
<022>
@@<h3><b>6. Emotional State Machine</b></h3>

When it comes to designing gameplay systems, it is often useful to model each game character as a state machine (i.e. an object with a set of possible states). There are more advanced models indeed, but state machines usually suffice for fairly simple purposes.

Such a state machine typically comprises the character's action states, such as "idle", "attacking", "stunned", "wandering", and so on. However, this representation does not reflect the character's inner psychological states such as emotions.

In order to give depth to the game's narratives, we must let game characters have their own emotions. And this can be done by designing each character as an emotional state machine.

An emotional state machine resides in a 3D space called "emotion space", whose 3 spatial axes represent the character's happiness, excitement, and confidence.

The characters's emotional state is a point in the emotion space, and a change in the emotion is the same thing as a displacement of the point from one location to another.

When happiness, excitement, and confidence are all low, the character is depressed and timid. When happiness, excitement, and confidence are all high, the character is fascinated and arrogant. When happiness is high but excitement and confidence are low, the character is quietly happy in its selfless devotion. And when happiness and excitement are low but confidence is high, the character is in the mood of Squidward.

You can change the emotion's current state by applying a "psychological force" to it. The way you do it is to put the emotion's position under a psychological force field.

@@<hr>
@@<div class="l_spacer"></div>
<023>
@@<h3><b>7. Deities of the Game World</b></h3>

Designing a game is essentially the same thing as designing your own virtual world.

A game is a world which is governed by its own set of natural laws. And the manner in which these laws are being enforced largely depends on the manner in which the developer has initially configured the world.

Game worlds come in different types, each of which pertains to a particular theistic worldview.

Inside a monotheistic game world, a single control module regulates the feedback loops of the game characters.

Inside a polytheistic game world, multiple control modules regulate the feedback loops of the game characters.

Inside a pantheistic game world, the game characters' feedback loops are not being regulated by any external module; the characters themselves are their own regulators.

One of the main advantages of using either a monotheistic or polytheistic system is that it allows the gamemaster to occasionally override the game's default laws by means of admin privilege. In computer science, it is called "miracle".

@@<hr>
@@<div class="l_spacer"></div>
<025>
@@<h3><b>8. Modular Behavior Tree</b></h3>

Behavior trees are useful in game AI. You can implement a wide range of complex decision-making agents based upon them.

Sometimes, however, we feel overwhelmed by the urge to make a behavior tree unreasonably enormous when there are way too many types of items with which the agent is supposed to interact.

For example, imagine that a game character has a behavior tree which involves a task called "eat". In order to tell the character exactly what to do when it runs this task, the "eat" node must be able to handle all possible ways of eating, such as how to eat a salmon, how to eat a donut, how to eat a taco, and so on.

Thus, it is oftentimes convenient to make behavior trees modular, so that a tree of tasks that is specific to the object of interaction can simply reside within the object, temporarily stick itself to the character's "eat" task during the interaction, and then depart once the interaction is over.

@@<hr>
@@<div class="l_spacer"></div>
<026>
@@<h3><b>9. Brand-Building</b></h3>

One thing I learned while developing and publishing indie games, was that a game needs to have its own brand in order to be truly successful.

Creating a brand is such a monumental challenge. One cannot just put a bunch of buzzwords together and expect it to leave a lasting impact upon the heart of the audience. In my opinion, a great brand requires 3 major elements: Purpose, Logic, and Mystery.

A brand needs a purpose because otherwise the customer won't be encouraged to partake in its narrative. Without a purpose, there is no need to support the brand's growth by any means.

A brand cannot flourish without any logic either. It must have a logically sound solution to fulfill the said purpose. Our reason must be able to grasp it, for otherwise everybody will be left confounded.

However, a brand also ought to preserve a decent amount of mystery in it. Even a perfectly logical solution, guaranteed to solve the most urgent problem in the most quintessential way, won't attract the audience if they are not given their own roles to participate in a journey to freely explore the unknown and discover hidden treasures.

In general, I believe that the most appealing brand must have its own purpose, logic, and mystery in equal measures. This corresponds to the center point of the circular diagram I have shown here (denoted by the Sun).

@@<hr>
@@<div class="l_spacer"></div>
<043>
@@<h3><b>10. Image as a Game Map</b></h3>

Using an image to generate a game map is sometimes a good idea.

Suppose that your game comprises one vast terrain, modeled as a 2D voxel grid.

All you need to do is create an image and simply assume that its pixels represent to the terrain's voxels.

Each pixel's brightness may indicate the terrain's height. This can be graphically implemented by rendering the terrain as a grid of quads and letting the vertex shader set the y-coordinate of each vertex based on the corresponding pixel's brightness.

Each pixel's saturation may indicate the density of props, where low saturation means low probability of spawning a prop at the pixel's location, and high saturation means high probability of spawning a prop at the pixel's location.

Lastly, each pixel's hue may indicate the terrain's biome type, where "green" means forest/meadow, "orange" means village, "magenta" means palace, and so on.

Additional data-embedding is possible, too, as long as your image is transparent. The opacity of each pixel can be used to specify some other physical properties of the terrain, such as temperature, humidity, etc. Or it may be used for metadata, in which the game's trigger zones, waypoints, and spawn hotspots can be encoded.

With this image-based map generation system, you can even manipulate the terrain while playing the game because it is just a matter of image processing (run by fragment shaders). The overall erosion of the terrain is the same thing as blurring the image, and hitting the terrain with a meteorite is the same thing as painting the impact zone with a semi-transparent black brush.







:d:A mathematical model of our own thoughts, feelings, and the sense of curiosity.
:k:Curiosity, Motivation, Motive Force, Curiosity Force, Conceptual Space, Physical Space, Katarina Gyllenbäck, Feature Space, Idealism, Ontology, Epistemology
:l:2024-07-27

[Model of the Mind] June 28, 2024 - July 27, 2024

This is a collection of mathematical concepts designed to express the nature of human mind in a rational manner.

The ideas shown below are inspired by Katarina Gyllenbäck's articles. For more information, visit <a href="https://thingspool.net/read-rec/page-2.html">Here</a>.

@@<hr>
@@<div class="l_spacer"></div>
<006>
@@<h3><b>1. Physical Space and Conceptual Space</b></h3>

There are two different spaces in our universe - physical space and conceptual space.

Physical space is the space we usually refer to whenever we are employing the word "space". It consists of spatial and temporal axes (e.g. X, Y, Z, and Time), and serves as a frame of reference when it comes to describing physical entities such as rigid bodies.

Conceptual space, on the other hand, is the space of qualitative features. For example, a color is a position in the RGB color space, where the axes (R, G, B) represent the intensity levels of the three primary color components (i.e. Red, Green, Blue). The RGB color space is one of many types of conceptual spaces we can imagine.

Each object has its own position in physical space as well as a position in conceptual space. The former tells us where the object is, and the latter tells us what the object looks like.

@@<hr>
@@<div class="l_spacer"></div>
<007>
@@<h3><b>2. Particulars and Universals</b></h3>

There are two types of objects - particulars and universals.

A particular is an object which exists at a specific point in space and time. All tangible objects, such as a table we can touch, a sandwich we can eat, a cup we can hold, and countless other "real" things, can be classified as particulars.

A universal is different from a particular in the sense that we cannot directly perceive it, since it exists only in conceptual space and not in physical space. It is a pure idea which resides only in the spiritual realm; it does not belong to anywhere in our material world.

In computer science, a class is a universal. It is purely spiritual because it lives in the static memory, which is fixed and therefore "eternal" in the sense that it spans the entirety of the application's runtime.

An instance of a class, which is dynamically allocated in memory, is a particular. It is a mortal being which gets created at some point in time and gets destroyed at some other point in time. It is never eternal because it does not span the entirety of the application's runtime.

@@<hr>
@@<div class="l_spacer"></div>
<008>
@@<h3><b>3. Contiguity and Resemblance</b></h3>

Since an object exists in two different spaces (namely, "physical space" and "conceptual space"), a distance between a pair of objects can possess either one of two meanings depending on the type of space in which it is measured.

Physical proximity implies contiguity. When two things are very close to each other in physical space, we say that they are contiguous because looking at one of them lets us look at the other much more easily.

Conceptual proximity implies resemblance. When two things are very close to each other in conceptual space, we say that they resemble each other because thinking of one of them lets us think of the other much more easily.

Proximity can be measured by taking the reciprocal of the distance. Less distance means more proximity, and more distance means less proximity.

@@<hr>
@@<div class="l_spacer"></div>
<009>
@@<h3><b>4. Surprise</b></h3>

How to measure the amount of surprise between two objects?

Each object has two distinct positions - one in physical space, and the other one in conceptual space. Therefore, we are able to compute two separate distances between a pair of objects - physical distance and conceptual distance.

The amount of surprise between two objects is proportional to their conceptual distance because the more qualitatively different they are, the more surprised they will be when they see each other.

On the other hand, the amount of surprise between two objects is inversely proportional to their physical distance because the closer they are, the more vividly they will observe each other's qualitative differences.

Thus, we can measure the amount of surprise by measuring the conceptual distance and then dividing it by the physical distance.

@@<hr>
@@<div class="l_spacer"></div>
<010>
@@<h3><b>5. Curiosity Force</b></h3>

Curiosity often drives us to move from familiar places to unfamiliar places. It is possible to devise a mathematical formula which tells us exactly how the force of curiosity will initiate such a movement.

Suppose that there is an observer somewhere in physical space. We can first compute the observer's "surprise vectors", each of which represents the amount of surprise that the observer feels in regard to an external object.

If you take the sum of all the surprise vectors which involve the observer and multiply the resulting "net surprise vector" by the amount of the observer's curiosity, you will obtain the "curiosity force vector" which is responsible for pushing the observer to venture into the unknown.

@@<hr>
@@<div class="l_spacer"></div>
<016>
@@<h3><b>6. How to Compute Curiosity</b></h3>

Can we represent curiosity as a numerical quantity?

The amount of curiosity reaches its peak value when the person is feeling a sense of surprise which is neither too intense nor too dim.

If you are surrounded by an environment which is not surprising at all, you will lose curiosity due to boredom.

If you are surrounded by an environment which is too overwhelmingly surprising, you will be anxious. As a result, you will suppress your curiosity in order to protect yourself from potential dangers.

It is only when you are surrounded by a moderately surprising environment (i.e. neither too familiar nor too unfamiliar) that you will be able to feel a vivid sense of curiosity.

A halfway mixture between familiar and unfamiliar elements creates a "Goldilocks zone of motivation" which will encourage you to uncover partially hidden secrets.

If everything is already uncovered, there will be no secret to uncover and so you won't feel the necessity to start an adventure. If everything is veiled in darkness, you will feel clueless and thus not even dare to start an adventure.

@@<hr>
@@<div class="l_spacer"></div>
<046>
@@<h3><b>7. Uniformity</b></h3>

It is possible to measure the amount of uniformity between two objects.

In order for a pair of objects to comprise one uniform body, they must satisfy two conditions.

First, they must be physically close to each other. If they are too far apart, we will clearly be able to see that there is a significant spatial gap between them, showing that they are discontinuous and thus not uniform.

Secondly, they must resemble each other (i.e. similar in characteristics). If they look too drastically different, we will be able to tell that their mutual contrast is too huge to ensure that they are part of one smooth, uniform body.

Therefore, the amount of uniformity can be computed by taking the inverse of the product between their physical and conceptual distances.

@@<hr>
@@<div class="l_spacer"></div>
<047>
@@<h3><b>8. Force of Adaptation</b></h3>

If you measure the amount of uniformity between the observer and a nearby object, you will obtain a number which tells you how familiar the observer is with the object.

And if you represent this number as the magnitude of a vector which starts at the observer's conceptual location and points itself to the object's conceptual location, you will get a vector which can be referred to as a "uniformity vector".

Take the sum of all uniformity vectors which originate from the observer, and you will acquire the net uniformity vector. This vector informs us the strength and direction of the surrounding environment's familiarity with respect to the observer.

Scale this net uniformity vector by the observer's adaptivity (which is a scalar value) and you will obtain the force vector which is currently pushing the observer's viewpoint in conceptual space. This force gradually "adapts" the observer to the surroundings, making them become more and more familiar as time passes by.

@@<hr>
@@<div class="l_spacer"></div>
<048>
@@<h3><b>9. Dynamics of Exploration</b></h3>

The force of curiosity pushes the observer's body in physical space, toward areas which are unfamiliar to him.

Meanwhile, the force of adaptation pushes the observer's viewpoint in conceptual space, toward areas which are as familiar to him as possible. This lets him quickly adapt himself to his surroundings.

These two forces work together in parallel, continuously propelling both the observer's body (location in physical space) and viewpoint (location in conceptual space) in the direction of spontaneous exploration.

The back-and-forth interaction between these two forces creates a feedback system. The force of curiosity puts the observer in unfamiliar places, which in turn compels the observer to adapt his viewpoint to the unfamiliar. Once his surroundings become too familiar to him, his curiosity then drives him to search for other unfamiliar territories to explore.







:d:A mathematical interpretation of David Hume's philosophy.
:k:David Hume, Empiricism, Empirical Philosophy, Metaphysics, Epistemology, Ontology, Discrete Math, Philosophy Of Mind, Computational Psychology
:l:2024-07-31

[Mathematical Interpretation of Hume's Philosophy] July 2, 2024 - July 31, 2024

This is a mathematical interpretation of David Hume's philosophy. It is mostly based upon my personal analysis, so please take it with a grain of salt.

I drew most of my inspirations from his book, "An Enquiry Concerning Human Understanding". For more information, visit <a href="https://thingspool.net/read-rec/page-6.html">Here</a>.

@@<hr>
@@<div class="l_spacer"></div>
<011>
@@<h3><b>1. Introduction</b></h3>

Hume's empiricist worldview begins with a hierarchy of concepts.

There are two major types of components in his domain of knowledge. One is "perceptions", and the other one is "objects of reason". Perceptions are the atoms of the mind, whereas objects of reason are molecules which can be formed by bonding those atoms together.

A perception is any "thought" we can conceive in our minds. It belongs to either one of the two categories - impressions and ideas.

An impression is a direct stimulus received by our sense organs. Things we directly see, hear, smell, taste, and feel are all impressions.

In contrast, an idea is an afterthought on the impressions we received. For example, what we see is an impression, but the recollection of what we just saw is an idea. Impressions are vivid, while ideas are dim.

Objects of reason can be subdivided into two categories - "relations of ideas" and "matters of fact".

A relation of ideas is a result of pure logic, such as a mathematical theorem which manages to prove itself based upon a set of ideas only, without relying on the presence of external stimuli. A matter of fact, on the other hand, requires a considerable amount of empirical data to validate itself (like the law of gravitation).

@@<hr>
@@<div class="l_spacer"></div>
<012>
@@<h3><b>2. Impressions and Ideas</b></h3>

Hume's definition of "impressions" and "ideas" provides us with a rudimentary ground of logic, upon which we can formulate a model of how we sense and recall our own thoughts.

Impressions are what we typically refer to as "sensory stimuli". These are the most immediate and piercing kind of perceptions which we feel with the utmost degree of intensity.

Ideas, on the other hand, are byproducts of impressions. They linger in our minds like ghosts, which occasionally touch our feelings but to a much lesser degree. Unlike impressions which are momentary, ideas stay in the person's memory and get recalled on demand.

In a way, therefore, ideas are Lego bricks which can fit one another nicely in our minds, whereas impressions are just raw plastic ingredients which are yet to be molded into such bricks.

@@<hr>
@@<div class="l_spacer"></div>
<013>
@@<h3><b>3. Generation of Ideas</b></h3>

According to Hume's philosophy, each impression generates its corresponding idea when it enters our domain of cognition.

However, he also mentions that the relation between impressions and their ideas is not necessarily one-to-one. There may as well be cases in which a wide spectrum of ideas manage to emerge from a relatively few impressions.

An impression of "light blue" and an impression of "dark blue", for example, may allow us to imagine an intermediate shade of blue (by mixing the qualities of light blue and dark blue) and remember it as a distinct idea. This lets us picture the full spectrum of blue without having to directly sense every single one of its variants via external stimuli.

@@<hr>
@@<div class="l_spacer"></div>
<014>
@@<h3><b>4. Relations between Ideas</b></h3>

We assign meaning to our ideas by establishing relations between them. In Hume's model of the human mind, there are three fundamental types of such relations - resemblance, contiguity, and causality (aka "cause and effect").

Resemblance tells us that two ideas are qualitatively similar to each other (such as two slightly different shades of blue). This is something we can immediately tell from our perceptions.

Contiguity tells us how close two ideas are to each other in spacetime. This, too, is something we can immediately tell from our perceptions.

Causality, however, is not something we can identify in such a straightforward manner. We must derive it from the other two types of relations (i.e. resemblance and contiguity).

@@<hr>
@@<div class="l_spacer"></div>
<015>
@@<h3><b>5. Causal Relations</b></h3>

An idea alone does not have the word "cause" or "effect" written on its face, and the only way for us to prove that an idea "causes" another idea is that one of them frequently precedes (or succeeds) the other in spacetime.

Also, since it is almost impossible for us to reproduce the same exact idea over and over in our material world (which is plagued with all sorts of random noises such as acoustic waves, electromagnetic disturbances, thermal noise, etc), we must rely on our belief that similar causes are likely to produce similar effects.

This leads us to the conclusion that, if a set of mutually resembling ideas are contiguous with another set of mutually resembling ideas, we can say that these two sets are causally related to each other.

@@<hr>
@@<div class="l_spacer"></div>
<017>
@@<h3><b>6. Facts</b></h3>

What is a "fact", really?

There are many ideas in our domain of reason, yet the boundary between ones that are supposed to be "facts" and ones that are mere personal feelings often looks a bit fuzzy.

Hume's philosophy tells us that an idea can be considered a "fact" if it is caused by a sufficiently large number of causes (e.g. preceded by a sufficiently long chain of causal relations).

Each cause works as a proof of the idea's truthfulness. The more causes there are, the more confidently we are able to say that the idea is true. If it is so true that its truthfulness is hardly questionable, we say that the idea is a "fact".

People who know how a blockchain works (such as Bitcoin or Ethereum) will easily come to the realization that ideas are reminiscent of blockchain transactions, and that a "fact" is basically a transaction which has been mined (verified) and is given credit by a long chain of preceding blocks.

@@<hr>
@@<div class="l_spacer"></div>
<027>
@@<h3><b>7. Simple and Complex Ideas</b></h3>

In "A Treatise of Human Nature", Hume makes a clear distinction between simple and complex ideas.

Based upon his rejection of the infinite divisibility of our sense-data, he says that "simple ideas" are ideas which cannot be further divided into its component parts, meaning that they are the "atoms" of our mind.

Examples of simple ideas include the primary color components (e.g. red, green, and blue), musical notes, and other irreducible units of sensation.

"Complex ideas", on the other hand, are groups of simple ideas. Each complex idea is a product of synthesis among two or more simple ideas. It is also possible to group complex ideas to form even more complex ideas.

A simple impression (i.e. external stimulus) gives birth to a simple idea. A multitude of simple ideas, then, give birth to complex ideas based on the way in which they are related to each other.

@@<hr>
@@<div class="l_spacer"></div>
<028>
@@<h3><b>8. Abstraction and Combination</b></h3>

A group of simple ideas are able to produce a complex idea. A group of complex ideas, too, are able to produce yet another complex idea which is even more complex than the preceding ones.

In general, therefore, we can say that a group of ideas with appropriate relations, whether they are simple or complex, are capable of generating a complex idea whose level of complexity is slightly higher than them.

There are two ways in which a complex idea may emerge - abstraction and combination.

When you see a group of slightly different shades of blue, you will recognize that they closely resemble each other. From this, you can conclude that they all belong to a class of objects called "blue". This is an example of abstraction.

When you see a lump of various colors, on the other hand, you will recognize that the individual colored spots do not necessarily resemble each other but are nevertheless very closely packed together in physical space. From this, you can conclude that they all belong to the same object. This is an example of combination.

@@<hr>
@@<div class="l_spacer"></div>
<029>
@@<h3><b>9. Relations between Complex Ideas</b></h3>

There are two primary types of relations between ideas - resemblance and contiguity. Resemblance indicates conceptual proximity, and contiguity indicates physical proximity.

Just like resemblance and contiguity can connect simple ideas, they are able to connect complex ideas as well.

An object is a complex idea which is based off of a set of contiguous ideas. When two objects have sufficiently many pairs of resembling ideas between them, they resemble each other.

A class is a complex idea which is based off of a set of resembling ideas. When two classes have sufficiently many pairs of contiguous ideas between them, they are contiguous to each other.

A contiguity between two classes may also be referred to as "causality" (i.e. One of them is either the "cause" or "effect" of the other).

@@<hr>
@@<div class="l_spacer"></div>
<030>
@@<h3><b>10. Data Structure of an Idea</b></h3>

According to Hume's argument in "A Treatise of Human Nature", every idea (or impression) must possess its own quality and quantity.

An idea's quality denotes the category of sensation to which it belongs, such as "brightness", "musical pitch", or "temperature".

An idea's quantity denotes its quality's intensity level. For instance, if there is an idea whose quality is "temperature" and whose quantity is "30", we may consider this idea as a sensation of warmth which is 30 degrees in temperature.

Hume says that an impression is basically the same thing as an idea (i.e. It has its own quality and quantity), except that it is much higher in "force and vivacity".

Therefore, I personally find that it is much more convenient to consider an impression as an idea whose level of vivacity is sufficiently high.

When expressed in the language of computer science, both impressions and ideas are mere instances of the same data structure called "Idea", which contains 3 integers - Quality, Quantity, and Vivacity.

@@<hr>
@@<div class="l_spacer"></div>
<031>
@@<h3><b>11. Metaphor</b></h3>

Metaphors are everywhere. They appear in poetry, novels, songs, and many other forms of media. However, they are often accused of being irrational.

Hume's philosophy suggests otherwise. It is possible to define a metaphor on a rational basis.

An idea has a location in conceptual space, which is composed of two dimensions called "quality" and "quantity". Quality indicates the category of sensation (e.g. brightness, loudness, temperature, etc), and quantity indicates its level of intensity.

We say that there is a resemblance between two ideas when they are close to each other in conceptual space. There are two types of resemblances: (1) Resemblance in quality, and (2) Resemblance in quantity.

Coldness and hotness do not resemble each other quantitatively, since their intensity levels (i.e. temperature) differ significantly. However, they resemble each other qualitatively because they both belong to the same category called "temperature".

On the contrary, red and hotness do not resemble each other qualitatively because they belong to two drastically different categories of sensation. However, they resemble each other quantitatively because the high emotional intensity of red is similar in magnitude to the high temperature of hotness. This is what we call "a metaphor".

@@<hr>
@@<div class="l_spacer"></div>
<032>
@@<h3><b>12. Unity between Two Positions</b></h3>

An idea must have its own quality and quantity. However, we ought to be aware that it must also have its own physical location in order for the mind to conceive it.

For example, when you are imagining a colored point, you cannot do it without locating it somewhere inside your imaginary field of vision.

Hume suggests that, in order for an idea to "exist", we must be able to perceive it either through external senses or our own imagination. Therefore, an idea is required to have a pair of positions - one in conceptual space, and the other one in physical space.

It may theoretically be insisted that it is also feasible to formulate "pure ideas" which belong to either physical space or conceptual space but not both. Such constructs, however, are not directly sensible and thus do not belong to the domain of cognition.

@@<hr>
@@<div class="l_spacer"></div>
<033>
@@<h3><b>13. Position of a Complex Idea</b></h3>

How to compute the position of an idea?

The position of a simple (atomic) idea does not have to be computed. It is simply given to our faculty of senses the very moment it is perceived.

The position of a complex idea, on the other hand, must be computed based upon those of its component ideas.

An object in physical space appears to be a single point when viewed from a sufficiently long distance. The physical position of such a point is the center of mass of the object's components in physical space.

Meanwhile, the object's individual color spots "average out" when they are condensed into a single point. This means that its conceptual position is the center of mass of the object's components in conceptual space.

The "mass" of an idea is its vivacity.

@@<hr>
@@<div class="l_spacer"></div>
<034>
@@<h3><b>14. Word and Symbol</b></h3>

Whenever we communicate, we use words and symbols to reference our ideas.

The difference between a word and a symbol can be found in the two fundamental relations between ideas - contiguity (i.e. proximity in physical space) and resemblance (i.e. proximity in conceptual space).

When you open up a children's book intended to teach basic English words, you will see that there are lots of images with words next to them. For example, if there is an image of fire, the book will also put the word "fire" right next to it in order to teach the child that the word "fire" is associated with the appearance of fire.

Here, the word "fire" and the appearance of fire do not visually resemble each other, but the child nevertheless learns that the former indicates the latter because these two things have been displayed contiguously in physical space (i.e. page of the book).

What about a symbol? Here is an example. An airplane's safety manual typically uses an icon of fire (aka pictogram) to reference real fire.

In this case, the icon is a symbol of fire, not because we have necessarily seen this icon appearing right next to real fire in physical space, but because we know that these two things visually resemble each other.

Therefore, a word is an idea which references another idea by means of proximity in physical space, whereas a symbol is an idea which references another idea by means of proximity in conceptual space.

@@<hr>
@@<div class="l_spacer"></div>
<035>
@@<h3><b>15. Rate of Change</b></h3>

When there is a moving car, how do we measure its speed?

Suppose that we have two snapshots available, one of them showing the car's position at one point in time, and the other one showing the car's position at another point in time.

Let us refer to the first snapshot's position and time as (p1, t1), and the second snapshot's position and time as (p2, t2). Since p1 and t1 appear together in the same snapshot, we know that they are contiguous. And since p2 and t2 appear together in the same snapshot, we know that they, too, are contiguous. Furthermore, since the two snapshots are juxtaposed right next to each other, they are contiguous as well.

And since they (p1, t1, p2, t2) all make up a single body of contiguities, we can tell that they all belong to the same context.

t1 and t2, although they are not physically nearby, belong to the same "quality" in conceptual space (because they are both time values). From this coincidence, we are able to tell that their quantities are comparable. The result of their comparison is the change in time (Δt = t2 - t1).

Similarly, p1 and p2 belong to the same "quality" in conceptual space (because they are both position values), so we are able to tell that their quantities are comparable as well. The result of their comparison is the change in position (Δp = p2 - p1).

The car's speed according to the two snapshots, then, is the ratio between Δt and Δp (i.e. ratio between the lengths of the vertical line segments in conceptual space which are associated with the two snapshots).

@@<hr>
@@<div class="l_spacer"></div>
<036>
@@<h3><b>16. Cause and Effect</b></h3>

Ideas often represent events, and we know that the human mind is prone to associate events with one another in terms of cause and effect (i.e. causality).

Hume says that, by making a sufficient number of observations, we are able to notice a "constant conjuction" between two classes of objects. Hence, he explains that this "constant conjuction" is the data from which we draw the notion of causality.

In order to decide which event is the cause (or effect) of the other, however, we should make an additional analysis. It is the concept of "precedence" to which we ought to pay attention, since it is what gives a direction to the causal relation.

If there is a relation of causality between X and Y, we say that X must be the cause of Y if X precedes Y in time, and vice versa.

This endows the chain of events with a fixed direction of progress, flowing from the past to the future.

@@<hr>
@@<div class="l_spacer"></div>
<037>
@@<h3><b>17. Belief</b></h3>

It is possible to compute the amount of belief in an idea.

Our minds are populated by various ideas. Some of them are considered fictitious, while others are considered real. We make such a distinction based upon the amount of belief in each idea.

Imagine that an idea is preceded by a chain of causes (i.e. causal relations). The longer and more vivid the chain is, the more we are convinced that the idea is "real". And the shorter and less vivid the chain is, the more we are convinced that the idea is "fake".

Thus, the total amount of belief in an idea is the sum of vivacities of its preceding ideas, plus its own vivacity.

An impression (i.e. external stimulus) is "real" because, although it is not preceded by a chain of causes, its own vivacity is so sufficiently high that it easily conjures up a strong sense of belief.

@@<hr>
@@<div class="l_spacer"></div>
<038>
@@<h3><b>18. Conditional Probability</b></h3>

When a cause is given, how do we measure the probability of occurrence of each of its effects?

Our minds are filled with ideas, and ideas usually represent events. Our belief in the occurrence of an event possesses its own numerical quantity, which can be computed by the "Belief(X)" function where X is the event of interest.

Given a cause, we say that the probability of occurrence of one of its potential effects is the proportion of the belief in the given effect with respect to the sum of the beliefs in all the potential effects.

The more frequently we observe an event, its vivacity increases. And the less frequently we observe an event, its vivacity decreases.

Since the amount of belief in an event is the sum of the vivacities of its history, we can say that more observation yields higher probability and less observation yields lower probability.

@@<hr>
@@<div class="l_spacer"></div>
<039>
@@<h3><b>19. Attention</b></h3>

A person's attention is a pointer which points to an idea.

Ideas, which fill up the mind's mental space, stay inactive as long as they are being neglected. It is because their vivacity levels are zero by default.

When an external stimulus enters the person's sensory organ, an impression gets created. It sticks itself to the corresponding idea and breathes vivacity into its mouth, thereby making it alive.

At the same time, the impression attracts the mind's attenion and induces it to point to the idea. The impression soon dies out (due to the cooling down of the stimulus), but the attention remains for a while, cogitating the idea to which it was summoned.

@@<hr>
@@<div class="l_spacer"></div>
<040>
@@<h3><b>20. Attention's Job</b></h3>

A person's mind contains at least one active agent of cognition called "attention". An attention points itself to one idea at a time.

There may as well be multiple attentions navigating the person's mental space concurrently. If it is the case, we will refer to them as "primary attention", "secondary attention", and so on.

An attention performs two major jobs while it is pointing to an idea.

(1) It connects the idea with nearby ideas. In physical space, such a connection is called "contiguity". In conceptual space, such a connection is called "resemblance".

(2) It boosts up the vivacity level of the idea.

The more we pay attention to certain ideas, the more vivid they get. This, in turn, strengthens our belief in these ideas.

Ceremonies and rituals are important in human society because citizens need to share a set of common beliefs. Such activities basically "recharge" the vivacity levels of a set of ideas, ensuring that their connections are firmly fixed in our minds.

@@<hr>
@@<div class="l_spacer"></div>
<041>
@@<h3><b>21. Attention Shift</b></h3>

The dots you see here are ideas. Ideas can be connected to each other (denoted by line segments) if they are either contiguous in physical space or if they resemble each other in conceptual space.

The mind contains a self-moving agent called "attention" which constantly crawls the vast network of ideas and their connections, boosting their vivacity levels.

Each idea possesses its own "belief" number. This number tells us how strongly the mind believes in the existence of the idea.

When the attention encounters multiple alternative pathways through which it can move, it tends to move toward nearby ideas with higher beliefs than those with lower beliefs.

Over time, this tendency forces only a few strongly believed ideas to survive and all the other ideas to die out. It is reminiscent of gas clouds in space gradually being condensed into a few dense balls of mass (i.e. planets).

@@<hr>
@@<div class="l_spacer"></div>
<042>
@@<h3><b>22. Thinning of the Cloud</b></h3>

A person's mind is like a galaxy; it is a dense celestial body of innumerable ideas, all shining desperately to be embraced by the attention of the consciousness.

The mind must pay attention to an idea at least occasionally in order to keep it alive. Otherwise, its vivacity will decrease over time and, once it reaches zero, it will kill the idea.

Unfortunately, the mind can pay attention to only a small number of ideas at a time. So, even if the mind happens to have a vast cloud of ideas (due to a sudden appearance of a huge number of external stimuli, for instance), time will eventually do its job of "thinning out" such a cloud into a rigid skeleton of only a selected few ideas which are deemed way more important than others.

@@<hr>
@@<div class="l_spacer"></div>
<044>
@@<h3><b>23. Plenum and Vacuum</b></h3>

Hume's rejection of the infinite divisibility of matter in our minds eventually leads us to the conclusion that ideas must be discrete and finite in nature.

The reason is simple. A brain does not possess infinite processing power, so it cannot possibly perceive an infinite number of ideas.

Therefore, our mental space must be discrete (i.e. not continuous), and must be enclosed by finite boundaries beyond which no further ideas are conceivable (We cannot see things whiter than white itself, for instance).

What this means is that there must be a "minimum distance between ideas". No two distinct ideas can ever be closer than this.

If a pair of ideas separated by the minimum distance are connected to each other (either via the relation of contiguity or resemblance), we can define this interval as the most basic unit of "plenum" (i.e. filled space).

If a pair of ideas separated by the minimum distance are disjoint from each other, we can define this interval as the most basic unit of "vacuum" (i.e. empty space).

@@<hr>
@@<div class="l_spacer"></div>
<045>
@@<h3><b>24. Idea Field</b></h3>

Since ideas are discrete, we can imagine the mind as a vast field of ideas which are placed at regular intervals. The size of each interval is the minimum distance allowed between a pair of ideas.

Most of these ideas, however, are in sleep because their vivacity levels are zero. The mind cannot perceive them because they "do not exist".

External stimuli, which enter the mind via sense organs, give birth to impressions. These impressions, in turn, pump up the vivacity levels of their respective ideas.

The vivified ideas attract the mind's attention. The attention, then, connects these ideas by "smearing" their fluids of vivacity toward each other. If they are too far apart, however, there won't be enough vivacity to spread and the connection will fall short.









:d:Possible usage of Peter Gärdenfors' two-vector event model in the design of gameplay systems.
:k:Peter Gärdenfors, Cognitive Science, Causality, Causation, Causal Loops, Systems Thinking, System Dynamics, Game Design, Game Mechanics, Game Systems, Philosophy, Epistemology, Russell, Hume, Gameplay Systems Design, Technical Design, Lund University
:l:2024-07-28

[Game Design using Gärdenfors' Event Model] July 28, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Introduction</b></h3>

When developing a game, one of the biggest challenges that the developer often encounters is the problem of implementing complex gameplay systems.

A large-scale game project often involves various in-game events, such as instantaneous actions (e.g. malee attack), firing of projectiles, casting of spells (i.e. status conditions), area effects, upgrades, and many others. It is not so easy to make sure that all these events will coexist in harmony, due to undesired side effects which might be caused by factors such as: (1) Race condition, (2) Combination of multiple events, (3) Criteria for deciding whether an event should be applied or not, and so on.

Professor Gärdenfors, who is both a cognitive scientist and a philosopher at the University of Lund (Sweden), has introduced a structurally elegant model of events and their internal causal relations. It is called the "Two-Vector Model", and it leverages vector quantities as means of specifying the cause and effect of an event. In other words, his model defines an event as an instance of vector transformation.

What I have personally noticed is that his event model works beautifully in the context of game development. Many of the complexities which are prone to arise in gameplay systems can easily be mitigated (or even avoided) by applying the two-vector model, due to the fact that it lets us nicely encapsulate each gameplay event's causal relation as a simple algebraic operation.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>The Two-Vector Event Model</b></h3>

<049>

According to Professor Gärdenfors' definition of cause and effect, an event can be thought of as a vector function which takes a vector as the input and returns another vector as the output.

In the two-vector event model, the input is a "force vector" and the output is a "result vector". Imagine that there are two separate entities in the world - agent and patient. The agent is the one who causes the event, and the patient is the one who is being affected by the event. Once the event kicks in, the patient receives the force vector (aka "cause") that was emitted by the agent, and yields its own result vector (aka "effect").

The result vector should be able to represent any type of change, but the easiest way to understand it (from the point of view of classical mechanics) is to simply assume that it represents an offset in the patient's position. So if you (i.e. agent) hit a ball (i.e. patient) with the force of 1N and let it move by 1m, you may say that the force vector is (1N, 0N, 0N) and the result vector is (1m, 0m, 0m) in 3D space.

Gärdenfors, however, does not necessarily confine the force and result vectors solely to the physical domain. In his model of events, a "position" may as well refer to the quality of the patient (e.g. color, temperature, emotional state, etc), and a "force" may as well be considered a force which modifies the quality. For instance, an act of painting can be considered an application of a "color-changing force" to the patient, which subsequently pushes the patient's position in color space (e.g. RGB) to the desired color location.

<050>

Gärdenfors' event model differs from more traditional models of causation due to its nature of self-encapsulation. It has widely been presumed that the so-called "causation" is simply a relation between events, and that each event is more or less just a "snapshot" of how things look like at each moment. In Gärdenfors' model, on the other hand, each event contains its own cause-and-effect relation, defined in terms of agent, patient, force, and result. The agent and the force it emits can altogether be considered the "cause" of the event, while the patient and its result of receiving the emitted force can altogether be considered the "effect" of the event.

I think the most prominent advantage of modeling an event this way is that it allows us to apply the notion of causation inside the event itself rather than in terms of its relation with other events. In computer science, such a form of conceptualization nicely fits the OOP (Object-Oriented Programming) paradigm, where each object defines its own behaviors within its own body. So for example, in a typical object-oriented programming language such as Java or C#, it is oftentimes convenient to define "Event" as a class, and assume that its force-to-result vector transformation procedure (i.e. causal relation) will be implemented as the class's member function.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>An Alternative Interpretation</b></h3>

<051>

As a side note, I would like to briefly introduce yet another mathematical interpretation of an event. In his paper on event structure and force dynamics (See Fig 11 of <a href="https://www.sciencedirect.com/science/article/pii/S038800012300075X">"Event structure, force dynamics and verb semantics"</a>), Gärdenfors explains Croft's alternative definition of causality. According to Croft, a cause-and-effect relation between forces can be explicated as the propagation of a "causal signal" across the dimension of causality. What's really interesting in this worldview is that it imagines "causality" as yet another dimension in spacetime, via which various worldly phenomena (i.e. events) establish causal links with one another.

This philosophically fascinating design, however, requires both the force vector and the result vector to reside in the same set of dimensions, thereby disallowing the result vector from identifying itself as part of its own hypothetical space which is of a different type from that of the force vector. This apparent lack of expressive freedom, I think, is one of the reasons why this unified spatial representation of causality is not so widely used.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>A Linguistic Interpretation</b></h3>

<052>

In <a href="https://www.researchgate.net/publication/352868530_Causal_Reasoning_and_Event_Cognition_as_Evolutionary_Determinants_of_Language_Structure">"Causal Reasoning and Event Cognition as Evolutionary Determinants of Language Structure"</a>, as well as the latter half of <a href="https://www.sciencedirect.com/science/article/pii/S038800012300075X">"Event structure, force dynamics and verb semantics"</a>, Gärdenfors suggests a possible usage of his two-vector event model as a device for explaining sentence structures in our language. An "event", according to him, can be expressed as an English sentence because it has its own subject (agent), verb (force), and object (patient).

Both the agent and patient can be described by nouns, yet adjectives and prepositions can also be leveraged as "filters" for specifying them more precisely. For example, in conceptual space (aka "feature space" in machine learning and artifical intelligence), a noun can be imagined as a voluminous region (which encloses a cluster of data points that are associated with that noun) and an adjective can be imagined as a thin plane which partially intersects such a region. A combination between a noun and an adjective (e.g. "black cat", "white rose", or "wooden jar"), therefore, indicates the intersection (i.e. a plane segment) between the noun's region and the adjective's plane.

Similarly, a preposition may as well function as a filter because it specifies a region in physical space with respect to the physical location (and direction) of the observer's point of reference. It "sorts out" any object which does not fall within the specified region.

The force and result vectors are expressible in terms of verbs. Here, a verb (or a "verb phrase" in general) can be defined as a vector transformation which maps a region in space to another region in space. These regions are specified by the sentence's subject and object, respectively.

Based upon these observations, Professor Gärdenfors suggests that we formulate our language in terms of events and their force-to-result (i.e. cause-and-effect) relations. In other words, our language is based on the way we cogitate causal relations.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Application in Game Development</b></h3>

A potential application of Peter Gärdenfors' event model can be found in the development of video games. When designing a gameplay system, a developer often finds it hard to construct the cause-and-effect relations of various in-game events (e.g. Attack, Heal, Stun, Knockback, Poison, Teleport, etc) without introducing too many layers of complexity. Gärdenfors' nicely encapsulated model of events solves this problem, and I am here to demonstrate why.

First of all, we need to take a look at the generalized form of the two-vector model in order to be able to leverage it for game design purposes. It is illustrated below.

<053>

Previously, I have shown that an event can be summarized as a combination of a cause (i.e. agent and the force it emits) and an effect (i.e. patient and the result it generates from the received force). In general, however, an event does not necessarily have to involve exactly one agent, one patient, and one force vector.

Whenever I walk on my own, I am both the one who exerts the force of movement (agent) and the one who is being moved by that force (patient). And whenever I happen to be pushed by two people simultaneously, I should consider both of them as the agents of the "push" event. Their force vectors will have to be added up to yield the net force vector, which will then be used by the event to compute the result vector.

Let me show you a simple gameplay scenario to explain why the concept shown so far is useful for gameplay systems design. Suppose that there is a role-playing game in which the player is a fantasy warrior traveling in a dungeon. There are currently 3 characters nearby, one of them attacking the player (i.e. Attacker) and the other two healing the player (i.e. Healer A and Healer B). The player has a health bar which shows his current health. Each attacker decreases the health, and each healer increases the health.

<054>

In the two-vector model, it is necessary to represent this simultaneous presence of attacking/healing effects as a combination of force vectors. Imagine that there is a hypothetical space called "force space" in which all the contributing forces of the event reside (The idea of representing the force/result vectors in their own conceptual spaces is illustrated in <a href="https://www.sciencedirect.com/science/article/pii/S038800012300075X">"Event structure, force dynamics and verb semantics"</a>). When an event kicks in, these contributing forces all add up to yield a single net force vector. This net force vector, then, gets mapped into its corresponding result vector. The result vector exists in another hypothetical space called "result space".

<055>

In the case of the player's health-changing event, we should consider the force space as the spectrum of all health-changing force values. So if the force is 0, you are doing nothing to the player's health. If the force is 1, you are increasing the player's health with the strength of 1 (This is what "healing" does). If the force is -1, you are decreasing the player's health with the strength of 1 (This is what "attacking" does). And so on.

The attacker applies the health-changing force of -1 to the player, while each of the two healers applies the health-changing force of 1 to the player. The net force is (-1) + 1 + 1 = 1, so we will conclude that the overall health-changing force that the player receives must be 1.

<056>

The health-changing event system, then, should be expected to take this net force vector (= 1) and transform it into its corresponding result vector which characterizes the change in the player's health (aka "ΔHealth"). Mathematically, such a process of transformation can be carried out by plugging the net force vector (as the input parameter) into the function called "transfer function", which basically shows us the one-to-one correspondence between force vectors and their result vectors.

Once the transformation part is complete, the only task remaining is to add the result vector (ΔHealth) to the player's current health. This is essentially what the player's health-changing event does whenever it executes itself.

But of course, one might be confused and say, "Dude, why do you overthink it? Just keep it simple. Simple is best. All you need to do is increase the player's health by 1 whenever a healer heals, and decrease it by 1 whenever an attacker attacks. You don't need such a fancy framework to do that!"

I am pretty sure that this is the exact kind of response which will be asserted a thousand times by a group of parrots unless I come up with a slightly more advanced example to show you the complexity of the issue. So here is an additional example.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Status Conditions</b></h3>

<057>

Suppose that there is also a wizard who is casting a spell on the player. This spell is called "heal-blocker spell", and while it is affecting the player, it prevents him from being healed. How shall we implement this this?

A naive approach is to put a conditional statement inside the the gameplay logic, such as: "IF (the player is being affected by a heal-blocker spell), THEN (do not heal the player)". This might be a decent solution for small games. If the game happens to involve a hundred (or even more) types of spells, however, a decent developer will agree that hard-coding their effects using a bunch of conditional statements is not an okay way to do it.

A much more scalable way of implementing a spell (aka "status condition") is to define it as a modifier of an event's transfer function.

<058>

The default transfer function of the player's health-changing event is the identity function ("f(x) = x"). It gracefully handles both the force of heal and the force of attack because, whenever the force is a positive number (heal), the health will change in the positive direction with the rate that is proportional to the magnitude of the force, and whenever the force is a negative number (damage), the health will change in the negative direction with the rate that is proportional to the magnitude of the force. This is exactly what we would expect the health-changing event to do every time it receives a force.

When the player is under the influence of the health-blocker spell, however, such a transfer function is no longer valid because the player shouldn't be healed when he receives a healing force. Therefore, we must zero out the right half of the transfer function to enforce such a condition. And how do we do that? There are multiple ways, but the easiest one is to "add" another function to the transfer function which, after the addition, will cancel out the healing behavior of the original transfer function.

This additive approach is quite elegant because it is incredibly easy to undo the process of addition. Whenever we add the spell, we simply add the spell's modifier function to the player's current transfer function. Whenever we remove the spell, we simply remove (subtract) the spell's modifier function from the player's current transfer function. Since subtraction is the exact inverse of addition, no information will be lost and all the external factors (i.e. anything that is not part of the spell) will be preserved no matter how many times we add/remove the spell to/from the player.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Thresholding</b></h3>

<059>

Another application of the two-vector event model can be found in success-or-fail (aka "binary") scenarios, such as trying to let the character jump up a steep hill in order to proceed to the next stage. Imagine that there is a hill right in front of the player, and that the player is trying to reach the top of the hill by jumping. The player's current altitude is 0, and it will be shifted up to 1 once he successfully reaches the top.

<060>

Just like we did in the previous example, we can use the two-vector event model for the problem of jumping. Unlike in the case of attacking and healing, though, we will now begin to assume that the force space refers to the range of "jump forces" (where high magnitudes denote powerful jumps and low magnitudes denote weak jumps), and that the result space refers to the change in the player's altitude after the jump.

The jump event has its own transfer function which is not an expression of proportionality between two variables, but a "threshold condition" which tells us how strong the player's jump must be in order to let him reach the top of the hill. In this example, at least the force of magnitude 2 is required to accomplish such a goal.

The main benefit of threshold-oriented gameplay scenarios (where you either CAN or CANNOT do something, not somewhere in between) is that it allows you to impose upon the player a specific set of keys which must be utilized in order to unlock his/her way out of the obstacle. If the hill were a smooth surface, for example, the player would've been able to climb it up by paying just a bit more effort and time. Under a strict yes-or-no condition, on the other hand (e.g. locked door, unreachable height, uncrossable river), it becomes possible to force the player to follow an absolute requirement such as: "You MUST have this item in your inventory in order to finish this task". This prevents the player from completing the whole game based solely upon brute-force and enough patience.

<061>

In his article on force dynamics (See <a href="https://www.sciencedirect.com/science/article/pii/S038800012300075X">"Event structure, force dynamics and verb semantics"</a>), Gärdenfors shows us that an event's force vector can be classified into one of the following categories under the presence of a goal - "Enable", "Help", "Prevent", and "Despite". The "Enable" force, when added to the patient's current force vector, allows him/her to achieve the desired result which was unachievable before. The "Help" force is similar to the "Enable" force, except that its presence is not absolutely necessary because the patient is already able to achieve the desired result (with just a bit of additional time and effort). The "Prevent" force is the opposite of the "Enable" force because it disables the patient from achieving the goal which would have been achievable otherwise, and the "Despite" force is the opposite of the "Help" force.

Such categorization of forces is definitely feasible in a threshold-based scenario, such as the problem of jumping to reach the top of the steep hill. For example, if the player's initial jump force is only 1 and there is a "booster" item in the inventory which he/she can consume in order to add an extra boost of 1 to the jump force (which will achieve enough level of force to reach the top of the hill), we will be able to tell that this item is the "enabler" of the player's hill-mounting event. This way, we are able to sort various items, abilities, spells, and other numerous in-game factors into the four major categories (i.e. Enable, Help, Prevent, and Despite) and implement them appropriately based on how their presence will affect the progression of the game in binary (i.e. threshold-driven) gameplay scenarios.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Data-Driven Design</b></h3>

Many of you who have implemented large-scale gameplay systems may have heard of the term, "data-driven". It is one of the most popular design philosophies in game development, in which the game's rules are specified in the form of declarative statements (e.g. data tables, English sentences, block diagrams, etc) instead of being hard-coded as part of the game's script itself.

Gärdenfors' event model nicely fits the spirit of data-driven gameplay design, due to the fact that it allows us to fully describe an event and its causal relation in the form of a plain English sentence (i.e. a declarative statement), instead of a bunch of conditional and iterative statements which are intertwined with one another (See <a href="https://www.researchgate.net/publication/352868530_Causal_Reasoning_and_Event_Cognition_as_Evolutionary_Determinants_of_Language_Structure">"Causal Reasoning and Event Cognition as Evolutionary Determinants of Language Structure"</a>). Engineers who have studied a logic programming language (e.g. Prolog) will instantly grasp the beauty of this, as well as how neatly it is going to mitigate many of the design complexities which tend to arise in gameplay engineering.

As long as we manage to express gameplay events as English sentences, we will be able to summarize all gameplay rules simply as a list of sentences and hardly anything else.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Event as a List Processor</b></h3>

The examples I have shown so far are only one-dimensional - that is, each force space or result space is only a single number line, made up of a single variable (e.g. "change in health", "change in altitude", etc). However, this is just for the ease of visualization (because it is easier to draw 1D and 2D graphs than ones which are 3D, 4D, etc). In general, each force space or result space should be allowed to possess any number of dimensions, which may be spatial (x, y, z), temporal (t), or qualitative (e.g. color, temperature, health, mana, dexterity, experience, anger, happiness, attack strength, defense strength, and so forth).

Designing a transfer function which maps a multidimensional force vector to a multidimensional result vector is indeed a difficult thing to do. If you consider each vector as just an array of numbers (e.g. "int[]"), however, you will be able to tell that the two-vector event model is nothing more than a "list-mapping process" - a generic system which takes a list of numbers as the input, and generates another list of numbers as the output. One of the easiest ways of designing such a system is to treat each element of the output list as a linear combination of the elements of the input list. This lets the system's transfer function be constructed as a simple matrix multiplication, which is something your graphics card (GPU) can do extremely well.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Special Thanks</b></h3>

<062>

I would really like to thank Katarina Gyllenbäck for introducing the works of Professor Gärdenfors. I would have not had a chance to delve into his profound insights in the field of cognitive science, if she did not introduce his papers in her articles.

Katarina Gyllenbäck, who is both a narrative designer and a researcher of interactive media, has shown me a narrative-driven interpretation of Gärdenfors' two-vector event model. It is most thoroughly illustrated in her description of conceptual space in the article, <a href="https://katarinagyllenback.com/2023/03/16/part-11-the-meaning-makers-space/">"Part 11, The Meaning-Maker's Space"</a>.

To learn more about her areas of insight, please visit <a href="https://thingspool.net/read-rec/page-2.html">Here</a> to see my review of her writings on narrative design. Or, you may want to visit her website and read her vast collection of articles <a href="https://katarinagyllenback.com">Here</a>.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Bibliography</b></h3>

1. <a href="https://www.sciencedirect.com/science/article/pii/S038800012300075X">Event structure, force dynamics and verb semantics</a> by Peter Gärdenfors (This article most accurately summarizes the mathematical pattern behind the causal relations of the two-vector event model.)

2. <a href="https://www.researchgate.net/publication/352868530_Causal_Reasoning_and_Event_Cognition_as_Evolutionary_Determinants_of_Language_Structure">Causal Reasoning and Event Cognition as Evolutionary Determinants of Language Structure</a> by Peter Gärdenfors (This one most thoroughly describes the linguistic interpretation of the two-vector event model, explaining why an event can be considered a sentence and each element of the event can be considered a phrase such as a "noun phrase", "verb phrase", etc)

3. <a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2020.584017/full">Primary Cognitive Categories Are Determined by Their Invariances</a> by Peter Gärdenfors (This is a great introductory text to the idea of "Conceptual Space" - a hypothetical space which expresses the qualitative attributes of an object as a point in geometry. It also explains how a set of invariances in our domain of cognition (i.e. a dense cluster of sense-data) eventually manifest themselves in the form of a discrete entity called "object". This is one of the most foundational ideas in the study of artificial intelligence and machine learning (often referred to as "pattern recognition").)

4. <a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2020.00630/full">Events and Causal Mappings Modeled in Conceptual Spaces</a> by Peter Gärdenfors (This is a general overview of how the force and result vectors are related to one another in an event. In this paper, Professor Gärdenfors tells us various subleties that are involved in the dynamics of causality, such as the capacity of the human mind to perform interpolation between two force vectors (which means that the total domain of forces which can be formed by a set of basis force vectors is their convex hull), etc.)

5. <a href="https://www.researchgate.net/publication/322314237_From_Sensations_to_Concepts_a_Proposal_for_Two_Learning_Processes">From Sensations to Concepts: a Proposal for Two Learning Processes</a> by Peter Gärdenfors (This article introduces some of the experimental results which show us that, during early childhood development, young children do manage to learn how much an object (i.e. a cluster of data points) differs from another object (i.e. another cluster of data points), but not necessarily the direction (i.e. dimension) in which they differ. It is only later stages in life during which they acquire the ability to break down each object as a product of multiple dimensions and make comparisons based upon individual dimensions, not only in terms of the overall distance between two clusters of data).






:d:A computational interpretation of Good and Evil.
:k:Good and Evil, Dichotomy, Dualism, Binarism, Philosophy, Computational Philosophy, Computational Ethics, Ethics, Monotheism, Theology, Theism, Theosophy
:l:2024-07-30

[Good and Evil] July 30, 2024

This is a computational interpretation of Good and Evil, as well as how to model their dynamics using vector math. This is useful for technical systems design in the development of computer games.

@@<hr>
@@<div class="l_spacer"></div>
<018>
@@<h3><b>Heaven and Hell</b></h3>

Good and evil are measurable quantities.

There are three points in space - the center of Heaven, the center of Hell, and the center of the world.

The center of Heaven is the best possible state of the world; it is the pivot of pure good.

The center of Hell is the worst possible state of the world; it is the pivot of pure evil.

The center of the world belongs to neither of these two pivots. It represents the current state of the world, which is a mixture between both good and evil. Therefore, it is located somewhere between Heaven and Hell.

Both Heaven and Hell are perfect spheres. The radius of Heaven is the radius of its spherical event horizon (i.e. threshold beyond which the world can no longer escape from the volume of Heaven), and the radius of Hell is the radius of its spherical event horizon (i.e. threshold beyond which the world can no longer escape from the volume of Hell).

The amount of good in the world is its distance from Hell, minus its distance from Heaven. The farther away the world is from Hell, the more "good" it is. The closer the world is to Heaven, the more "good" it is.

The opposite scenario applies to the amount of evil in the world; it is the world's distance from Heaven, minus its distance from Hell.

@@<hr>
@@<div class="l_spacer"></div>
<019>
@@<h3><b>Goodness of Movement</b></h3>

There are three regions in space - Heaven, Hell, and the world in which we live. All three of them have their own center positions.

The world can either be moving toward Heaven, toward Hell, or somewhere in between. A movement directed toward Heaven is a "good movement", and a movement directed toward Hell is an "evil movement".

The world's movement is characterized by its velocity vector. This vector tells us how fast and in which direction the world is currently moving.

Suppose that there is a unit vector which starts from the center of the world and points directly to the center of Heaven. This indicates the best direction in which the world can ever move with respect to Heaven.

Furthermore, suppose that there is yet another unit vector which starts from the center of the world and points directly away from the center of Hell. This indicates the best direction in which the world can ever move with respect to Hell.

Combine these two unit vectors together and you will get the best direction of movement with respect to both Heaven and Hell.

If you compute the dot product between this vector and the world's velocity vector, you will obtain the degree of how good the world's velocity is.

@@<hr>
@@<div class="l_spacer"></div>
<020>
@@<h3><b>Thermostat's World</b></h3>

How to calculate the position of Heaven and Hell? It really depends on the definition of our world.

A world made up of a single thermostat dwells in a one-dimensional space which represents the full range of temperatures. The center of the world refers to the current temperature.

This one-dimensional space's lower edge indicates the lowest temperature that the thermostat can ever reach. It is one of the two centers of Hell (i.e. It is the center of the headquarter of Hell's ice department).

In contrast, the upper edge indicates the highest temperature that the thermostat can ever reach. This, too, is one of the two centers of Hell (i.e. It is the center of the headquarter of Hell's fire department).

The center of Heaven is the thermostat's most ideal temperature (i.e. Temperature that the thermostat is ordered to reach).

@@<hr>
@@<div class="l_spacer"></div>
<021>
@@<h3><b>Force of Morality</b></h3>

Measurement of the force of morality starts from the realization of our best desire.

The center of the world is constantly moving. The rate at which it simultaneously approaches Heaven and escapes Hell indicates the overall goodness of its movement.

The best velocity of the world is its most optimal direction of movement (That is, the direction which decreases the distance between the world and Heaven and increases the distance between the world and Hell as quickly as possible), scaled by the maximum possible speed of the world.

Our best desire is the direction which guides the world's current velocity to its best velocity as quickly as possible. If you multiply it by the world's overall amount of morality, you will get the force of morality which is currently pushing the world.

@@<hr>
@@<div class="l_spacer"></div>
<024>
@@<h3><b>Multiple Eras</b></h3>

The world's timeline consists of multiple eras. As time passes by, the world advances from one era to the next in a sequential manner.

Each era has its own Heaven and Hell, meaning that the amount of good (or evil) in the world is determined by the particular era in which we live.

Once the world enters Heaven 1 during Era 1, the era changes from Era 1 to Era 2. Then, once the world enters Heaven 2 during Era 2, the era changes from Era 2 to Era 3.

If Era 3 is the last of all eras, the world will finally merge with Heaven 3 (i.e. the final Heaven) after entering it.

On the other hand, entering the current era's Hell brings the world back to its previous era instead of the next.

As a side note, it is also feasible to connect the last era to the first era, thus forming an infinite loop of eras. In this case, time will be eternal and the world will keep on moving in its orbit forever.








:d:This a new way of designing biology-inspired emergent systems, based upon Glenn Puchtel's biocybernetic theory. It encompasses the construction of artificial life, artificial mind, virtual ecosystems, wetware, and other nature-inspired phenomena, based on ideas such as Systems Thinking and Unconventional Computing.
:k:Glenn Puchtel, Emergent Systems, Control Systems, Feedback Loop, Control Theory, Cybernetics, Biocybernetics, Swarm Intelligence, Software Design, Software Architecture, System Dynamics, Systems Thinking, Systems Engineering, Signal Processing, DSP, Communication Systems, Communication Network, Wetware, Unconventional Computing, Unconventional Cognition, Cognitive Science
:l:2024-08-02

[Emergent Systems based on Glenn Puchtel's Biocybernetic Theory] August 2, 2024

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Introduction</b></h3>

If you are a software engineer, you will probably agree that designing a well-organized system is a necessary step in the development of an application. Not that many engineers, however, agree that the system must be "emergent" in order for us to maximize its robustness as well as resilience.

It is probably true that emergence is not a necessary ingredient when it comes to creating a rather static, single-purpose program. When it comes to highly dynamic applications such as simulations and video games, though, we cannot help ourselves realizing that the sheer complexity of the system we are dealing with is not something which can be thoroughly grasped by the developer's intellect alone.

A large-scale application with its own adaptive behaviors is oftentimes too complex in nature, that the developer is inevitably led to the conclusion that the system must be broken down into smaller subsystems. Such a divide-and-conqure approach comes in handy especially when a fairly large team of developers are simultaneously working on the same codebase (Modularization helps us reduce interdependencies, for example).

There is a much more profound advantage in the aforementioned design philosophy, however, and it is often referred to as "emergence". As you might have already guessed, expressing a system as a group of multiple subsystems (rather than a single, monolithic blackbox) is a good idea not only because it makes it easy for developers to tackle each individual part separately, but also because the collective behavior of such subsystems makes room for what we would like to describe as "swarm intelligence" - an army of relatively dumb agents which, when coordinated under a common goal, display surprisingly robust and resilient phenomena (e.g. self-recovery of a multicellular organism).

Such a multi-agent system is called "emergent", due to the fact that its complexity is something which emerges out of simpler elements, rather than something which was carved like a rigid sculpture by the developer.

<a0_1>

Glenn Puchtel, who is an interdisciplinary software architect with expertise in system dynamics and cognitive science, has introduced a set of novel concepts in the design of emergent systems. Explained in the context of cybernetics, these concepts tell us that they can be used as building blocks of what may be termed "artificial biological organs" - modules that a cyborg would attach to its body in order to adapt itself to the surrounding environment.

In the following sections, I will be illustrating a collection of Glenn Puchtel's ideas which are indispensable for the construction of emergent systems. They are inspired by some of his major articles, which are listed below:

1. <a href="#bibliography_1">"Cybernetic-Oriented Design (CyOD)"</a>
2. <a href="#bibliography_2">"Coordination without (direct) Communication"</a>
3. <a href="#bibliography_3">"Cybernetic Waves"</a>
4. <a href="#bibliography_4">"Reaction Networks"</a>
5. <a href="#bibliography_5">"Biological Models of Reactionary Networks"</a>
6. <a href="#bibliography_6">"Temporality"</a>
7. <a href="#bibliography_7">"Bio-Cybernetic Patterns"</a>

These articles, however, are not the only ones he has written. If you want to read more of his works, please visit his LinkedIn newsletter: <a href="https://www.linkedin.com/newsletters/cyborg-bio-cybernetics-6879770834110689280/">"Cyborg - (bio)cybernetics"</a>.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>1. Separation of State and Behavior</b></h3>

Glenn Puchtel begins his introduction to cybernetic-oriented design with the notion of "separation of state and behavior" <a href="#bibliography_1">[1]</a>. Programmers who have learned OOP (Object Oriented Programming) will remember that a system (i.e. "object") is practically a blockbox which encapsulates both a behavior and a state. This is quite syntactically apparent in a class declaration, where the member functions characterize its behavior and the member variables characterize its state.

People who dislike OOP may insist that the very idea of wrapping both a behavior and a state inside the same container called "object" is a bad decision, since the mixture of these two drastically different elements is prone to spill nasty side effects such as race conditions and deadlocks.

This, however, is not really an intrinsic aspect of OOP, but rather a result of misunderstanding the way this paradigm should be handled. Most of its undesirable side effects can be attributed to the lack of enough separation between systems (objects), not the lack of a thick, gigantic wall which segregates everything into two global zones - one containing all the functions (behavior), and the other one containing all the state variables.

It is okay to let each system have its own behavior AND its own local state. After all, a system without any state is memoryless, and the range of actions that a memoryless system can take is extremely limited (since it is only able to react to the current input and none of the previous inputs).

One of the main sources of OOP's complexity problem is one's attempt to pack too many functionalities in a single object. Such a mistake can be prevented by making each object as simple as possible. However, we should also take care not to use this design approach as a means of justifying tight coupling (i.e. direct communication) among objects which are functionally closely related.

<a1_1>

Tight coupling might be okay to have if we are dealing with just a few objects. If there are too many of them, the overall architecture will start to degenerate into a jungle of entangled, disorderly web of communication.

<a1_2>

So, what's the solution? The key lies on Glenn Puchtel's concept of "coordination without direct communication" <a href="#bibliography_2">[2]</a>. I will explain it in detail throughout the upcoming sections.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>2. Indirect Communication</b></h3>

If you have looked at Glenn Puchtel's bio-inspired systems (i.e. biocybernetic systems) <a href="#bibliography_5">[5]</a>, you will be able to tell that they do not allow their biological subsystems (e.g. cells) to share information simply by directly invoking each other's member functions. Instead, these subsystems communicate via a "medium" - a chemical mixture which exists somewhere in space and decays over time. Such a medium continuously emits waves <a href="#bibliography_3">[3]</a>, which are signals waiting to be picked up by nearby systems (e.g. neighboring cells) and be processed according to their own behavioral logic (i.e. goal + rules).

<a2_1>

What I just mentioned is the essence of indirect communication. Instead of directly feeding signals to each other (which creates dependency), systems can instead talk to each other by means of a medium. A medium could be interpreted as some form of "shared state" among multiple systems, yet we should also be aware that it carries its own behavior as well (e.g. continual emission of waves, interaction with environmental factors, etc). Such a dual aspect, combined with the architect's demand for structural consistency, eventually leads us to conclude that the place which holds a medium is itself yet another system, composed of its own state and behavior.

(For a specific example, please refer to the component called "Pipe" in Glenn Puchtel's article, "Biological Models of Reactionary Networks" <a href="#bibliography_5">[5]</a>.)

<a2_2>

This is analogous to typical communication networks which we use daily. Our cellphones exchange data by means of cellphone towers, and out personal computers exchange data by means of servers and routers (which altogether constitute the internet). Two most widely known benefits of such a networking scheme are: (1) Reduction of the number of connections between nodes, and (2) Simplification of the overall topology of the connections.

In Glenn Puchtel's biocybernetic design philosophy, however, he reveals yet another major advantage of indirect communication - scoping of information.

In the "Space (scope)" and "Time" sections of his article, "Coordination without (direct) Communication" <a href="#bibliography_2">[2]</a>, Glenn Puchtel mentions that "giving individuals access to too much information may lead to sensory overload", suggesting that limiting the scope of information is crucial.

He says that it can be achieved by using a medium as the gateway of communication. As long as a medium occupies only a limited region in space and time, systems which communicate via such a medium will be guaranteed to receive information which is only relevant to the local region to which they belong.

The importance of scoping eventually leads us to the conclusion that the application as a whole should comprise multiple layers of scope, which necessitates the notion of a "hierarchy".

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>3. Hierarchy of Systems</b></h3>

When developing a large-scale application, a hierarchical worldview oftentime helps. The reason behind this is not difficult to grasp; whenever the system we are required to implement is too complex, we feel the necessity to break it down to a collection of simpler subsystems, devise each of them separately, and then join them together to let them collaborate as a whole.

For instance, a biological organism is a complex system which can be broken down to a number of major subsystems such as the digestive system, circulatory system, respiratory system, nervous system, immune system, and so on. Since these subsystems are still pretty complex, we still have to break them down to even simpler subsystems, etc, in a recursive (tree-like) manner. This means that a complex system should be hierarchical in structure.

<a3_1>

(According to Glenn Puchtel, "Complex systems organize themselves in hierarchical layers of abstraction-a structure achieved by encapsulating smaller, more specific systems within more extensive, more general systems" <a href="#bibliography_1">[1]</a>.)

In fact, we have already seen an example of hierarchical modeling in the previous section (i.e. "2. Indirect Communication"). When two systems are communicating through a medium, we may as well say that they are both physically bound to the same place to which the medium belongs. In other words, these two communicators should be deemed as two neighboring objects which are occupying the same region in space.

This is the simplest example of a hierarchy, in which the two communicating agents are the children of their common parent. In a way, therefore, one could claim that each branching point of a tree of systems is basically a place (i.e. a medium-provider) through which its subsystems are allowed to communicate, as though it is a LAN (Local Area Network).

<a3_2>

In general, a hierarchical breakdown of systems allows us to handle our problems via multiple layers of abstraction (where the root of the tree represents the most general (abstract) system, and each leaf of the tree represents the most specific (single-purpose) system). At the same time, it also lets systems communicate with one another by means of their parent systems, which means that they are able to transmit messages across multiple layers of the hierarchy.

("The result is the control or dynamic regulation of behavior between layers" - Glenn Puchtel <a href="#bibliography_1">[1]</a>)

For example, suppose that we are modeling an animal's anatomy as a hierarchy of systems. And let us also suppose that cells are subsystems of a tissue and tissues are subsystems of a bloodstream (Note: I know that this is not an accurate reflection of how the body really works, but let's just ignore it for the sake of demonstration). If a cell wants to send a signal to another cell, it won't require a direct connection to that cell to do so. It will only release a chemical which will eventually be delivered to the other cell through the following steps:

(1) First, the cell's chemical will be absorbed by the surrounding tissue.
(2) The tissue will release the chemical to the adjacent bloodstream.
(3) The chemical in the bloodstream will be picked up by the other tissue.
(4) And finally, the other cell's receptor will receive the chemical's signal.

<a3_3>

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>4. Polymorphism</b></h3>

Glenn Puchtel's "separation of statics and dynamics" <a href="#bibliography_1">[1]</a> is an extremely useful concept not just for the sake of organization, but also for the sake of enabling polymorphism.

The foundation of polymorphism lies on the idea of decoupling. Glenn Puchtel mentions in his article that individual systems which are decoupled by knowledge "need not know about the other; only that stimulus introduction affects the state" <a href="#bibliography_2">[2]</a>. What he means by this is that the stimulus (information) can simply reveal its presence in a shared medium, exposing itself to nearby systems and hardly doing anything else. The individual systems, then, can pick up the stimulus from the shared medium and respond to it based on their own decision-making processes.

<a4_1>

The main advantage of polymorphism is that it enhances the modularity of systems. The sender of a stimulus does not have to care who the recipient is, or in which fashion the stimulus ought to be presented in order to fit the recipient's expectations. Those who want to receive it will receive it, and those who want to respond to it will respond to it. And the type of response is entirely up to the recipient's own behavior. The sender only needs to care about sending, and the recipient only needs to care about receiving.

Since a single type of stimulus is able to trigger different responses when detected by different types of recipients, the effects of its presence can be considered "polymorphic" - "poly" because it exhibits a one-to-many relationship (i.e. single input, multiple outputs), and "morphic" because the effects appear in distinct forms.

<a4_2>

A great example of polymorphism can be found in the case of ants and their pheromone-based communication. Glenn Puchtel says in his article that: "Just as the same pheromone elicits different behavior, whereby a worker ant might respond differently from a soldier ant, messages trigger receptors' behavior depending on their role" <a href="#bibliography_2">[2]</a>. Here, a pheromone is a stimulus (input signal) which triggers two separate responses when received by two different recipients (i.e. worker ant and solider ant).

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>5. Feedback Loops</b></h3>

Another benefit of indirect (medium-based) communication is that it allows us to create indirect feedback loops - i.e. long, circular chains of causality which control the flow of the overall system based on not only short-term effects, but also long-term effects (aka "Circular Causality", as mentioned by Glenn Puchtel in his introduction to cybernetic-oriented design <a href="#bibliography_1">[1]</a>). Such a phenomenon is indispensable for the design of dynamics systems which involve multiple causal loops that are intertwined with one another, such as an ecosystem, a marketplace, an electrical grid, and many others which appear in the study of System Dynamics (aka "Systems Thinking").

<a5_1>

A direct (i.e. internal) feedback loop is something which can easily be constructed within the anatomy of the system itself; those of you who have studied systems engineering will probably know how to design such a thing. All you need to do is branch off the output signal, feed it into a stream of time-delay elements (just 1 delay element for a first-order system, or 2 delay elements for a second-order system, etc), and then use that stream as part of the subsequent input of the system. This is an example of how a system can leverage part of its own history of outputs as means of calculating its current input.

<a5_2>

An indirect (i.e. external) feedback loop, on the other hand, requires a collaboration of multiple systems. The output of a system in such a loop first leaves the system, enters another system, leaves that system too, enters yet another system, and so on, until its effect eventually comes back to the input port of the original system. This is how you can simulate long-term effects in complex systems, such as too much population growth eventually leading to more deaths due to food shortage, and so on.

<a5_3>

The most obvious way of implementing indirect feedback loops is to first draw a CLD (<a href="https://en.wikipedia.org/wiki/Causal_loop_diagram">Causal Loop Diagram</a>) and then devise systematic components (e.g. stocks and flows) based on its graph structure. This approach, however, forces the overall architecture to be static (i.e. hard to modify) due to the way it tightly couples its individual subsystems with each other.

Indirect communication offers a nice solution to this lack of structural flexibility. As long as the individual systems communicate only via their "shared pool of information" (i.e. medium), we will be free to either add an additional system to the pool or remove an existing system from the pool without invoking undesirable side effects. This allows systems to dynamically reproduce or destroy themselves as though they are part of a living organism, allowing the overall architecture to continuously modify its shape (which is indispensable for adaptive, self-regulatory behaviors).

Besides, medium-based communication is far superior to predefined communication routes when it comes to the creation of indirect feedback loops, due to one simple reason; a shared medium allows its members to indirectly influence each other in any order/combination, as illustrated in the diagram below.

<a5_4>

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>6. Divisibility means Resilience</b></h3>

Expressing the overall system as an assembly of numerous subsystems has yet another advantage to offer; it is the sense of resilience.

In the "Weight [measure]" section of his article, "Coordination without (direct) Communication", Glenn Puchtel mentions that "emergent systems favor small, lightweight, almost negligible parts; losing any part does not adversely affect the whole" <a href="#bibliography_2">[2]</a>.

What he means by this is that a system which is divisible in nature (i.e. able to cut some of its parts off and still manage to function) is capable of sacrificing small portions of itself for larger gains - a sign of flexibility. If the system were a single, inseparable unit, any risk which involves its loss would cost the total annihilation of the system and would have to be avoided entirely.

<a6_1>

In general, a divisible system is robust because it is composed of rearrangeable parts. Such a system can grow, shrink, and change its shape as needed, and is able to accept relatively minor risks (e.g. A lion hunts down a giraffe despite the risk of being injured, since it can regrow its damaged tissues).

(Look at "Apoptosis" in Glenn Puchtel's "Coordination without (direct) Communication" <a href="#bibliography_2">[2]</a>.)

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>7. Goal</b></h3>

There is one major factor in systems design which I haven't mentioned yet. It is "goal" - a sense of purpose. A system needs a goal to serve its designated role; otherwise there is no point in designing a system, unless all we want is an engineering equivalent of "art for art's sake".

<a7_1>

A goal is what drives the system's control mechanism. A goal-oriented system constantly strives to keep its current state as close to the desired state as possible; for instance, a thermostat's "goal" is to minimize the difference between its current temperature and the desired temperature.

("A goal-oriented system must actively intervene to achieve or maintain its goal" - Glenn Puchtel <a href="#bibliography_1">[1]</a>)

For a simple system such as a thermostat, the goal is easy to define. It only requires us to state simple numerical relations, such as: "The difference between X and X0 should be kept minimal", and so on. In the case of a complex system whose goal is way too complicated to be fully explicated in such a manner, however, we need a somewhat more advanced way of defining goals. From my point of view, one of the best ways of illustrating a complex goal is to decompose it into a list of more specific goals (aka "subgoals"), decompose each of them into even more specific goals, and so on, thereby creating a hierarchy of goals. This is similar to the so-called "behavior tree" in video games.

What's interesting in this model of reasoning is that it is structurally analogous to a hierarchical arrangement of systems. In fact, this happy correlation is due to the intrinsic one-to-one correspondence between each system and the goal it is expected to serve (e.g. The root system serves the root goal, the left subtree's system serves the left subtree's goal, etc).

<a7_2>

Here is an example. An organism's goal is to survive. In this case, "organism" is the root system and "survive" is the root goal. The problem is that the words "organism" and "survive" are so broad in scope, that they fail to delineate all the necessary details.

Therefore, we must repeatedly break them down into more specific components, up until the moment at which we finally feel assured that everything is broken down to a set of "atoms" which do not demand further conceptual decomposition. In computer engineering, the atoms are primitive data types (e.g. char, int, float) and machine level instructions (e.g. MOV, ADD, MUL). In electrical engineering, the atoms are basic circuit components (e.g. transistors, capacitors, inductors).

In this example, the "survive" goal can be defined as a compound of 2 subgoals - "eat" and "breathe". Serving the "survive" goal is the same thing as serving both the "eat" and "breathe" goals. 

The hierarchy of systems can be expected to mirror the hierarchy of goals. Since the "survive" goal is the parent of its 2 child goals ("eat" and "breathe"), the organism (whose goal is to "survive") should be considered the parent of its 2 child systems which serve the "eat" and "breathe" goals, respectively. The first one is the digestive system, and the second one is the respiratory system.

<s7_3>

The presence of a hierarchy of goals helps us design the hierarchy of systems because these two have a direct one-to-one relationship (i.e. they are structurally identical). All we have to do is look at each of the goals and construct a system which fulfills that goal.

@@<hr>
@@<div class="l_spacer"></div>
@@<h3><b>Bibliography</b></h3>

1. <a id="bibliography_1" href="https://www.linkedin.com/pulse/cybernetic-oriented-design-cyod-glenn-puchtel/">Cybernetic-Oriented Design (CyOD)</a> by Glenn Puchtel (This introductory article outlines pretty much all the main concepts in the design of emergent systems, including: (1) Separation of state and behavior (which enables polymorphism), (2) Hierarchical arrangement of individual subsystems (which is a neat way of breaking down a complex system into a collaborative network of simpler systems), (3) Back-and-forth interaction between state and behavior, which gives rise to feedback loops, and so on.)

2. <a id="bibliography_2" href="https://www.linkedin.com/pulse/coordination-without-direct-communication-glenn-puchtel/">Coordination without (direct) Communication</a> by Glenn Puchtel (Reading this article is crucial for understanding the nature of emergence and how its full potential might be leveraged. Here, the author suggests "indirect communication" (i.e. communication by means of a medium, rather than by means of a direct and instantaneous feeding of signals) as a method of letting individual subsystems collaborate with each other in an implicit manner, which eventually reveals highly emergent patterns such as those we can find in cellular automata.)

3. <a id="bibliography_3" href="https://www.linkedin.com/pulse/cybernetic-waves-glenn-puchtel/">Cybernetic Waves</a> by Glenn Puchtel (This article suggests a chemistry-inspired method of designing a signal-transmitting medium in a cybernetic communication network. The author tell us that a "medium", a mixture of multiple chemical substances of varying saturations, along with several physical parameters such as temperature and pressure, can be placed in the environment, which in turn will emit waves (signals) to the surroundings for some limited duration.)

4. <a id="bibliography_4" href="https://www.linkedin.com/pulse/reaction-networks-glenn-puchtel/">Reaction Networks</a> by Glenn Puchtel (Here, the author directly shows us how to define a chemical mixture in a software simulation and use it as a medium of communication between virtual biological modules. He also suggests specific ways of interpreting the content of such a mixture for the purpose of evaluating/modifying the surrounding environment (aka "conditions" and "cures"). Additionally, the very last diagram of the article deserves special attention, since it summarizes the grand cycle of information flow in a cybernetic-oriented system. In this diagram, "signals" is where an organism receives information, "rules" and "states" are where the organism evaluates and stores the received information, and "actions" is where the organism emits actions based on the result of evaluation. The "world" is the outside environment, which is governed by its own environmental factors such as chemical mixtures (media). These factors continuously emit waves, which the organism's receptors then receive as "signals".)

5. <a id="bibliography_5" href="https://www.linkedin.com/pulse/biological-models-reactionary-networks-glenn-puchtel/">Biological Models of Reactionary Networks</a> by Glenn Puchtel (This one explains in detail the specific building blocks of the author's (bio)cybernetic systems architecture, including nodes, edges, pipes, rules, applicators, kits, and others. Nodes are basically the entry/exit points of signals, edges are transmitters of signals, and pipes/applicators are the ones which make decisions based on the received signals.)

6. <a id="bibliography_6" href="https://www.linkedin.com/pulse/temporality-glenn-puchtel/">Temporality</a> by Glenn Puchtel (This article illustrates the inner workings of time-related cybernetic components (e.g. temporals) using specific code examples. By doing this, the author proves us that these components are highly useful for simulating the ways in which signals vary their intensity levels as time passes by - an extremely crucial concept for implementing time delays in the system's feedback mechanism, as well as for implementing gradual memory decay.)

7. <a id="bibliography_7" href="https://www.linkedin.com/pulse/cybernetic-patterns-glenn-puchtel/">Bio-Cybernetic Patterns</a> by Glenn Puchtel (This is the graphical summary of the major building blocks in cybernetic-oriented design. They resemble digital circuit components in some sense, yet are much more functionally abstract. Within this collection, "pipe" is probably the most notable component because it represents the very concept of "controlled transmission of signals" - an ever-recurring theme in the activity of neurons, protein receptors, and other biological signal-processors.)